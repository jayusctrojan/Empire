{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Backend Environment Setup (FastAPI, Celery, Supabase, Redis, Neo4j)",
        "description": "Establish the production backend infrastructure using FastAPI, Celery, Supabase PostgreSQL (with pgvector), Redis (Upstash), and Neo4j Community (Docker).",
        "details": "Provision Render services for FastAPI and Celery. Configure Supabase PostgreSQL with pgvector and graph tables. Set up Redis (Upstash) for caching and Celery broker. Deploy Neo4j Community via Docker on Mac Studio for knowledge graph storage. Ensure all services use TLS 1.3 and encrypted environment variables. Recommended versions: FastAPI >=0.110, Celery >=5.3, supabase-py >=2.0, redis-py >=5.0, Neo4j Community 5.x.",
        "testStrategy": "Validate service connectivity, health endpoints, and database schema migrations. Run integration tests for API endpoints and Celery task execution. Confirm Redis and Neo4j connectivity.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Provision FastAPI and Celery Services on Render",
            "description": "Deploy FastAPI and Celery worker services using Render, ensuring production-grade configuration and separation.",
            "dependencies": [],
            "details": "Set up two separate Render services: one for FastAPI (API server) and one for Celery (background worker). Use recommended versions (FastAPI >=0.110, Celery >=5.3). Configure environment variables securely and ensure both services are reachable over the network.",
            "status": "done",
            "testStrategy": "Verify service deployment via Render dashboards. Access FastAPI health endpoint and confirm Celery worker logs show successful startup.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configure Supabase PostgreSQL with pgvector Extension and Graph Tables",
            "description": "Set up Supabase PostgreSQL instance, enable pgvector, and create required tables for embeddings and graph data.",
            "dependencies": [],
            "details": "In Supabase dashboard, enable the 'vector' extension (pgvector) via Extensions panel or SQL command. Create tables for storing embeddings (e.g., documents with embedding vector columns) and graph structures as needed. Use recommended supabase-py >=2.0 for client access.\n<info added on 2025-11-03T04:12:52.520Z>\nSupabase PostgreSQL is already provisioned at qohsmuevxuetjpuherzo.supabase.co with credentials stored in the .env file. The database is accessible via Supabase Management Console Panel (MCP). \n\nTo complete this subtask:\n\n1. Connect to the Supabase PostgreSQL instance using the MCP or SQL editor.\n\n2. Enable the pgvector extension by executing:\n   ```sql\n   CREATE EXTENSION IF NOT EXISTS vector;\n   ```\n\n3. Create all 37+ required tables from /workflows/database_setup.md, including:\n   - documents\n   - document_chunks\n   - chat_sessions\n   - user_memory_nodes\n   - crewai_agents\n   - crewai_crews\n   - vector tables with embedding columns\n   - graph structure tables\n   - and all other tables specified in the database setup file\n\n4. Verify table creation and ensure proper relationships and constraints are established according to the schema definitions.\n\n5. Test database connectivity using supabase-py >=2.0 client from the application.\n</info added on 2025-11-03T04:12:52.520Z>",
            "status": "done",
            "testStrategy": "Run SQL queries to confirm pgvector is enabled and tables exist. Insert and retrieve sample data, including vector columns.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Set Up Redis (Upstash) for Caching and Celery Broker",
            "description": "Provision a Redis instance on Upstash and configure it for both caching and as the Celery message broker.",
            "dependencies": [],
            "details": "Create a new Redis database on Upstash. Obtain connection URL and credentials. Configure FastAPI and Celery to use this Redis instance for caching and as the Celery broker. Use redis-py >=5.0 for integration.",
            "status": "done",
            "testStrategy": "Connect to Redis from both FastAPI and Celery. Set and retrieve cache keys. Confirm Celery can enqueue and process tasks using Redis broker.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Deploy Neo4j Community Edition via Docker on Mac Studio",
            "description": "Install and run Neo4j Community Edition (5.x) using Docker on the Mac Studio for knowledge graph storage.",
            "dependencies": [],
            "details": "Pull the official Neo4j Community Docker image (version 5.x). Configure Docker container with appropriate ports, volumes for data persistence, and secure environment variables. Ensure Neo4j is accessible from the local network.",
            "status": "done",
            "testStrategy": "Access Neo4j Browser UI, run basic Cypher queries, and verify data persistence after container restart.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Configure TLS 1.3 and Encrypted Environment Variables for All Services",
            "description": "Ensure all backend services (FastAPI, Celery, Supabase, Redis, Neo4j) use TLS 1.3 for secure communication and store environment variables encrypted.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Update service configurations to enforce TLS 1.3 (e.g., Render custom domains with TLS, Upstash Redis with TLS, Supabase with SSL, Neo4j Docker with TLS certificates). Store all secrets and environment variables using encrypted storage mechanisms provided by each platform.",
            "status": "done",
            "testStrategy": "Attempt connections using only TLS 1.3. Inspect certificates and verify environment variables are not exposed in logs or process listings.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Validate Integration and Connectivity Across All Services",
            "description": "Test and confirm that FastAPI, Celery, Supabase, Redis, and Neo4j are correctly integrated and can communicate securely.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Implement health checks and integration tests: FastAPI connects to Supabase and Neo4j, Celery tasks use Redis broker and access Supabase, all over TLS. Run end-to-end tests for API endpoints and background tasks.",
            "status": "done",
            "testStrategy": "Run automated integration tests. Check logs for successful connections. Use tools like curl or Postman to verify TLS and endpoint health.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Break down the backend environment setup into subtasks for provisioning each service (FastAPI, Celery, Supabase PostgreSQL with pgvector, Redis, Neo4j), configuring secure communication (TLS 1.3), and validating integration and connectivity."
      },
      {
        "id": 2,
        "title": "File Upload Interface & Backblaze B2 Integration",
        "description": "Implement multi-file upload (up to 10 files, 100MB each) with drag-and-drop UI, progress indicators, and direct upload to Backblaze B2 pending/courses/ folder.",
        "details": "Use Gradio or Streamlit for the web UI. Integrate Backblaze B2 via b2sdk (Python >=1.20). Support Mountain Duck polling (30s) and immediate processing for web UI uploads. Enforce file size/type limits and progress feedback. Organize files per B2 folder structure.",
        "testStrategy": "Upload various file types and sizes, verify progress indicators, and confirm files appear in B2 pending/courses/. Test both Mountain Duck and web UI flows.",
        "priority": "high",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Multi-File Upload UI with Drag-and-Drop",
            "description": "Create a user interface using Streamlit or Gradio that supports uploading up to 10 files (max 100MB each) via drag-and-drop, with progress indicators and file type/size validation.",
            "dependencies": [],
            "details": "Use Streamlit's st.file_uploader with accept_multiple_files=True or Gradio's file upload component. Implement drag-and-drop functionality, enforce file type and size limits, and display progress indicators for each file. Ensure the UI is intuitive and provides feedback on upload status and errors.",
            "status": "done",
            "testStrategy": "Upload various file types and sizes, verify drag-and-drop works, progress indicators display correctly, and validation prevents unsupported files.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Backblaze B2 Direct Upload via b2sdk",
            "description": "Connect the file upload UI to Backblaze B2 using b2sdk (Python >=1.20), enabling direct upload of files to the pending/courses/ folder and organizing files per B2 folder structure.",
            "dependencies": [
              1
            ],
            "details": "Configure b2sdk for authentication and folder management. Implement logic to upload files directly from the UI to the pending/courses/ folder, ensuring files are organized according to the required B2 structure. Handle upload errors and provide feedback to the user.",
            "status": "done",
            "testStrategy": "Upload files through the UI and confirm they appear in the correct B2 folder. Test error handling and folder organization.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Mountain Duck Polling and Immediate Processing Logic",
            "description": "Support file uploads via Mountain Duck by polling the local folder every 30 seconds and trigger immediate processing for files uploaded via the web UI.",
            "dependencies": [
              2
            ],
            "details": "Set up a polling mechanism to detect new files in the local folder synced by Mountain Duck every 30 seconds. For files uploaded via the web UI, initiate processing immediately after upload. Ensure both flows enforce file limits and integrate with the B2 upload logic.",
            "status": "done",
            "testStrategy": "Simulate uploads via Mountain Duck and web UI, verify polling detects new files, immediate processing works, and all files are uploaded to B2 with correct feedback.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on file upload interface & backblaze b2 integration."
      },
      {
        "id": 3,
        "title": "File Format Validation & Security Scanning",
        "description": "Validate file formats, check integrity, scan for malware, and enforce MIME/extension rules before upload.",
        "details": "Use python-magic for MIME detection, validate extensions, and run integrity checks (e.g., PDF header validation). Integrate ClamAV (clamd) for malware scanning. Reject unsupported formats with clear error messages.",
        "testStrategy": "Attempt uploads of valid, corrupted, and malicious files. Confirm correct rejection and error messaging. Validate security scan logs.",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement File Format and MIME Type Validation",
            "description": "Detect and validate the file's MIME type and extension before upload using python-magic and extension checks.",
            "dependencies": [],
            "details": "Use the python-magic library to inspect the file's magic number and determine its true MIME type. Cross-check this with the file extension to ensure consistency. Reject files with mismatched or unsupported MIME types/extensions, and provide clear error messages. Consider using additional libraries like file-validator for comprehensive checks if needed.",
            "status": "done",
            "testStrategy": "Attempt uploads with valid and invalid file types and extensions. Confirm correct acceptance or rejection and error messaging.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Perform File Integrity and Header Validation",
            "description": "Check file integrity and validate headers for supported formats (e.g., PDF, images) to ensure files are not corrupted or malformed.",
            "dependencies": [
              1
            ],
            "details": "For each supported file type, implement header validation (e.g., check PDF header for '%PDF', image headers for magic numbers). Reject files that fail integrity or header checks. Ensure that only structurally valid files proceed to the next stage.",
            "status": "done",
            "testStrategy": "Upload corrupted or partially valid files and verify that they are rejected with appropriate error messages.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Malware Scanning with ClamAV",
            "description": "Scan validated files for malware using ClamAV (clamd) before final acceptance.",
            "dependencies": [
              2
            ],
            "details": "After passing format and integrity checks, submit files to ClamAV for malware scanning. Reject any files flagged as malicious and log the incident. Ensure the scanning process is efficient and does not introduce significant upload latency.",
            "status": "done",
            "testStrategy": "Upload files containing known malware signatures and verify detection, rejection, and logging. Confirm clean files are accepted.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on file format validation & security scanning."
      },
      {
        "id": 4,
        "title": "Metadata Extraction & Supabase Storage",
        "description": "Extract basic and advanced metadata (filename, size, type, timestamps, EXIF, audio/video info) and store in Supabase documents table.",
        "details": "Use Python libraries: exifread for images, mutagen for audio/video, python-docx for DOCX metadata. Store extracted metadata in Supabase documents table as per schema. Ensure upload triggers metadata extraction.",
        "testStrategy": "Upload files of each supported type, verify metadata extraction accuracy, and confirm correct Supabase storage.",
        "priority": "high",
        "dependencies": [
          "3"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Metadata Extraction for Supported File Types",
            "description": "Develop Python functions to extract basic and advanced metadata from images, audio/video, DOCX, and PDF files using appropriate libraries.",
            "dependencies": [],
            "details": "Use exifread for image EXIF data, mutagen for audio/video metadata, python-docx for DOCX files, and PyPDF2 or pdfminer.six for PDF metadata extraction. Ensure extraction covers filename, size, type, timestamps, and relevant advanced fields (EXIF, audio/video info, document properties). Structure output as per Supabase schema requirements.",
            "status": "done",
            "testStrategy": "Unit test each extractor with sample files of each type. Validate that all required metadata fields are present and accurate.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Metadata Extraction with File Upload Workflow",
            "description": "Ensure that metadata extraction is automatically triggered upon file upload and that extracted data is prepared for storage.",
            "dependencies": [
              1
            ],
            "details": "Modify the upload handler to invoke the correct extraction function based on file type immediately after upload. Collect and format extracted metadata into a dictionary/object matching the Supabase documents table schema.\n<info added on 2025-11-05T22:11:51.333Z>\nImplementation completed for metadata extraction integration with upload workflow:\n\n1. Added metadata_extractor import to upload.py\n2. Modified upload flow to:\n   - Create temp file if not already created (for virus scanning)\n   - Extract metadata from temp file using MetadataExtractor\n   - Include extracted metadata in upload results\n3. Installed required libraries: exifread 3.5.1 and mutagen 1.47.0\n4. Metadata extraction happens after validation and virus scanning, before B2 upload\n5. Graceful error handling - if extraction fails, error is logged but upload continues\n6. Metadata is included in JSON response under \"metadata\" key for each uploaded file\n</info added on 2025-11-05T22:11:51.333Z>",
            "status": "done",
            "testStrategy": "Simulate file uploads via the interface and verify that metadata extraction is triggered and output is correctly formatted for storage.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Store Extracted Metadata in Supabase Documents Table",
            "description": "Insert the extracted metadata into the Supabase documents table, ensuring schema compliance and error handling.",
            "dependencies": [
              2
            ],
            "details": "Use the Supabase Python client to insert metadata records into the documents table. Implement error handling for failed inserts and log issues for debugging. Confirm that all required fields are populated and that the data matches the schema.\n<info added on 2025-11-05T22:21:11.569Z>\nSuccessfully implemented the SupabaseStorage class in app/services/supabase_storage.py with methods for managing document metadata: store_document_metadata(), get_document_by_file_id(), update_document_status(), and list_documents(). The implementation has been integrated into the upload workflow immediately after the B2 upload process. The API response now includes a \"supabase_stored\" boolean flag to indicate successful metadata storage. The system gracefully degrades if Supabase is not configured, allowing the application to function without interruption. Testing confirms that the complete upload workflow functions as expected - metadata extraction works perfectly and Supabase storage attempts are handled gracefully, returning false if not configured.\n</info added on 2025-11-05T22:21:11.569Z>",
            "status": "done",
            "testStrategy": "Upload files of each supported type, then query the Supabase documents table to verify that metadata is stored correctly and completely.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on metadata extraction & supabase storage."
      },
      {
        "id": 5,
        "title": "Duplicate Detection (SHA-256 & Fuzzy Matching)",
        "description": "Detect duplicate and near-duplicate files using SHA-256 hashes and optional fuzzy matching.",
        "details": "Compute SHA-256 hash for each file and check against Supabase documents table. Implement fuzzy matching using Levenshtein distance for filenames and content (rapidfuzz >=2.0). Provide skip/overwrite options.",
        "testStrategy": "Upload duplicate and near-duplicate files, verify detection and user options. Confirm deduplication accuracy.",
        "priority": "high",
        "dependencies": [
          "4"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement SHA-256 Hash-Based Duplicate Detection",
            "description": "Compute SHA-256 hashes for each file and compare against existing hashes in the Supabase documents table to identify exact duplicates.",
            "dependencies": [],
            "details": "Use a reliable hashing library to generate SHA-256 hashes for all files. Query the Supabase documents table for existing hashes and flag files with matching hashes as duplicates. Ensure efficient scanning and parallel processing for large file sets.",
            "status": "done",
            "testStrategy": "Upload files with identical content and verify that duplicates are detected solely by hash comparison. Confirm that files with different content are not flagged as duplicates.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Fuzzy Matching for Near-Duplicate Detection",
            "description": "Apply fuzzy matching algorithms (Levenshtein distance via rapidfuzz >=2.0) to filenames and file content to identify near-duplicate files.",
            "dependencies": [
              1
            ],
            "details": "After hash-based filtering, use rapidfuzz to compute similarity scores for filenames and optionally file contents. Set configurable thresholds for similarity to flag near-duplicates. Optimize for performance when comparing large numbers of files.",
            "status": "done",
            "testStrategy": "Upload files with similar but not identical names and/or content. Verify that near-duplicates are detected according to the configured similarity threshold.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement User Options for Duplicate Handling (Skip/Overwrite)",
            "description": "Provide user interface and backend logic for skip or overwrite actions when duplicates or near-duplicates are detected.",
            "dependencies": [
              1,
              2
            ],
            "details": "Design UI prompts and backend logic to allow users to choose whether to skip uploading duplicates, overwrite existing files, or take other actions. Ensure options are clearly presented and actions are reliably executed.",
            "status": "done",
            "testStrategy": "Simulate duplicate and near-duplicate uploads, test all user options (skip, overwrite), and verify correct file handling and user feedback.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on duplicate detection (sha-256 & fuzzy matching)."
      },
      {
        "id": 6,
        "title": "Celery Task Queue Management",
        "description": "Implement priority-based Celery task queue for async document processing, with status tracking, retries, and dead letter queue.",
        "details": "Configure Celery with Redis broker. Use priority queues (urgent, normal, low). Implement status tracking in Supabase file_uploads table. Add retry logic (3 attempts, exponential backoff) and dead letter queue for failed tasks.",
        "testStrategy": "Submit tasks with varying priorities, simulate failures, and verify retry and dead letter queue behavior.",
        "priority": "high",
        "dependencies": [
          "5"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Celery with Redis for Priority Queues",
            "description": "Set up Celery to use Redis as the broker and implement priority-based task queues (urgent, normal, low).",
            "dependencies": [],
            "details": "Update Celery configuration to use Redis as the broker. Define separate queues for each priority level (e.g., urgent, normal, low) and configure the broker_transport_options with 'queue_order_strategy': 'priority'. Adjust worker_prefetch_multiplier to 1 for effective prioritization. Ensure workers are started with the correct queue order.",
            "status": "done",
            "testStrategy": "Submit tasks with different priorities and verify that urgent tasks are processed before normal and low priority tasks.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Status Tracking with Supabase",
            "description": "Implement status updates for each task in the Supabase file_uploads table.",
            "dependencies": [
              1
            ],
            "details": "Modify Celery tasks to update the status field in the Supabase file_uploads table at key stages (queued, started, succeeded, failed). Ensure atomic updates and handle race conditions. Use Supabase client libraries for database operations.",
            "status": "done",
            "testStrategy": "Trigger tasks and verify that status changes are accurately reflected in the Supabase file_uploads table throughout the task lifecycle.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Retry Logic with Exponential Backoff",
            "description": "Add retry logic to Celery tasks with up to 3 attempts and exponential backoff on failure.",
            "dependencies": [
              1
            ],
            "details": "Configure Celery task decorators to include retry parameters: max_retries=3 and a backoff strategy (e.g., exponential). Ensure that exceptions trigger retries and that retry attempts are logged or tracked for observability.",
            "status": "done",
            "testStrategy": "Simulate task failures and verify that tasks are retried up to 3 times with increasing delays between attempts.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Set Up Dead Letter Queue for Failed Tasks",
            "description": "Configure a dead letter queue to capture tasks that fail after all retry attempts.",
            "dependencies": [
              3
            ],
            "details": "Create a dedicated dead letter queue in Celery/Redis. Update task failure handlers to route tasks to this queue after exhausting retries. Optionally, log or notify on dead letter events for monitoring.",
            "status": "done",
            "testStrategy": "Force tasks to fail beyond retry limits and verify their presence in the dead letter queue.",
            "updatedAt": "2025-11-05T23:00:18.337Z",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "End-to-End Testing of Priority Queue Management",
            "description": "Test the complete priority queue system, including status tracking, retries, and dead letter handling.",
            "dependencies": [
              2,
              4
            ],
            "details": "Design and execute test cases covering all priority levels, status transitions, retry scenarios, and dead letter queue routing. Validate system behavior under normal and failure conditions.",
            "status": "done",
            "testStrategy": "Run integration tests that submit tasks with various priorities, induce failures, and confirm correct processing, status updates, retries, and dead letter handling.",
            "parentId": "undefined",
            "updatedAt": "2025-11-05T23:00:42.292Z"
          }
        ],
        "complexity": 6.5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Decompose Celery task queue management into subtasks for priority queue configuration, status tracking integration, retry logic implementation, dead letter queue setup, and end-to-end testing.",
        "updatedAt": "2025-11-05T23:00:42.292Z"
      },
      {
        "id": 7,
        "title": "User Notification System (WebSocket & Email)",
        "description": "Provide real-time upload and processing notifications via WebSocket, with optional email alerts for long-running tasks.",
        "details": "Implement FastAPI WebSocket endpoints for progress and completion notifications. Use SMTP or SendGrid for email alerts. Integrate with frontend for actionable error messages.",
        "testStrategy": "Trigger uploads and processing, verify real-time notifications and email delivery for long tasks.",
        "priority": "medium",
        "dependencies": [
          "6"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement FastAPI WebSocket Endpoints for Real-Time Notifications",
            "description": "Develop FastAPI WebSocket endpoints to deliver real-time upload and processing progress and completion notifications to connected clients.",
            "dependencies": [],
            "details": "Set up FastAPI WebSocket routes (e.g., /ws/notifications). Manage client connections and broadcast progress/completion events. Ensure endpoints can handle multiple simultaneous connections and send actionable error messages. Integrate with backend processing logic to emit updates as tasks progress or complete.",
            "status": "done",
            "testStrategy": "Simulate uploads and processing tasks; verify clients receive real-time progress and completion notifications via WebSocket.",
            "parentId": "undefined",
            "updatedAt": "2025-11-05T23:01:15.700Z"
          },
          {
            "id": 2,
            "title": "Integrate Email Alert System for Long-Running Tasks",
            "description": "Add optional email notifications for users when uploads or processing tasks exceed a defined duration threshold.",
            "dependencies": [
              1
            ],
            "details": "Configure SMTP or SendGrid integration for sending emails. Implement logic to detect long-running tasks and trigger email alerts with relevant status and error details. Ensure emails are sent only when user opts in or when thresholds are exceeded. Handle email delivery failures gracefully.",
            "status": "done",
            "testStrategy": "Trigger long-running tasks and confirm that email alerts are sent to the correct recipients with accurate information.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Frontend Integration for Real-Time and Email Notifications",
            "description": "Connect frontend application to WebSocket endpoints and display real-time notifications, including actionable error messages. Provide UI for email alert preferences.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update frontend to establish and manage WebSocket connections, display progress/completion notifications, and show errors in a user-friendly manner. Add UI controls for users to opt in/out of email alerts. Ensure seamless user experience for both notification channels.",
            "status": "done",
            "testStrategy": "Test frontend by uploading files and processing tasks; verify real-time updates and error messages appear, and email preferences are respected.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on user notification system (websocket & email).",
        "updatedAt": "2025-11-05T23:01:15.700Z"
      },
      {
        "id": 8,
        "title": "Backblaze B2 Folder Management & Encryption",
        "description": "Automate file movement across B2 folders (pending → processing → processed/failed) and support zero-knowledge encryption for sensitive files.",
        "details": "Use b2sdk for folder operations. Implement file movement logic based on processing status. Integrate PyCryptodome for optional AES encryption before upload.",
        "testStrategy": "Process files through all folder stages, verify correct organization and encryption for flagged files.",
        "priority": "high",
        "dependencies": [
          "7"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate b2sdk and Set Up B2 Folder Interfaces",
            "description": "Initialize b2sdk, authenticate, and set up interfaces for pending, processing, processed, and failed folders in the B2 bucket.",
            "dependencies": [],
            "details": "Use b2sdk's AccountInfo and B2Api to authenticate and connect to the B2 bucket. Instantiate B2Folder objects for each logical folder (pending, processing, processed, failed) to enable file operations between them.",
            "status": "done",
            "testStrategy": "Verify connection and folder listing for each B2 folder using b2sdk methods.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement File Movement Logic Based on Processing Status",
            "description": "Develop logic to move files between B2 folders according to their processing status (pending → processing → processed/failed).",
            "dependencies": [
              1
            ],
            "details": "Create functions to list files in each folder and move them to the next stage based on status. Ensure atomicity and handle errors during move operations using b2sdk's file copy and delete methods.",
            "status": "done",
            "testStrategy": "Simulate status changes and verify files are moved to the correct folders without duplication or loss.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate PyCryptodome for Optional AES Encryption",
            "description": "Add support for zero-knowledge AES encryption of sensitive files before upload to B2.",
            "dependencies": [
              1
            ],
            "details": "Use PyCryptodome to encrypt files with a user-supplied key before uploading to B2. Ensure encryption is optional and only applied to flagged files. Store encrypted files in the appropriate B2 folder.",
            "status": "done",
            "testStrategy": "Upload both encrypted and unencrypted files, then download and verify decryption for encrypted files.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Handle Status-Based Transitions and Error Recovery",
            "description": "Implement robust handling for file status transitions, including retries and error recovery for failed moves or uploads.",
            "dependencies": [
              2,
              3
            ],
            "details": "Add logic to detect and recover from failed moves or uploads. Implement retry mechanisms and ensure files are not lost or duplicated during transitions. Log all status changes and errors for auditability.",
            "status": "done",
            "testStrategy": "Intentionally trigger errors (e.g., network failures) and verify that files are correctly retried or moved to the failed folder.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Develop Comprehensive Tests for Folder Organization and Encryption",
            "description": "Create automated tests to verify correct file organization across all folder stages and validate encryption/decryption for sensitive files.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Write tests that process files through all folder stages, check their presence in the correct folders, and confirm that encryption is correctly applied and reversible for flagged files.",
            "status": "done",
            "testStrategy": "Run end-to-end tests covering all transitions and encryption scenarios, ensuring files are organized and protected as specified.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Divide B2 folder management and encryption into subtasks for implementing folder movement logic, integrating b2sdk, supporting AES encryption with PyCryptodome, handling status-based transitions, and verifying organization/encryption through tests."
      },
      {
        "id": 9,
        "title": "AI Department Classification Workflow (Claude Haiku)",
        "description": "Classify uploaded documents into 10 departments using Claude Haiku API, storing results in Supabase.",
        "details": "Integrate anthropic-py SDK. Implement async auto_classify_course function as per PRD. Store department, confidence, and subdepartment in documents and courses tables.",
        "testStrategy": "Upload sample documents for each department, verify classification accuracy and Supabase updates.",
        "priority": "high",
        "dependencies": [
          "8"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate Claude Haiku API and anthropic-py SDK for Document Classification",
            "description": "Set up the Claude Haiku API and anthropic-py SDK to enable classification of uploaded documents into 10 departments.",
            "dependencies": [],
            "details": "Install and configure the anthropic-py SDK. Implement API authentication and error handling (e.g., retries, rate limits). Ensure the async auto_classify_course function is ready to send document content to Claude Haiku and receive department predictions. Tune parameters such as temperature and max_tokens for optimal classification accuracy.",
            "status": "done",
            "testStrategy": "Send sample documents to the API and verify department predictions are returned correctly. Test error handling by simulating API failures.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Async auto_classify_course Function and PRD Logic",
            "description": "Develop the async auto_classify_course function according to the Product Requirements Document (PRD), ensuring it processes documents and extracts department, confidence, and subdepartment.",
            "dependencies": [
              1
            ],
            "details": "Write the async function to handle document input, call the Claude Haiku API, and parse the response for department, confidence score, and subdepartment. Ensure the function supports batch processing and handles edge cases (e.g., ambiguous classifications). Document the function and its parameters for maintainability.",
            "status": "done",
            "testStrategy": "Unit test the function with mock API responses. Validate output structure and accuracy against expected department labels.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Store Classification Results in Supabase Documents and Courses Tables",
            "description": "Persist the classification results (department, confidence, subdepartment) in the Supabase documents and courses tables.",
            "dependencies": [
              2
            ],
            "details": "Map the classification output to the correct schema fields in Supabase. Implement transactional writes to ensure data consistency. Add logging for successful and failed writes. Verify that updates are reflected in both documents and courses tables as required.",
            "status": "done",
            "testStrategy": "Upload test documents, run classification, and confirm Supabase tables are updated with correct department, confidence, and subdepartment values. Check for data integrity and error handling.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on ai department classification workflow (claude haiku)."
      },
      {
        "id": 10,
        "title": "Universal Document Processing Pipeline",
        "description": "Extract text and structured data from all supported document types using specialized services and fallback methods.",
        "details": "Integrate LlamaIndex (REST API) for clean PDFs, Mistral OCR for scanned PDFs, Tesseract OCR for fallback. Use python-docx for DOCX, mutagen for audio/video, Claude Vision API for images. Implement table/image extraction and maintain page/section info.",
        "testStrategy": "Process each file type, verify extraction accuracy, structure preservation, and fallback logic.",
        "priority": "high",
        "dependencies": [
          "9"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Modular Document Ingestion and Classification",
            "description": "Design and build the pipeline's ingestion layer to accept documents from various sources and classify them by type (PDF, DOCX, image, audio/video).",
            "dependencies": [],
            "details": "Set up connectors for file sources (e.g., S3 buckets, local uploads). Integrate document type detection logic to route files to appropriate extraction modules. Log ingestion events and maintain audit trails for each document.",
            "status": "done",
            "testStrategy": "Submit sample files of each supported type, verify correct classification and routing, and check ingestion logs for completeness.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Specialized Extraction Services and Fallbacks",
            "description": "Connect and orchestrate specialized extraction services for each document type, with fallback logic for unsupported or failed cases.",
            "dependencies": [
              1
            ],
            "details": "Integrate LlamaIndex REST API for clean PDFs, Mistral OCR for scanned PDFs, Tesseract OCR as fallback, python-docx for DOCX, mutagen for audio/video, Claude Vision API for images. Implement logic to select extraction method based on classification and handle failures by cascading to fallback services.",
            "status": "done",
            "testStrategy": "Process a diverse set of documents, intentionally trigger extraction failures, and verify fallback mechanisms activate and extract data as expected.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Extract Structured Data and Metadata with Section/Page Tracking",
            "description": "Develop logic to extract tables, images, and maintain page/section metadata for all processed documents, ensuring structured outputs.",
            "dependencies": [
              2
            ],
            "details": "Implement table and image extraction for supported formats. Track and store page/section information alongside extracted text and structured data. Ensure outputs are normalized for downstream consumption.",
            "status": "done",
            "testStrategy": "Validate extracted outputs for structure, completeness, and correct association of metadata (page/section info) using test documents with known layouts.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on universal document processing pipeline."
      },
      {
        "id": 11,
        "title": "Audio & Video Processing (Soniox, Claude Vision)",
        "description": "Transcribe audio, extract speakers/timestamps, and analyze video frames using Soniox and Claude Vision APIs.",
        "details": "Integrate Soniox REST API for transcription and diarization. Use ffmpeg-python for frame/audio extraction from video. Analyze frames with Claude Vision API. Store transcripts and timeline metadata.",
        "testStrategy": "Process audio and video files, verify transcript accuracy, speaker identification, and frame analysis.",
        "priority": "high",
        "dependencies": [
          "10"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Extract Audio and Video Frames from Input Files",
            "description": "Use ffmpeg-python to extract audio tracks and video frames from input video files for downstream processing.",
            "dependencies": [],
            "details": "Implement a Python module using ffmpeg-python to separate audio from video files and extract video frames at configurable intervals. Ensure extracted audio is in a Soniox-compatible format (e.g., 16kHz mono WAV). Store extracted frames and audio in a structured directory or object storage for later processing.",
            "status": "done",
            "testStrategy": "Run extraction on sample video files, verify correct number and quality of frames, and check audio format compatibility with Soniox.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Transcribe Audio and Extract Speaker/Timestamps with Soniox API",
            "description": "Integrate Soniox REST API to transcribe extracted audio, enabling speaker diarization and timestamp extraction.",
            "dependencies": [
              1
            ],
            "details": "Authenticate with Soniox API using a project API key. Send extracted audio files for transcription using the async or streaming endpoints. Enable speaker diarization and timestamp options in the API request. Parse and store the returned transcript, speaker labels, and word-level timestamps in the database or metadata files.",
            "status": "done",
            "testStrategy": "Submit test audio files, verify transcript accuracy, correct speaker segmentation, and presence of timestamps. Compare results with ground truth if available.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Analyze Video Frames with Claude Vision API and Store Metadata",
            "description": "Send extracted video frames to Claude Vision API for analysis and store the resulting metadata alongside transcripts and timeline data.",
            "dependencies": [
              1
            ],
            "details": "Batch or stream video frames to the Claude Vision API, handling authentication and rate limits. Parse the returned analysis (e.g., scene description, object detection) and associate results with corresponding timestamps. Store all metadata in a structured format, linking frame analysis to transcript timeline.",
            "status": "done",
            "testStrategy": "Process sample frames, verify that analysis results are received and correctly mapped to frame timestamps. Check integration with transcript timeline and metadata storage.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on audio & video processing (soniox, claude vision)."
      },
      {
        "id": 12,
        "title": "Structured Data Extraction (LangExtract)",
        "description": "Extract entities, key-value pairs, and course metadata using LangExtract API.",
        "details": "Integrate LangExtract REST API for field/entity extraction. Store results in Supabase courses and document_chunks tables. Implement intelligent filename generation (M01-L02 format).",
        "testStrategy": "Process documents with structured fields, verify entity extraction and metadata accuracy.",
        "priority": "high",
        "dependencies": [
          "11"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Extraction Schema and Example Prompts for LangExtract",
            "description": "Specify the entity types, key-value pairs, and course metadata fields to be extracted. Create example prompts and sample extractions to guide the LangExtract API.",
            "dependencies": [],
            "details": "List all required fields (e.g., course title, module number, lesson number, instructor, date) and define their expected formats. Write natural language prompts and provide high-quality example extractions using LangExtract's ExampleData objects to ensure consistent output schema and accurate extraction.",
            "status": "done",
            "testStrategy": "Review extracted fields from test documents to confirm schema coverage and prompt effectiveness.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate LangExtract REST API for Automated Entity and Metadata Extraction",
            "description": "Connect to the LangExtract REST API and implement logic to process course documents, extracting entities, key-value pairs, and metadata as defined in the schema.",
            "dependencies": [
              1
            ],
            "details": "Set up API authentication and request handling. For each uploaded course document, send the text and extraction instructions/examples to LangExtract. Parse the returned structured data, ensuring source grounding and attribute mapping. Handle errors and edge cases (e.g., missing fields, ambiguous extractions).",
            "status": "done",
            "testStrategy": "Process a variety of course documents and verify that all required entities and metadata are extracted with correct attributes and source positions.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Store Extracted Data in Supabase and Implement Intelligent Filename Generation",
            "description": "Save the extracted entities and metadata into Supabase courses and document_chunks tables. Generate filenames using the M01-L02 format based on extracted module and lesson numbers.",
            "dependencies": [
              2
            ],
            "details": "Map extracted fields to Supabase table schemas, ensuring correct data types and relationships. Implement logic to generate filenames (e.g., M01-L02) from extracted metadata and associate them with stored records. Validate data integrity and handle duplicate or conflicting entries.",
            "status": "done",
            "testStrategy": "Insert extracted data from sample documents into Supabase, verify correct mapping and filename generation, and check for consistency across multiple uploads.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on structured data extraction (langextract)."
      },
      {
        "id": 13,
        "title": "Adaptive Chunking Strategy Implementation",
        "description": "Implement semantic, code, and transcript chunking with configurable size and overlap, preserving context.",
        "details": "Use LlamaIndex chunking for documents, custom logic for code (AST parsing), and time/topic-based chunking for transcripts. Store chunks in document_chunks table with metadata and overlap.",
        "testStrategy": "Chunk various document types, verify chunk boundaries, overlap, and context preservation.",
        "priority": "high",
        "dependencies": [
          "12"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Adaptive Semantic Chunking for Documents",
            "description": "Develop and configure semantic chunking for text documents using LlamaIndex, supporting adjustable chunk size and overlap to preserve context.",
            "dependencies": [],
            "details": "Use LlamaIndex's semantic chunker to split documents into contextually coherent chunks. Expose configuration for chunk size and overlap (e.g., via parameters or settings). Ensure chunk metadata (source_doc_id, chunk boundaries, overlap) is captured for each chunk and stored in the document_chunks table. Validate that semantic boundaries are respected and context is preserved across chunks.",
            "status": "done",
            "testStrategy": "Chunk a variety of document types, verify chunk boundaries align with semantic units, check overlap, and confirm metadata is correctly stored.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop Custom Code Chunking Using AST Parsing",
            "description": "Create a chunking mechanism for code files that leverages AST parsing to split code into logical units with configurable size and overlap.",
            "dependencies": [
              1
            ],
            "details": "Implement code chunking logic that parses source code into AST nodes (e.g., functions, classes) and groups them into chunks based on configurable parameters (lines per chunk, overlap). Support multiple programming languages if required. Store resulting code chunks with relevant metadata (e.g., language, function/class names, overlap) in the document_chunks table.",
            "status": "done",
            "testStrategy": "Process code files in different languages, verify chunking aligns with logical code units, check overlap, and ensure metadata accuracy.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Time/Topic-Based Chunking for Transcripts",
            "description": "Design and implement a chunking strategy for transcripts that splits content based on time intervals or topic shifts, with configurable overlap.",
            "dependencies": [
              1
            ],
            "details": "Develop logic to segment transcripts using either fixed time windows or detected topic boundaries. Allow configuration of chunk duration or topic sensitivity, as well as overlap between chunks. Store transcript chunks with metadata (e.g., start/end time, topic label, overlap) in the document_chunks table. Ensure context is preserved across chunk boundaries.",
            "status": "done",
            "testStrategy": "Chunk transcripts with varying lengths and topics, verify chunk boundaries match time/topic criteria, check overlap, and validate metadata storage.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on adaptive chunking strategy implementation."
      },
      {
        "id": 14,
        "title": "Error Handling & Graceful Degradation",
        "description": "Implement robust error handling, retry logic, partial processing, and detailed logging for all pipeline stages.",
        "details": "Use Python exception handling, Celery retry policies, and fallback to simpler methods. Log errors with stack traces in processing_logs table. Move failed files to B2 failed/ folder.",
        "testStrategy": "Simulate service failures, verify retries, partial saves, and error logs.",
        "priority": "high",
        "dependencies": [
          "13"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Robust Exception Handling and Retry Logic in Pipeline Tasks",
            "description": "Integrate structured Python exception handling and Celery retry policies for all pipeline stages to ensure resilience against transient and expected failures.",
            "dependencies": [],
            "details": "Wrap all critical pipeline operations in try/except blocks. Use Celery's retry mechanisms (e.g., autoretry_for, max_retries, retry_backoff) to handle transient errors such as network or service outages. Configure per-task retry parameters and ensure idempotency to avoid side effects on repeated execution. Avoid retrying on non-transient exceptions.",
            "status": "done",
            "testStrategy": "Simulate transient and permanent failures in pipeline tasks. Verify that retries occur as configured, and that non-retriable errors do not trigger retries.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enable Graceful Degradation and Partial Processing with Fallbacks",
            "description": "Design pipeline stages to degrade gracefully by falling back to simpler or partial processing methods when primary logic fails.",
            "dependencies": [
              1
            ],
            "details": "For each pipeline stage, define fallback logic (e.g., simplified processing, skipping non-critical steps) to be invoked when primary processing fails after retries. Ensure that partial results are saved where possible, and that the system continues processing unaffected files or stages. Move unrecoverable files to the B2 failed/ folder for later inspection.",
            "status": "done",
            "testStrategy": "Force failures in primary processing logic and verify that fallback methods are invoked, partial results are saved, and failed files are moved appropriately.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Detailed Error Logging and Monitoring",
            "description": "Log all errors, stack traces, and processing outcomes in the processing_logs table to support debugging and monitoring.",
            "dependencies": [
              1,
              2
            ],
            "details": "On every exception or failure, capture the full stack trace and relevant context. Insert detailed error records into the processing_logs table, including task identifiers, error types, messages, and timestamps. Ensure logs are structured for easy querying and monitoring. Integrate with monitoring tools if available.",
            "status": "done",
            "testStrategy": "Trigger various error scenarios and verify that all relevant details are logged in the processing_logs table, including stack traces and context.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on error handling & graceful degradation."
      },
      {
        "id": 15,
        "title": "Processing Monitoring & Metrics Collection",
        "description": "Track real-time processing progress, resource usage, and cost per document using Prometheus metrics.",
        "details": "Integrate prometheus_client for FastAPI, Celery, and custom business metrics. Track processing time, resource usage, and cost. Store stage-wise metrics in processing_logs table.",
        "testStrategy": "Process documents, verify Prometheus metrics, Grafana dashboard updates, and Supabase logs.",
        "priority": "high",
        "dependencies": [
          "14"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate Prometheus Metrics Collection in FastAPI and Celery",
            "description": "Instrument FastAPI and Celery services to expose Prometheus-compatible metrics endpoints for processing progress, resource usage, and cost tracking.",
            "dependencies": [],
            "details": "Install prometheus_client in both FastAPI and Celery environments. For FastAPI, mount the /metrics endpoint using make_asgi_app and add counters, histograms, and gauges for request counts, processing time, and resource usage. For Celery, use available Prometheus exporters or integrate prometheus_client to expose worker and task metrics. Ensure all relevant business and custom metrics are included.",
            "status": "done",
            "testStrategy": "Verify /metrics endpoints in FastAPI and Celery return expected metrics. Use Prometheus to scrape these endpoints and confirm metrics are ingested.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Track and Store Stage-wise Processing Metrics in Database",
            "description": "Capture and persist detailed stage-wise metrics (processing time, resource usage, cost per document) in the processing_logs table for audit and analysis.",
            "dependencies": [
              1
            ],
            "details": "Extend processing logic to record metrics at each pipeline stage. Store metrics such as start/end timestamps, CPU/memory usage, and cost estimates in the processing_logs table. Ensure schema supports all required fields and that writes are efficient and reliable.",
            "status": "done",
            "testStrategy": "Process sample documents and verify that processing_logs table contains accurate, stage-wise metrics matching Prometheus data.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Validate Metrics Collection and Visualization End-to-End",
            "description": "Test the full monitoring pipeline from metrics emission to visualization and logging, ensuring real-time and historical data is accurate and actionable.",
            "dependencies": [
              1,
              2
            ],
            "details": "Simulate document processing and monitor Prometheus for real-time metrics updates. Confirm that Grafana dashboards reflect current and historical metrics. Cross-check database logs with Prometheus data for consistency. Validate cost calculations and resource usage reporting.",
            "status": "done",
            "testStrategy": "Run end-to-end tests: process documents, check Prometheus and Grafana for live metrics, and verify processing_logs entries. Ensure all metrics are accurate and actionable.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on processing monitoring & metrics collection."
      },
      {
        "id": 16,
        "title": "Embedding Generation Pipeline (BGE-M3, Claude API)",
        "description": "Generate and cache embeddings for document chunks using BGE-M3 (Ollama for dev, Claude API for prod).",
        "details": "Integrate langchain.embeddings.OllamaEmbeddings for dev, Claude API for prod. Batch process 100 chunks, cache embeddings in Supabase pgvector. Regenerate on content updates.",
        "testStrategy": "Generate embeddings for sample chunks, verify latency, caching, and Supabase storage.",
        "priority": "high",
        "dependencies": [
          "15"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate BGE-M3 Embedding Generation for Development (Ollama)",
            "description": "Set up and integrate the BGE-M3 embedding model using Ollama for local development, enabling batch processing of document chunks.",
            "dependencies": [],
            "details": "Install and configure langchain_ollama and OllamaEmbeddings with the BGE-M3 model. Implement batch processing for 100 document chunks at a time. Ensure the pipeline can handle content updates by triggering re-embedding as needed. Optimize for local inference speed and resource usage.",
            "status": "done",
            "testStrategy": "Generate embeddings for a sample batch of 100 chunks, verify output shape and latency, and confirm embeddings are regenerated on content updates.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Claude API for Production Embedding Generation",
            "description": "Implement embedding generation using the Claude API for production, supporting batch processing and seamless switching from development to production.",
            "dependencies": [
              1
            ],
            "details": "Configure the Claude API integration within the embedding pipeline. Ensure batch processing of 100 chunks per request, with error handling and retry logic. Provide a configuration switch to toggle between Ollama (dev) and Claude API (prod). Ensure compatibility of embedding formats and dimensions.",
            "status": "done",
            "testStrategy": "Run embedding generation for a sample batch via Claude API, verify output consistency with dev pipeline, and test failover and error handling.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Embedding Caching and Regeneration Logic in Supabase pgvector",
            "description": "Design and implement caching of generated embeddings in Supabase pgvector, including logic to detect content updates and trigger regeneration.",
            "dependencies": [
              2
            ],
            "details": "Integrate with Supabase pgvector to store and retrieve embeddings. Implement logic to check for content changes and invalidate or update cached embeddings as needed. Ensure efficient batch inserts and retrievals. Maintain metadata for tracking embedding versions and update timestamps.",
            "status": "done",
            "testStrategy": "Insert, retrieve, and update embeddings in Supabase for sample documents. Simulate content updates and verify that embeddings are correctly regenerated and cached.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on embedding generation pipeline (bge-m3, claude api)."
      },
      {
        "id": 17,
        "title": "Vector Storage & Indexing (Supabase pgvector)",
        "description": "Store embeddings in Supabase pgvector, create HNSW index for fast similarity search, and optimize batch inserts.",
        "details": "Enable pgvector extension, create HNSW index, and optimize batch inserts using supabase-py bulk operations. Organize by namespace and support metadata filtering.",
        "testStrategy": "Insert and search embeddings, verify index performance and metadata filtering.",
        "priority": "high",
        "dependencies": [
          "16"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Enable pgvector Extension in Supabase",
            "description": "Activate the pgvector extension in the Supabase PostgreSQL database to support vector data types and similarity search operations.",
            "dependencies": [],
            "details": "Access the Supabase dashboard, navigate to the Extensions section, and enable the 'vector' extension. This step is required before creating tables with vector columns and using vector search features.",
            "status": "done",
            "testStrategy": "Verify that the 'vector' extension is listed as enabled in the Supabase dashboard and that SQL commands using the 'vector' data type execute without errors.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Create Embeddings Table and HNSW Index",
            "description": "Design and create a table for storing embeddings, including metadata and namespace columns, and add an HNSW index for fast similarity search.",
            "dependencies": [
              1
            ],
            "details": "Define a table schema with columns for id, embedding (vector), metadata (JSONB), and namespace (text or UUID). Use SQL to create the table and then create an HNSW index on the embedding column for efficient ANN search.",
            "status": "done",
            "testStrategy": "Insert sample embeddings and confirm that the HNSW index exists and is used in EXPLAIN query plans for similarity searches.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Optimize Batch Inserts Using supabase-py Bulk Operations",
            "description": "Implement efficient batch insertion of embeddings and metadata using supabase-py or equivalent bulk insert methods.",
            "dependencies": [
              2
            ],
            "details": "Use supabase-py or another supported client to insert multiple embeddings in a single operation, minimizing transaction overhead and maximizing throughput. Ensure the code handles large batches and error cases.",
            "status": "done",
            "testStrategy": "Benchmark batch insert performance with varying batch sizes and verify that all records are correctly stored in the table.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Organize Embeddings by Namespace",
            "description": "Implement logic to assign and query embeddings by namespace to support multi-tenant or segmented storage.",
            "dependencies": [
              2
            ],
            "details": "Add a namespace column to the embeddings table if not already present. Ensure all insert and query operations include namespace filtering to logically separate data for different use cases or clients.",
            "status": "done",
            "testStrategy": "Insert embeddings with different namespaces and verify that queries scoped to a namespace only return relevant records.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Metadata Filtering in Similarity Search",
            "description": "Enable filtering of similarity search results based on metadata fields stored with each embedding.",
            "dependencies": [
              2
            ],
            "details": "Use PostgreSQL's JSONB operators to filter embeddings by metadata fields in combination with vector similarity queries. Update search queries to support metadata-based filtering (e.g., by document type, tags, or timestamps).",
            "status": "done",
            "testStrategy": "Run similarity searches with and without metadata filters, confirming that results are correctly filtered and performance remains acceptable.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7.5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Expand vector storage and indexing into subtasks for enabling pgvector, creating HNSW index, optimizing batch inserts, organizing by namespace, and implementing metadata filtering."
      },
      {
        "id": 18,
        "title": "Hybrid Search Implementation (Dense, Sparse, Fuzzy, RRF)",
        "description": "Implement hybrid search combining vector similarity, BM25, ILIKE, fuzzy matching, and reciprocal rank fusion.",
        "details": "Use pgvector for dense search, PostgreSQL full-text search for BM25, ILIKE for pattern matching, rapidfuzz for fuzzy search. Implement RRF for result fusion with configurable weights.",
        "testStrategy": "Run hybrid searches, verify result fusion, relevance, and latency targets.",
        "priority": "high",
        "dependencies": [
          "17"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Dense, Sparse, and Fuzzy Search Pipelines",
            "description": "Develop individual search pipelines for dense (vector), sparse (BM25), and fuzzy (ILIKE, rapidfuzz) retrieval methods.",
            "dependencies": [],
            "details": "Set up pgvector for dense search, configure PostgreSQL full-text search for BM25, implement ILIKE for pattern matching, and integrate rapidfuzz for fuzzy matching. Ensure each pipeline can independently retrieve and score results for a given query.",
            "status": "done",
            "testStrategy": "Run isolated queries for each pipeline and verify result relevance, accuracy, and latency.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Design and Implement Reciprocal Rank Fusion (RRF) Algorithm",
            "description": "Create a fusion algorithm to combine ranked results from dense, sparse, and fuzzy pipelines using reciprocal rank fusion.",
            "dependencies": [
              1
            ],
            "details": "Develop RRF logic to merge result lists from all pipelines, applying configurable weights. Ensure the algorithm penalizes lower-ranked results and boosts consensus across methods. Validate with sample queries and edge cases.",
            "status": "done",
            "testStrategy": "Test fusion with controlled input lists, verify ranking consistency, and check that top results reflect combined relevance.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Hybrid Search and Expose Unified API Endpoint",
            "description": "Combine all search pipelines and RRF fusion into a single hybrid search workflow, exposing it via an API endpoint.",
            "dependencies": [
              2
            ],
            "details": "Orchestrate parallel execution of all search methods, collect results, apply RRF fusion, and return unified ranked results. Implement API endpoint with configurable fusion weights and query parameters. Ensure robust error handling and logging.",
            "status": "done",
            "testStrategy": "Run end-to-end hybrid search queries through the API, validate result quality, latency, and error handling.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on hybrid search implementation (dense, sparse, fuzzy, rrf)."
      },
      {
        "id": 19,
        "title": "Query Expansion & Reranking (Claude Haiku, BGE-Reranker-v2)",
        "description": "Expand queries using Claude Haiku, execute parallel searches, and rerank results with BGE-Reranker-v2.",
        "details": "Integrate anthropic-py for query expansion, run parallel searches, and rerank top 20-30 results using Ollama BGE-Reranker-v2 (dev) or Claude API (prod).",
        "testStrategy": "Test query expansion and reranking, verify improved recall and precision.",
        "priority": "high",
        "dependencies": [
          "18"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate Claude Haiku for Query Expansion",
            "description": "Implement query expansion using Claude Haiku via anthropic-py, ensuring queries are enriched for improved recall.",
            "dependencies": [],
            "details": "Set up anthropic-py client and configure Claude Haiku 4.5 API parameters (e.g., max_tokens, temperature, top_p). Design prompt templates to expand user queries, leveraging advanced prompt engineering techniques for optimal output. Handle API errors and retries for reliability.",
            "status": "done",
            "testStrategy": "Send sample queries and verify that expanded queries are generated as expected. Compare recall and diversity of results before and after expansion.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Execute Parallel Searches with Expanded Queries",
            "description": "Run parallel searches using the expanded queries to retrieve a broad set of relevant results.",
            "dependencies": [
              1
            ],
            "details": "Implement asynchronous or concurrent search logic to execute multiple queries in parallel. Aggregate results from all searches, ensuring deduplication and efficient handling of large result sets. Optimize for latency and throughput.",
            "status": "done",
            "testStrategy": "Test with multiple expanded queries and measure search latency. Confirm that all relevant results are retrieved and aggregated correctly.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Rerank Search Results Using BGE-Reranker-v2",
            "description": "Apply BGE-Reranker-v2 to rerank the top 20-30 search results for improved relevance and precision.",
            "dependencies": [
              2
            ],
            "details": "Integrate Ollama BGE-Reranker-v2 (dev) or Claude API (prod) to rerank aggregated results. Configure reranker model and permissions, and tune reranking parameters. Validate reranked output for relevance and consistency.",
            "status": "done",
            "testStrategy": "Compare original and reranked result sets using relevance metrics (precision, recall, NDCG). Conduct manual review of top results for quality assurance.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on query expansion & reranking (claude haiku, bge-reranker-v2)."
      },
      {
        "id": 20,
        "title": "Neo4j Graph Integration & Entity Storage",
        "description": "Store entities and relationships in Neo4j, enable graph-based queries and context retrieval.",
        "details": "Use neo4j Python driver (neo4j >=5.10) to create document and entity nodes, relationships, and vector index. Implement Cypher queries for entity-centric and relationship traversal.",
        "testStrategy": "Insert entities/relationships, run Cypher queries, verify graph traversal and context retrieval.",
        "priority": "high",
        "dependencies": [
          "19"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Set Up Neo4j Python Driver and Database Connection",
            "description": "Install the Neo4j Python driver and establish a secure connection to the Neo4j database instance.",
            "dependencies": [],
            "details": "Use pip to install the neo4j Python driver (neo4j >=5.10). Configure connection parameters (URI, username, password) and verify connectivity using GraphDatabase.driver and driver.verify_connectivity(). Ensure the database instance is running and accessible.",
            "status": "done",
            "testStrategy": "Attempt connection and run a simple Cypher query to confirm connectivity.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Entity and Relationship Node Creation",
            "description": "Create Cypher queries and Python functions to insert document and entity nodes, and define relationships between them in Neo4j.",
            "dependencies": [
              1
            ],
            "details": "Define node labels (e.g., Document, Entity) and relationship types. Use MERGE or CREATE Cypher statements to add nodes and relationships. Implement Python functions to batch insert entities and relationships, ensuring idempotency and data integrity.",
            "status": "done",
            "testStrategy": "Insert sample entities and relationships, then query the graph to verify correct node and relationship creation.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Enable Graph-Based Queries and Context Retrieval",
            "description": "Develop Cypher queries and Python interfaces for entity-centric and relationship traversal, including context retrieval and vector index integration.",
            "dependencies": [
              2
            ],
            "details": "Implement Cypher queries for traversing relationships (e.g., MATCH, OPTIONAL MATCH). Integrate vector index for similarity search if required. Provide Python functions to retrieve context around entities and relationships, supporting advanced graph queries.",
            "status": "done",
            "testStrategy": "Run entity-centric and relationship traversal queries, validate context retrieval, and test vector index search if applicable.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on neo4j graph integration & entity storage."
      },
      {
        "id": 21,
        "title": "Caching Strategy (Redis, Tiered Cache)",
        "description": "Implement Redis caching for frequent queries, embeddings, and search results with semantic thresholds and tiered cache.",
        "details": "Use redis-py for L1 cache (Redis), fallback to L2 (PostgreSQL). Implement semantic cache thresholds and 5-minute TTL. Track cache hit rate.",
        "testStrategy": "Run repeated queries, verify cache hits/misses, and cache update logic.",
        "priority": "high",
        "dependencies": [
          "20"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Redis L1 Cache with Semantic Thresholds and TTL",
            "description": "Set up Redis as the primary (L1) cache for frequent queries, embeddings, and search results, applying semantic thresholds and a 5-minute TTL.",
            "dependencies": [],
            "details": "Use redis-py to connect to Redis. Define cache keys for queries, embeddings, and search results. Implement logic to only cache results that meet semantic similarity thresholds. Set a 5-minute expiration (TTL) for all cache entries to ensure freshness. Ensure cache-aside pattern is used for read-heavy workloads, checking Redis first and falling back to the database on cache miss.",
            "status": "done",
            "testStrategy": "Run repeated queries and verify that results are cached in Redis, TTL is respected, and only semantically relevant results are cached.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Tiered Cache Fallback to PostgreSQL (L2)",
            "description": "Implement fallback logic to query PostgreSQL (L2) when Redis (L1) cache misses occur, and repopulate Redis cache as needed.",
            "dependencies": [
              1
            ],
            "details": "On cache miss in Redis, query PostgreSQL for the required data. If found, repopulate Redis with the result, applying the same semantic threshold and TTL logic. Ensure the fallback mechanism is robust and does not introduce significant latency. Use efficient serialization for storing and retrieving data between Redis and PostgreSQL.",
            "status": "done",
            "testStrategy": "Simulate cache misses and verify that data is correctly fetched from PostgreSQL, then cached in Redis for subsequent requests.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Monitor and Track Cache Hit Rate and Effectiveness",
            "description": "Implement monitoring to track cache hit/miss rates and overall cache effectiveness for both Redis and PostgreSQL tiers.",
            "dependencies": [
              1,
              2
            ],
            "details": "Instrument the caching logic to record cache hits, misses, and repopulation events. Aggregate metrics such as hit rate, miss rate, and average response time. Set up dashboards or logs to visualize cache performance and identify optimization opportunities. Use these metrics to tune semantic thresholds and TTL values.",
            "status": "done",
            "testStrategy": "Generate load with a mix of repeated and unique queries, then verify that hit/miss metrics are accurately tracked and reported.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on caching strategy (redis, tiered cache)."
      },
      {
        "id": 22,
        "title": "Query Type Detection & Routing",
        "description": "Classify incoming queries and route to optimal workflow framework (LangGraph, CrewAI, Simple) based on query complexity and requirements.",
        "status": "done",
        "dependencies": [
          "21"
        ],
        "priority": "high",
        "details": "Implemented WorkflowRouter class in app/workflows/workflow_router.py with Claude Haiku-powered classification. The system analyzes queries and routes them to the appropriate processing framework with confidence scoring and reasoning.",
        "testStrategy": "Submit queries of each type, verify correct classification and routing to appropriate workflow frameworks. Validate confidence scoring and fallback mechanisms.",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Query Type Taxonomy and Routing Logic",
            "description": "Define the taxonomy of query types (semantic, relational, hybrid, metadata) and specify routing logic for each type.",
            "dependencies": [],
            "details": "Analyze typical incoming queries and categorize them into clear types. Document routing rules for each category, mapping them to the appropriate search pipeline (vector, graph, metadata). Consider hierarchical classification if the taxonomy is complex, and ensure the design supports future extensibility.",
            "status": "done",
            "testStrategy": "Review taxonomy coverage against a sample set of queries. Validate routing logic with test cases for each query type.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Query Classifier Using Claude Haiku",
            "description": "Develop and deploy a query classifier leveraging Claude Haiku to assign incoming queries to the correct type.",
            "dependencies": [
              1
            ],
            "details": "Use prompt engineering and, if needed, hierarchical classification to maximize accuracy. Integrate Claude Haiku via API, ensuring the classifier outputs only the defined category names. Optimize for speed and reliability, and consider using vector similarity retrieval for highly variable queries.",
            "status": "done",
            "testStrategy": "Submit queries of each type and edge cases to the classifier. Measure classification accuracy and latency. Confirm output matches taxonomy.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Classifier with Search Pipeline Routing",
            "description": "Connect the classifier output to the routing system, ensuring queries are dispatched to the correct search pipeline.",
            "dependencies": [
              2
            ],
            "details": "Implement the routing logic that receives the classified query type and triggers the corresponding search pipeline (vector, graph, metadata, or hybrid). Ensure robust error handling and logging. Validate that each pipeline receives only relevant queries and that fallback logic is in place for unclassified or ambiguous queries.",
            "status": "done",
            "testStrategy": "End-to-end test: submit queries, verify correct classification and routing to the intended pipeline. Check logs and error handling for misrouted or unclassified queries.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Document Workflow Type Taxonomy",
            "description": "Document the implemented workflow type taxonomy (LANGGRAPH, CREWAI, SIMPLE) with detailed characteristics of each type.",
            "dependencies": [
              3
            ],
            "details": "Create comprehensive documentation of the three workflow types: LANGGRAPH for adaptive queries needing iterative refinement and external search; CREWAI for multi-agent tasks with specialized roles and sequential processing; and SIMPLE for straightforward factual lookups. Include examples and decision criteria for each type.",
            "status": "done",
            "testStrategy": "Review documentation with team members to ensure clarity and completeness. Validate with example queries for each workflow type.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Monitor and Optimize Classification Performance",
            "description": "Implement monitoring for classification decisions and optimize performance based on real-world usage patterns.",
            "dependencies": [
              3
            ],
            "details": "Set up analytics to track classification accuracy, confidence scores, and routing decisions in production. Analyze patterns of misclassification or low confidence scores. Refine the classifier based on this data to improve accuracy and reduce fallbacks to SIMPLE workflow.",
            "status": "done",
            "testStrategy": "Analyze classification logs over time. Compare predicted workflow types with actual performance. Measure improvements in classification accuracy after optimization.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on query type detection & routing."
      },
      {
        "id": 23,
        "title": "Query Processing Pipeline & Result Merging",
        "description": "Normalize, expand, execute, deduplicate, and merge query results using RRF and reranking.",
        "status": "done",
        "dependencies": [
          "22"
        ],
        "priority": "high",
        "details": "Implemented comprehensive query processing pipeline with services for query expansion, hybrid search, reranking, and parallel execution. Features include multiple expansion strategies, parallel execution across search methods, deduplication, RRF merging, BGE-Reranker-v2 reranking, logging, metrics tracking, score thresholding, and Top-K selection.",
        "testStrategy": "Process complex queries, verify result quality, deduplication, and latency. All tests passed successfully with the implemented pipeline.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Query Normalization and Expansion",
            "description": "Develop modules to normalize incoming queries and expand them for improved recall and relevance.",
            "dependencies": [],
            "details": "Created query_expansion_service.py using Claude Haiku for query expansion with multiple strategies including synonyms and reformulations. Implemented standardization of query formats (lowercasing, removing stopwords) and comprehensive logging of all normalized and expanded queries for traceability.",
            "status": "done",
            "testStrategy": "Test with diverse query inputs, verify normalization accuracy, and check that expansions improve recall without introducing irrelevant results.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Execute Queries in Parallel and Deduplicate Results",
            "description": "Design and implement parallel query execution across multiple sources, followed by deduplication of retrieved results.",
            "dependencies": [
              1
            ],
            "details": "Implemented parallel_search_service.py to run expanded queries against all relevant data sources concurrently. Applied deduplication algorithms to remove duplicate results based on content similarity and unique identifiers. Added logging for execution times and deduplication statistics.",
            "status": "done",
            "testStrategy": "Simulate concurrent queries, measure execution latency, and verify that deduplication removes all duplicates while retaining unique results.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Merge Results Using RRF and Rerank Final Output",
            "description": "Integrate Reciprocal Rank Fusion (RRF) for merging results and apply reranking models to optimize final result order.",
            "dependencies": [
              2
            ],
            "details": "Created hybrid_search_service.py for RRF merging of results from dense, sparse, and fuzzy search methods. Implemented reranking_service.py using BGE-Reranker-v2 via Ollama (dev) or Claude API (prod). Added score thresholding and Top-K selection for optimal result quality. Ensured comprehensive logging of all queries and merged results for audit and debugging.",
            "status": "done",
            "testStrategy": "Process sample queries, validate that RRF merging and reranking improve relevance, and check that final output matches expected quality benchmarks.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on query processing pipeline & result merging."
      },
      {
        "id": 24,
        "title": "Faceted Search & Result Presentation",
        "description": "Enable faceted filtering (department, type, date, entities) and present results with snippets, highlights, and relevance scores.",
        "status": "done",
        "dependencies": [
          "23"
        ],
        "priority": "medium",
        "details": "Implemented multi-select facets for department, file_type, date_range, and entity filtering. Generated snippets with keyword highlighting using HTML <mark> tags. Displayed relevance scores, source metadata, and B2 URL links. Added pagination support and SQL WHERE clause generation for filters.",
        "testStrategy": "Verified filtered searches functionality, result presentation with snippets and highlights, facet accuracy, and pagination. Confirmed authentication with Clerk JWT tokens works correctly.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Multi-Select Faceted Filtering UI",
            "description": "Develop the frontend components to support multi-select faceted filtering by department, type, date, and entities.",
            "dependencies": [],
            "details": "Design and build user interface elements for each facet (department, type, date, entities) with multi-select capability. Ensure facets are easy to find, mobile-friendly, and update results quickly when filters are applied. Facet values should be ordered logically (alphabetical, numerical, or by relevance) and selected values should be clearly indicated. Only display relevant facets for the current result set.",
            "status": "done",
            "testStrategy": "Test by applying various combinations of facet filters and verifying that the displayed results update accordingly and facet selections persist. Check usability on both desktop and mobile.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Generate and Present Search Result Snippets with Highlights",
            "description": "Create backend and frontend logic to generate result snippets, highlight matched keywords, and display relevant metadata.",
            "dependencies": [
              1
            ],
            "details": "For each search result, extract a relevant snippet containing the matched keywords. Highlight these keywords in the snippet. Display additional metadata such as relevance score, source, and department. Ensure that snippets are concise and informative, and that highlights are visually distinct.",
            "status": "done",
            "testStrategy": "Run searches with various queries and verify that snippets are generated, keywords are highlighted, and metadata is displayed correctly for each result.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Result Presentation with B2 URLs and Relevance Scores",
            "description": "Link each search result to its corresponding Backblaze B2 URL and ensure relevance scores are visible and accurate.",
            "dependencies": [
              2
            ],
            "details": "For each result, provide a clickable link to the B2 URL. Display the relevance score prominently, ensuring it is calculated and presented consistently. Confirm that the source and department fields are shown as specified. Validate that all links are functional and direct users to the correct B2 resource.",
            "status": "done",
            "testStrategy": "Click through result links to verify correct B2 URL redirection. Check that relevance scores match backend calculations and are displayed for all results.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Documentation of Faceted Search Implementation",
            "description": "Document the implementation details of the faceted search service and API endpoint.",
            "dependencies": [
              3
            ],
            "details": "Create comprehensive documentation for the faceted search implementation, including the faceted_search_service.py and the POST /api/query/search/faceted endpoint. Document the parameters accepted by the API (query, departments, file_types, date_from, date_to, entities, page, page_size), authentication requirements, and response format.",
            "status": "done",
            "testStrategy": "Review documentation for completeness and accuracy. Ensure all parameters, response formats, and authentication requirements are clearly explained.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Performance Optimization for Faceted Search",
            "description": "Analyze and optimize the performance of the faceted search implementation.",
            "dependencies": [
              3
            ],
            "details": "Profile the faceted search implementation to identify performance bottlenecks. Optimize SQL queries for facet value extraction and filtering. Implement caching strategies for frequently used facet values. Ensure pagination works efficiently with large result sets.",
            "status": "done",
            "testStrategy": "Benchmark search performance with various query combinations and result set sizes. Verify that response times remain acceptable under load and with complex facet combinations.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on faceted search & result presentation."
      },
      {
        "id": 25,
        "title": "Query Analytics & A/B Testing",
        "description": "Log queries, track latency, CTR, and support A/B testing for ranking algorithms.",
        "details": "Store query logs and result clicks in Supabase. Implement analytics dashboard and A/B test framework for ranking methods.",
        "testStrategy": "Analyze logs, verify CTR tracking, and run A/B tests.",
        "priority": "medium",
        "dependencies": [
          "24"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Query Logging and Metric Tracking in Supabase",
            "description": "Set up infrastructure to log all search queries, track latency, and record click-through rates (CTR) in Supabase.",
            "dependencies": [],
            "details": "Design Supabase tables to store query logs, including query text, timestamps, latency, and user interactions (clicks). Integrate logging into the query execution pipeline to ensure all relevant metrics are captured for each search event.",
            "status": "pending",
            "testStrategy": "Verify that queries, latency, and clicks are correctly logged in Supabase by running test queries and inspecting the stored data for completeness and accuracy.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop Analytics Dashboard for Query Metrics",
            "description": "Build a dashboard to visualize query volume, latency, and CTR using data from Supabase.",
            "dependencies": [
              1
            ],
            "details": "Use a dashboarding tool (e.g., Grafana or Streamlit) to connect to Supabase and display real-time and historical analytics for query metrics. Include filters for date ranges and ranking algorithm versions to support analysis.",
            "status": "pending",
            "testStrategy": "Check that the dashboard accurately reflects Supabase data by comparing dashboard metrics with direct database queries. Test responsiveness and filtering capabilities.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement and Run A/B Testing Framework for Ranking Algorithms",
            "description": "Create an A/B testing framework to compare different ranking algorithms by splitting user traffic and measuring impact on CTR and latency.",
            "dependencies": [
              1
            ],
            "details": "Randomly assign users or sessions to control and treatment groups, each using a different ranking algorithm. Log group assignment and outcomes in Supabase. Analyze results using statistical tests (e.g., t-test or Z-test) to determine significance of observed differences in metrics like CTR and latency[1][2][3].",
            "status": "pending",
            "testStrategy": "Simulate A/B tests with test users, verify correct group assignment and metric logging, and validate statistical analysis pipeline with sample data.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on query analytics & a/b testing.",
        "updatedAt": "2025-11-08T18:01:36.843Z"
      },
      {
        "id": 26,
        "title": "Chat UI Implementation (WebSocket, Streaming)",
        "description": "Build a mobile-responsive chat UI with real-time messaging and token-by-token streaming.",
        "status": "done",
        "dependencies": [
          "25"
        ],
        "priority": "high",
        "details": "Implemented with Gradio for frontend. Used HTTP-based streaming with async generators instead of WebSocket for simpler implementation and better reliability with Gradio. Integrated Clerk authentication, comprehensive error handling, retry logic, and mobile-responsive design.",
        "testStrategy": "Tested chat interactions, streaming, and mobile responsiveness across multiple devices. Verified error handling and retry logic.",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Chat UI Frontend with Gradio or Streamlit",
            "description": "Create a mobile-responsive chat interface using Gradio or Streamlit, supporting user input, message display, and chat history.",
            "dependencies": [],
            "details": "Implemented the chat UI using Gradio's ChatInterface. Created chat_ui.py with mobile-responsive design and app_with_auth.py with Clerk authentication integration. Added custom CSS styling for improved mobile experience.",
            "status": "done",
            "testStrategy": "Manually tested UI on desktop and mobile browsers for responsiveness, usability, and correct message display.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Real-time Messaging for Chat Communication",
            "description": "Set up backend with HTTP-based streaming to handle real-time chat communication between frontend and backend.",
            "dependencies": [
              1
            ],
            "details": "Implemented HTTP-based streaming with async generators instead of WebSocket. This approach proved simpler to implement, more reliable with Gradio ChatInterface, and easier to deploy on Render while providing the same user experience.",
            "status": "done",
            "testStrategy": "Tested streaming implementation to verify real-time message delivery and connection stability.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Token-by-Token Streaming from Claude API",
            "description": "Enable streaming of Claude API responses token-by-token to the frontend for real-time chat experience.",
            "dependencies": [
              2
            ],
            "details": "Modified backend to call Claude API with streaming enabled. Implemented token-by-token streaming to the frontend using HTTP async generators. Updated frontend to append streamed tokens to the chat window in real time.",
            "status": "done",
            "testStrategy": "Sent prompts and verified that responses appeared incrementally in the chat UI, matching Claude API streaming output.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Loading Indicators and Error Handling",
            "description": "Add loading indicators for the assistant and robust error handling for network/API failures.",
            "dependencies": [
              3
            ],
            "details": "Added loading indicators (🔍 Processing your query...) while waiting for Claude API responses. Implemented comprehensive error handling with user-friendly messages. Added retry logic with exponential backoff for improved reliability.",
            "status": "done",
            "testStrategy": "Simulated slow responses and errors; verified loading indicator visibility and user-friendly error messages. Tested retry logic with network interruptions.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Test and Optimize Mobile Responsiveness",
            "description": "Thoroughly test the chat UI on various mobile devices and optimize for touch interaction and layout.",
            "dependencies": [
              4
            ],
            "details": "Used browser dev tools and real devices to test UI scaling, input usability, and scrolling. Applied custom CSS styling for optimal mobile experience. Deployed to production at https://jb-empire-chat.onrender.com with both authenticated (/chat) and non-authenticated versions.",
            "status": "done",
            "testStrategy": "Performed cross-device testing and collected feedback to ensure consistent, responsive behavior on phones and tablets.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6.5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Expand chat UI implementation into subtasks for frontend development (Gradio/Streamlit), WebSocket endpoint implementation, streaming response handling, typing indicator/error handling, and mobile responsiveness testing."
      },
      {
        "id": 27,
        "title": "Conversation Memory System (Supabase Graph Tables)",
        "description": "Store and retrieve user conversation memory using PostgreSQL graph tables (user_memory_nodes, user_memory_edges).",
        "details": "Implement memory node/edge creation, context window management, and recency/access-weighted retrieval. Enforce RLS policies.",
        "testStrategy": "Simulate conversations, verify memory storage, retrieval, and RLS enforcement.",
        "priority": "high",
        "dependencies": [
          "26"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Graph Tables for Conversation Memory",
            "description": "Create PostgreSQL tables (user_memory_nodes, user_memory_edges) to represent conversation memory as a graph structure, supporting efficient storage and retrieval.",
            "dependencies": [],
            "details": "Define schemas for user_memory_nodes and user_memory_edges, ensuring each node represents a memory item (e.g., message, context) and edges capture relationships (e.g., temporal, reference). Implement table creation scripts and indexes for efficient traversal. Ensure compatibility with Supabase and prepare for RLS enforcement.",
            "status": "done",
            "testStrategy": "Verify table creation, schema correctness, and ability to insert and query nodes/edges representing conversation history.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Memory Node/Edge Management and Context Window Logic",
            "description": "Develop logic for creating, updating, and deleting memory nodes and edges, and manage the context window for conversation retrieval.",
            "dependencies": [
              1
            ],
            "details": "Implement backend functions to add new conversation turns as nodes, link them with edges, and prune or limit history based on a context window (e.g., last N messages). Ensure recency and access-weighted retrieval logic is in place to prioritize relevant memory during retrieval. Integrate with Supabase API for transactional consistency.",
            "status": "done",
            "testStrategy": "Simulate conversations, add and remove nodes/edges, and verify that context window and recency/access-weighted retrieval return expected results.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Enforce Row-Level Security (RLS) and Validate Secure Access",
            "description": "Apply and test RLS policies to ensure users can only access their own conversation memory data in the graph tables.",
            "dependencies": [
              1,
              2
            ],
            "details": "Define and apply RLS policies on user_memory_nodes and user_memory_edges to restrict access by user identity. Test for unauthorized access attempts and verify that only the correct user's data is accessible. Document RLS configuration and integrate with Supabase authentication.",
            "status": "done",
            "testStrategy": "Attempt cross-user access, verify RLS enforcement, and run automated tests to confirm only authorized access to memory nodes and edges.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on conversation memory system (supabase graph tables)."
      },
      {
        "id": 28,
        "title": "Session & Preference Management",
        "description": "Support multiple concurrent sessions, session persistence, user preference learning, and privacy controls.",
        "details": "Implement session tracking, timeout, export, and deletion. Store preferences as memory nodes. Provide opt-out and explicit preference UI.",
        "testStrategy": "Test session persistence, preference learning, and privacy controls.",
        "priority": "medium",
        "dependencies": [
          "27"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Multi-Session Tracking and Persistence",
            "description": "Develop mechanisms to support multiple concurrent user sessions, ensure session data is persistent across server restarts, and enable session export and deletion.",
            "dependencies": [],
            "details": "Design a session management system that assigns unique, secure session IDs, supports concurrent sessions per user, and persists session data using a shared store (e.g., Redis). Implement session timeout, export, and deletion features. Ensure session data is securely stored and can be invalidated or removed on demand.",
            "status": "done",
            "testStrategy": "Simulate multiple concurrent sessions, verify session persistence after server restart, and test session export and deletion functionality.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop User Preference Learning and Storage",
            "description": "Create a system to learn, store, and update user preferences as memory nodes, ensuring preferences are associated with the correct session and user.",
            "dependencies": [
              1
            ],
            "details": "Implement logic to capture user actions and infer preferences, storing them as structured memory nodes linked to user profiles. Ensure updates are atomic and preferences persist across sessions. Provide mechanisms to retrieve and update preferences efficiently.",
            "status": "done",
            "testStrategy": "Test preference capture, retrieval, and update across multiple sessions and users. Validate that preferences persist and are correctly associated with users.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Design Privacy Controls and Explicit Preference UI",
            "description": "Provide user-facing controls for privacy, including opt-out options and an explicit UI for managing preferences and active sessions.",
            "dependencies": [
              1,
              2
            ],
            "details": "Develop UI components that allow users to view and manage their active sessions, export or delete session data, and opt out of preference learning. Ensure privacy controls are clear, accessible, and enforceable at the backend.",
            "status": "done",
            "testStrategy": "Perform UI/UX testing for privacy controls, verify backend enforcement of opt-out and deletion, and ensure users can manage sessions and preferences as intended.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on session & preference management."
      },
      {
        "id": 29,
        "title": "Monitoring & Observability (Prometheus, Grafana, Alertmanager)",
        "description": "Collect metrics, visualize in Grafana, set up alerting, and structured logging for all services.",
        "details": "Integrate prometheus_client for FastAPI, Celery, Redis, Neo4j. Build Grafana dashboards with pre-built panels. Configure Alertmanager for multi-channel alerts. Implement JSON logs and health check endpoints.",
        "testStrategy": "Simulate load, verify metrics, dashboard updates, alert triggers, and log accuracy.",
        "priority": "high",
        "dependencies": [
          "28"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate Prometheus Metrics Collection for All Services",
            "description": "Set up Prometheus metrics collection for FastAPI, Celery, Redis, and Neo4j services using prometheus_client.",
            "dependencies": [],
            "details": "Install and configure prometheus_client in each service. Expose /metrics endpoints for FastAPI, Celery, Redis, and Neo4j. Ensure custom business metrics are included where relevant. Validate that metrics are accessible and correctly formatted for Prometheus scraping.",
            "status": "done",
            "testStrategy": "Simulate service activity and verify metrics are exposed and collected by Prometheus. Check for completeness and accuracy of metrics.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build Grafana Dashboards and Panels for Metrics Visualization",
            "description": "Create Grafana dashboards with pre-built and custom panels to visualize collected metrics from all integrated services.",
            "dependencies": [
              1
            ],
            "details": "Connect Grafana to Prometheus as a data source. Design dashboards for FastAPI, Celery, Redis, and Neo4j, including panels for key metrics (e.g., request rates, error rates, resource usage). Use Grafana's dashboard editor to organize panels and set up useful visualizations for operational monitoring.",
            "status": "done",
            "testStrategy": "Verify dashboards update in real-time with incoming metrics. Confirm panels display accurate and actionable data for each service.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Configure Alertmanager for Multi-Channel Alerting and Notification Routing",
            "description": "Set up Alertmanager to handle alerts from Prometheus and Grafana, routing notifications to multiple channels (e.g., email, Slack).",
            "dependencies": [
              2
            ],
            "details": "Install and configure Alertmanager. Define alert rules in Prometheus and Grafana for critical metrics. Set up Alertmanager contact points for email, Slack, and other channels. Configure notification policies and silences as needed. Integrate Alertmanager with Grafana to manage and route alerts, ensuring unified notification handling[1][3][4][5][6].",
            "status": "done",
            "testStrategy": "Trigger test alerts and verify notifications are sent to all configured channels. Check alert deduplication, grouping, and routing logic.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Deploy Self-Hosted Langfuse on Render",
            "description": "Deploy Langfuse web service on Render using existing Supabase PostgreSQL database for LLM observability and cost tracking.",
            "details": "Deploy Langfuse Docker container to Render as a web service. Configure database connection to existing Supabase PostgreSQL (unified database architecture). Set environment variables: LANGFUSE_DATABASE_URL, NEXTAUTH_SECRET, NEXTAUTH_URL, SALT. Generate API keys after deployment and update .env file. Verify Langfuse UI is accessible and database tables are created. Cost: $7/month (Starter plan). Full deployment guide: .taskmaster/docs/LANGFUSE_INTEGRATION_PLAN.md (Phase 1: Deployment).",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 29,
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on monitoring & observability (prometheus, grafana, alertmanager)."
      },
      {
        "id": 30,
        "title": "Cost Tracking & Optimization",
        "description": "Track API, compute, and storage costs. Generate monthly reports and trigger budget alerts.",
        "details": "Integrate cost tracking for Claude, Soniox, Mistral, LangExtract, Render, Supabase, B2. Implement budget alert logic at 80% threshold.",
        "testStrategy": "Simulate usage, verify cost reports and alert triggers.",
        "priority": "medium",
        "dependencies": [
          "29"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate Cost Tracking for All Services",
            "description": "Implement automated cost tracking for Claude, Soniox, Mistral, LangExtract, Render, Supabase, and B2, covering API, compute, and storage expenses.",
            "dependencies": [],
            "details": "Set up data pipelines or use APIs to collect cost and usage data from each provider. Normalize and aggregate costs by service and resource type. Ensure tracking supports multi-cloud and SaaS sources, and enables per-service breakdowns for accurate reporting.",
            "status": "done",
            "testStrategy": "Simulate usage across all services, verify that cost data is collected, normalized, and attributed correctly for each provider.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Generate Monthly Cost Reports",
            "description": "Develop automated monthly reporting that summarizes API, compute, and storage costs for all integrated services.",
            "dependencies": [
              1
            ],
            "details": "Design and implement a reporting system that compiles monthly cost data into clear, actionable reports. Include breakdowns by service, resource type, and time period. Reports should be exportable and support visualization for trend analysis.",
            "status": "done",
            "testStrategy": "Trigger monthly report generation with sample data, verify report accuracy, completeness, and clarity for all tracked services.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Budget Alert Logic at 80% Threshold",
            "description": "Set up automated alerts to notify stakeholders when spending reaches 80% of the defined monthly budget for any tracked service.",
            "dependencies": [
              1
            ],
            "details": "Configure monitoring logic to evaluate cumulative spend against budget thresholds in real time. Integrate with notification channels (e.g., email, Slack) to deliver timely alerts. Ensure alerts are actionable and include relevant cost breakdowns.",
            "status": "done",
            "testStrategy": "Simulate cost increases to exceed 80% of budget, confirm that alerts are triggered promptly and contain accurate, actionable information.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on cost tracking & optimization."
      },
      {
        "id": 31,
        "title": "Role-Based Access Control (RBAC) & API Key Management",
        "description": "Implement RBAC for users, documents, and API keys with audit logging and row-level security.",
        "details": "Use Supabase RLS policies, implement user roles (admin, editor, viewer, guest), API key creation/rotation/revocation, and audit logs. Hash API keys with bcrypt.",
        "testStrategy": "Test role permissions, API key flows, and audit log accuracy.",
        "priority": "high",
        "dependencies": [
          "30"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement User Roles and Row-Level Security (RLS) Policies in Supabase",
            "description": "Define user roles (admin, editor, viewer, guest) and implement row-level security (RLS) policies for users, documents, and API keys using Supabase.",
            "dependencies": [],
            "details": "Create a roles table and associate users with roles. Use Supabase's RLS policies to restrict access to tables based on user roles. Ensure that each role has clearly defined permissions for CRUD operations on users, documents, and API keys. Reference Supabase documentation and best practices for RLS and RBAC implementation.\n<info added on 2025-11-11T02:00:19.256Z>\nImplementation completed for User Roles and RLS Policies:\n\n✅ Database Schema Created:\n- Created roles table with 4 default roles (admin, editor, viewer, guest)\n- Created user_roles table for user-to-role mappings\n- Created api_keys table with bcrypt hashing\n- Created rbac_audit_logs table for immutable audit trail\n\n✅ RLS Policies Implemented:\n- Enabled RLS on all RBAC tables\n- roles table: read-only for authenticated users\n- api_keys table: users can only see/manage their own keys\n- user_roles table: users can read own roles, admins can manage all roles\n- rbac_audit_logs table: admin-only access\n\n✅ Default Roles Seeded:\n- admin: Full system access (all permissions)\n- editor: Can read/write documents\n- viewer: Can read documents only\n- guest: Limited read access\n\nFiles created:\n- app/models/rbac.py (Pydantic models)\n- app/core/supabase_client.py (Supabase helper)\n- Supabase migration applied successfully\n\nNext: Testing RLS policies and role permissions.\n</info added on 2025-11-11T02:00:19.256Z>",
            "status": "done",
            "testStrategy": "Test RLS policies by creating users with different roles and verifying access to resources. Attempt unauthorized actions to confirm enforcement of restrictions.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement API Key Lifecycle Management with Secure Storage",
            "description": "Develop endpoints and logic for API key creation, rotation, and revocation. Store API keys securely using bcrypt hashing.",
            "dependencies": [
              1
            ],
            "details": "Create endpoints for generating, rotating, and revoking API keys. Store only hashed versions of API keys using bcrypt in the database. Ensure that API keys are associated with users and roles, and that their permissions align with RBAC policies. Document the API key management process and enforce secure handling throughout the lifecycle.\n<info added on 2025-11-11T02:00:28.704Z>\nAPI Key Lifecycle Management Implementation Complete:\n\nAPI Key Generation:\n- Secure random token generation (64 hex chars)\n- Format: emp_[64-char-token]\n- Bcrypt hashing for secure storage\n- Key prefix extraction for fast lookup (emp_xxxxxxxx)\n\nAPI Key Operations Implemented:\n- create_api_key(): Generate new key with role assignment\n- validate_api_key(): Verify key with bcrypt check\n- list_api_keys(): List user's keys (prefix only, no full keys)\n- rotate_api_key(): Create new key, revoke old one atomically\n- revoke_api_key(): Permanently disable key with reason\n\nSecurity Features:\n- Full key shown ONLY once at creation\n- Automatic expiration checking\n- Usage tracking (last_used_at, usage_count)\n- Rate limiting support (rate_limit_per_hour field)\n- Ownership verification for all operations\n\nFiles Created:\n- app/services/rbac_service.py (Complete service implementation)\n- app/routes/rbac.py (FastAPI endpoints)\n- app/middleware/auth.py (Authentication middleware)\n\nIntegration:\n- RBAC router added to main.py at /api/rbac\n- Supports both API key and JWT authentication (JWT stub for future)\n</info added on 2025-11-11T02:00:28.704Z>",
            "status": "done",
            "testStrategy": "Verify API key creation, rotation, and revocation flows. Confirm that only hashed keys are stored and that revoked keys cannot be used for access.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Audit Logging for Access and Key Management Events",
            "description": "Track and log all access events, permission changes, and API key operations for auditing and compliance.",
            "dependencies": [
              1,
              2
            ],
            "details": "Set up audit logging for all RBAC-related actions, including role assignments, permission changes, and API key lifecycle events. Store logs in a dedicated audit table with relevant metadata (user, action, timestamp, resource). Ensure logs are immutable and accessible for compliance reviews.\n<info added on 2025-11-11T02:00:37.494Z>\nCompleted implementation of Audit Logging:\n\n✅ Audit Log Events Tracked:\n- api_key_created: When new key is generated\n- api_key_used: Every time key is validated/used\n- api_key_rotated: When key is rotated\n- api_key_revoked: When key is revoked\n- role_assigned: When role is granted to user\n- role_revoked: When role is removed from user\n\n✅ Audit Log Fields:\n- event_type: Type of event\n- actor_user_id: Who performed the action\n- target_user_id: Who was affected (for role operations)\n- target_resource_type: Type of resource (api_key, user_role)\n- target_resource_id: UUID of affected resource\n- action: Action performed (create, revoke, assign, etc.)\n- result: Outcome (success, failure, denied)\n- ip_address: IP of the request\n- user_agent: User agent string\n- metadata: Additional context (JSON)\n- error_message: Error details if failed\n- created_at: Immutable timestamp\n\n✅ Audit Features:\n- Immutable logs (insert-only, no updates)\n- Automatic logging in all RBAC operations\n- Admin-only access via RLS policies\n- Query filtering by event_type, user_id\n- Pagination support (limit/offset)\n\n✅ API Endpoint:\n- GET /api/rbac/audit-logs (admin only)\n- Supports filtering and pagination\n\nNext: Testing audit log accuracy and RLS enforcement.\n</info added on 2025-11-11T02:00:37.494Z>",
            "status": "done",
            "testStrategy": "Trigger various RBAC and API key events, then review audit logs to confirm accurate and complete recording of all relevant actions.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on role-based access control (rbac) & api key management."
      },
      {
        "id": 32,
        "title": "Bulk Document Management & Batch Operations",
        "description": "Enable bulk upload, delete, reprocessing, metadata update, versioning, and approval workflow for documents.",
        "details": "Implement batch endpoints for document operations. Track progress and support document versioning and approval states.",
        "testStrategy": "Perform bulk operations, verify throughput, versioning, and approval transitions.",
        "priority": "high",
        "dependencies": [
          "31"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Bulk Document Operations Endpoints",
            "description": "Develop RESTful API endpoints to support bulk upload, delete, reprocessing, and metadata update for documents.",
            "dependencies": [],
            "details": "Design and implement backend endpoints that accept batch requests for document operations. Ensure endpoints handle large payloads efficiently, support progress tracking, and provide clear error reporting for partial failures. Integrate with storage and indexing layers to maintain consistency and performance.\n<info added on 2025-11-11T21:02:25.181Z>\n## Investigation Results\n\n**Already Implemented:**\n1. ✅ All 4 bulk operation REST API endpoints in app/routes/documents.py:\n   - POST /bulk-upload\n   - POST /bulk-delete  \n   - POST /bulk-reprocess\n   - PATCH /bulk-metadata\n   - GET /batch-operations/{operation_id}\n   - GET /batch-operations\n\n2. ✅ All 4 Celery tasks in app/tasks/bulk_operations.py:\n   - bulk_upload_documents\n   - bulk_delete_documents\n   - bulk_reprocess_documents\n   - bulk_update_metadata\n   - Includes progress tracking and error handling\n\n**Missing - Need to Implement:**\nThe Celery tasks reference 4 functions from app.services.document_processor that don't exist yet:\n1. ❌ process_document_upload(file_path, filename, metadata, user_id, auto_process)\n2. ❌ delete_document(document_id, user_id, soft_delete)\n3. ❌ reprocess_document(document_id, user_id, force_reparse, update_embeddings, preserve_metadata)\n4. ❌ update_document_metadata(document_id, metadata, user_id)\n\nThe current document_processor.py only contains text extraction/parsing logic, not document management operations.\n\n**Next Steps:**\nNeed to create these 4 document management functions to complete Task 32.1.\n</info added on 2025-11-11T21:02:25.181Z>",
            "status": "done",
            "testStrategy": "Submit bulk operation requests (upload, delete, reprocess, metadata update) with varying batch sizes. Verify throughput, error handling, and data integrity for all operations.",
            "parentId": "undefined",
            "updatedAt": "2025-11-11T03:42:03.083Z"
          },
          {
            "id": 2,
            "title": "Integrate Document Versioning and Approval Workflow",
            "description": "Enable version control and approval states for documents, supporting batch transitions and rollbacks.",
            "dependencies": [
              1
            ],
            "details": "Extend the document model to support version history and approval status. Implement logic for batch versioning (e.g., uploading new versions in bulk) and batch approval/rejection. Ensure audit trails are maintained for all version and approval changes.",
            "status": "done",
            "testStrategy": "Perform bulk version uploads and approval transitions. Verify correct version history, approval state changes, and audit trail entries for all affected documents.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Progress Tracking and Operation Auditing",
            "description": "Track and expose the progress and audit logs of all batch document operations for transparency and compliance.",
            "dependencies": [
              1,
              2
            ],
            "details": "Develop mechanisms to monitor the status of ongoing batch operations, including per-document success/failure. Provide APIs or dashboards for users to query operation progress and review detailed audit logs. Ensure compliance with organizational and regulatory requirements for traceability.\n<info added on 2025-11-11T21:17:31.729Z>\n## Implementation Status: Complete\n\n**Progress Tracking (✅ Complete):**\n1. Models defined in app/models/documents.py:\n   - BatchOperationResponse (lines 92-106) - operation tracking with progress\n   - BatchOperationStatusResponse (lines 108-123) - detailed status with progress_percentage\n\n2. REST API endpoints in app/routes/documents.py:\n   - GET /api/documents/batch-operations/{operation_id} (lines 402-447) - Get specific operation status\n   - GET /api/documents/batch-operations (lines 450-505) - List all operations with filtering, pagination, and progress calculation\n\n3. Real-time progress updates in app/tasks/bulk_operations.py:\n   - _update_operation_status() helper function (lines 551-600)\n   - Called at start, during processing (per-document), and on completion\n   - Tracks: status, processed_items, successful_items, failed_items, results array\n\n**Operation Auditing (✅ Complete):**\n1. Database table: batch_operations (workflows/database_setup.md lines 609-624)\n   - Stores: operation_type, initiated_by, items counts, status, parameters, results\n   - Timestamps: started_at, completed_at, created_at\n   - JSONB fields for detailed parameters and results\n\n2. Approval workflow audit: approval_audit_log table with ApprovalAuditLogEntry model\n   - Tracks all approval state transitions\n   - Includes: event_type, status changes, user, IP address, user agent, timestamps\n\n3. Detailed result tracking:\n   - DocumentOperationResult model (lines 83-90) - per-document status with success/failure/error\n   - Stored in results JSONB array in batch_operations table\n\n**Compliance & Traceability (✅ Complete):**\n- Full audit trail for all batch operations\n- User tracking (initiated_by field)\n- Timestamp tracking (created_at, started_at, completed_at, updated_at)\n- Error message logging\n- Detailed per-document results\n</info added on 2025-11-11T21:17:31.729Z>",
            "status": "done",
            "testStrategy": "Initiate various batch operations and monitor progress tracking endpoints or dashboards. Validate that audit logs accurately reflect all actions, including errors and rollbacks.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on bulk document management & batch operations.",
        "updatedAt": "2025-11-11T03:42:03.083Z"
      },
      {
        "id": 33,
        "title": "User Management & GDPR Compliance",
        "description": "Support user creation, editing, role assignment, password reset, suspension, activity logs, and GDPR-compliant data export.",
        "details": "Implement admin endpoints for user management. Store activity logs and support data export/deletion per GDPR.",
        "testStrategy": "Test user flows, activity logging, and GDPR export/deletion.",
        "priority": "high",
        "dependencies": [
          "32"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement User Account and Role Management Endpoints",
            "description": "Develop admin endpoints to support user creation, editing, role assignment, password reset, and suspension.",
            "dependencies": [],
            "details": "Create RESTful endpoints for user CRUD operations, role assignment, and password management. Ensure endpoints allow for user suspension/reactivation and support both pre-defined and custom roles. Integrate secure authentication and authorization checks for all admin actions.\n<info added on 2025-11-11T21:36:53.612Z>\n## Implementation Details\n\n**Database Schema (Already Implemented)**\n- admin_users table (username, email, password_hash, role, is_active, etc.)\n- admin_sessions table (session tokens)\n- admin_activity_log table (action logging)\n\n**RBAC System (Already Implemented)**\n- API key lifecycle management\n- Role assignment/revocation functionality\n- Audit logging for RBAC events\n- Authentication middleware using API keys and JWT via Clerk\n- Authorization check middleware\n\n**Required User Management Endpoints**\n1. User CRUD operations:\n   - POST /api/users - Create new admin user\n   - GET /api/users - List all users with pagination/filtering\n   - GET /api/users/{user_id} - Retrieve specific user details\n   - PATCH /api/users/{user_id} - Update user information\n   - DELETE /api/users/{user_id} - Delete user account\n\n2. Password management:\n   - POST /api/users/{user_id}/reset-password - Admin-initiated reset\n   - POST /api/users/change-password - Self-service password change\n\n3. Account status management:\n   - POST /api/users/{user_id}/suspend - Suspend user account\n   - POST /api/users/{user_id}/activate - Reactivate suspended account\n\n**Implementation Plan**\n- Create app/routes/users.py with admin user management endpoints\n- Develop app/services/user_service.py for user operations\n- Define app/models/users.py for Pydantic models\n- Utilize bcrypt for password hashing\n- Integrate with admin_activity_log for comprehensive audit trail\n</info added on 2025-11-11T21:36:53.612Z>",
            "status": "done",
            "testStrategy": "Test user creation, editing, role assignment, password reset, and suspension via API and UI. Verify role-based access control and error handling.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Activity Logging for User Actions",
            "description": "Log all significant user management actions (creation, edits, role changes, suspensions, password resets) for audit and compliance.",
            "dependencies": [
              1
            ],
            "details": "Design and implement a logging mechanism to capture all admin and user actions related to user management. Store logs securely with timestamps, user IDs, action types, and relevant metadata. Ensure logs are immutable and accessible for compliance audits.\n<info added on 2025-11-11T21:42:57.585Z>\n## Investigation Status Update\n\nInitial investigation of logging mechanism reveals:\n\n1. Implementation Status:\n   - _log_activity() function is implemented in user_service.py\n   - Function is called by all user management operations\n   - Logs are written to admin_activity_log table\n\n2. Pending Verification:\n   - Database constraints and RLS policies need to be checked to ensure log immutability\n   - No endpoints currently exist for retrieving user activity logs for compliance audits\n\n3. Action Items:\n   - Implement read-only API endpoints for retrieving filtered activity logs\n   - Add database constraints to prevent modification of existing log entries\n   - Document the logging schema and retention policies\n   - Create test cases to verify logging functionality across all user management actions\n</info added on 2025-11-11T21:42:57.585Z>",
            "status": "done",
            "testStrategy": "Trigger user management actions and verify that logs are created with correct details. Test log retrieval and integrity.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop GDPR-Compliant Data Export and Deletion Features",
            "description": "Enable GDPR-compliant export and deletion of user data, including activity logs, upon user or admin request.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement endpoints to export all user-related data in a machine-readable format and to delete user data in accordance with GDPR requirements. Ensure deletion covers user profile, roles, and associated activity logs, and that exports are complete and secure.\n<info added on 2025-11-11T21:46:01.948Z>\n**Requirements Analysis:**\n\n1. Data Export Endpoint (GET /api/users/{user_id}/export):\n   - Export user profile data (username, email, full_name, role, etc.)\n   - Export all activity logs related to user (both as actor and subject)\n   - Export user sessions history\n   - Export API keys (without sensitive key material)\n   - Export user roles and permissions\n   - Format: JSON (machine-readable)\n   - Admin-only access\n\n2. Data Deletion Endpoint (DELETE /api/users/{user_id}/gdpr-delete):\n   - Delete user profile from admin_users table\n   - Delete/anonymize activity logs (preserve audit trail but remove PII)\n   - Delete all user sessions from admin_sessions table\n   - Revoke all user API keys\n   - Delete user role assignments\n   - Cascade deletion with proper foreign key handling\n   - Admin-only access with confirmation required\n\n**Implementation Plan:**\n- Add export_user_data() method to UserService\n- Add gdpr_delete_user() method to UserService\n- Add GDPR export/delete endpoints to users router\n- Add Pydantic models for export response\n- Consider: Activity logs should be anonymized rather than deleted for audit compliance\n</info added on 2025-11-11T21:46:01.948Z>",
            "status": "done",
            "testStrategy": "Request data export and deletion for test users. Verify completeness of exported data and confirm all user data is removed after deletion, including logs.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on user management & gdpr compliance."
      },
      {
        "id": 34,
        "title": "Analytics Dashboard Implementation",
        "description": "Build dashboard for document stats, query metrics, user activity, storage usage, and API endpoint usage.",
        "details": "Use Grafana or Streamlit for dashboard UI. Aggregate metrics from Supabase and Prometheus.",
        "testStrategy": "Verify dashboard accuracy and responsiveness under load.",
        "priority": "medium",
        "dependencies": [
          "33"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Dashboard UI with Grafana or Streamlit",
            "description": "Set up the dashboard user interface using either Grafana or Streamlit, ensuring a logical layout for document stats, query metrics, user activity, storage usage, and API endpoint usage.",
            "dependencies": [],
            "details": "Install and configure Grafana or Streamlit. Design the dashboard structure, applying best practices such as focusing on key metrics, using consistent layouts, and providing clear panel documentation. Ensure the UI is intuitive and supports dynamic filtering or variable selection as needed.\n<info added on 2025-11-11T21:54:47.058Z>\nBased on the investigation findings, we will implement the analytics dashboard using Grafana since an existing infrastructure pattern is already established. We'll create a comprehensive dashboard with five main panel categories: document statistics, query metrics, user activity, storage usage, and API endpoint usage.\n\nThe implementation will follow this approach:\n1. Create a dedicated metrics service in app/services/metrics_service.py to collect and organize analytics data\n2. Add a Prometheus metrics endpoint in app/routes/monitoring.py to expose metrics for Grafana consumption\n3. Develop a Grafana dashboard JSON configuration at monitoring/grafana/dashboards/empire_analytics.json\n4. Follow the established pattern from the existing ragas_metrics.json dashboard for consistency\n\nThe dashboard will leverage the existing Grafana infrastructure while providing comprehensive visibility into system performance and usage patterns across all key operational areas.\n</info added on 2025-11-11T21:54:47.058Z>",
            "status": "done",
            "testStrategy": "Verify that all required metric categories are represented and the UI is navigable. Check for adherence to dashboard design best practices.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Aggregate Metrics from Supabase and Prometheus",
            "description": "Implement data aggregation logic to collect and preprocess metrics from Supabase and Prometheus for use in the dashboard.",
            "dependencies": [
              1
            ],
            "details": "Develop scripts or queries to extract relevant metrics (document stats, query metrics, user activity, storage usage, API endpoint usage) from Supabase and Prometheus. Transform and aggregate data as needed for efficient dashboard consumption. Ensure data freshness and reliability.",
            "status": "done",
            "testStrategy": "Validate that all required metrics are accurately aggregated and available for the dashboard. Test with sample data and edge cases.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Data Visualization Components",
            "description": "Create and configure visualizations for each metric category, ensuring clarity and actionable insights.",
            "dependencies": [
              2
            ],
            "details": "Select appropriate visualization types (e.g., graphs, tables, gauges) for each metric. Configure panels to highlight key signals and trends. Apply consistent color schemes and labeling. Add annotations or context where relevant to aid interpretation.",
            "status": "done",
            "testStrategy": "Review each visualization for accuracy, clarity, and alignment with dashboard goals. Solicit feedback from stakeholders and iterate as needed.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Test Dashboard Load and Responsiveness",
            "description": "Evaluate dashboard performance under expected and peak loads, optimizing for fast load times and responsive interactions.",
            "dependencies": [
              3
            ],
            "details": "Simulate concurrent users and high data volumes. Monitor dashboard load times, panel refresh rates, and responsiveness. Apply optimizations such as query aggregation, efficient variable usage, and appropriate refresh intervals. Document and address any bottlenecks.",
            "status": "done",
            "testStrategy": "Run load tests and measure key performance indicators (KPIs) such as load time and refresh latency. Confirm dashboard remains usable and responsive under stress.",
            "parentId": "undefined"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 4,
        "expansionPrompt": "Break down analytics dashboard implementation into subtasks for dashboard UI development (Grafana/Streamlit), metrics aggregation from Supabase/Prometheus, data visualization, and load/responsiveness testing."
      },
      {
        "id": 35,
        "title": "CrewAI Multi-Agent Integration & Orchestration",
        "description": "Integrate CrewAI service (REST API) for multi-agent workflows, agent management, and orchestration.",
        "details": "Connect to CrewAI REST API (srv-d2n0hh3uibrs73buafo0). Implement agent pool management, dynamic agent creation, lifecycle, and resource allocation. Support async task execution via Celery.",
        "testStrategy": "Run multi-agent workflows, verify orchestration, agent lifecycle, and result aggregation.",
        "priority": "high",
        "dependencies": [
          "34"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Integrate CrewAI REST API for Agent Pool Management and Dynamic Agent Creation",
            "description": "Connect to the CrewAI REST API and implement logic for managing an agent pool, including dynamic creation, configuration, and lifecycle management of agents.",
            "dependencies": [],
            "details": "Establish secure connectivity to the CrewAI REST API (srv-d2n0hh3uibrs73buafo0). Implement endpoints and logic for creating, updating, and deleting agents dynamically. Support agent configuration (roles, goals, tools, memory, etc.) as per CrewAI's agent model. Ensure agents can be instantiated with custom parameters and maintain their lifecycle state.\n<info added on 2025-11-12T02:56:38.121Z>\nBased on the investigation, I'll enhance the CrewAI integration by implementing the following:\n\n1. Extend the existing crewai_service.py with comprehensive agent pool management methods:\n   - Agent CRUD operations: create_agent(), update_agent(), delete_agent(), get_agent(), get_agents()\n   - Crew management functions: create_crew(), update_crew(), delete_crew(), get_crew(), get_crews()\n   - Resource monitoring via get_agent_pool_stats() to track agent utilization and availability\n\n2. Implement Supabase database integration for the existing schema (crewai_agents, crewai_crews, crewai_task_templates, crewai_executions) to ensure persistent storage of agent configurations and execution history.\n\n3. Develop agent lifecycle management functionality including activation, deactivation, and status tracking.\n\n4. Create REST API routes in app/routes/crewai.py exposing agent and crew management endpoints.\n\n5. Connect with the existing CrewAI REST API at https://jb-crewai.onrender.com for agent execution and orchestration.\n</info added on 2025-11-12T02:56:38.121Z>",
            "status": "done",
            "testStrategy": "Create, update, and delete agents via API calls. Verify agent state transitions and configuration persistence.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Multi-Agent Workflow Orchestration and Resource Allocation",
            "description": "Develop orchestration logic to coordinate multi-agent workflows, manage task assignments, and allocate resources efficiently among agents.",
            "dependencies": [
              1
            ],
            "details": "Design and implement orchestration mechanisms using CrewAI's crew-and-flow model. Enable both sequential and parallel task execution modes. Assign tasks to agents based on their roles and goals, and manage dependencies between tasks. Implement resource allocation strategies to optimize agent utilization and prevent overload.",
            "status": "done",
            "testStrategy": "Run sample multi-agent workflows with varying complexity. Verify correct task sequencing, parallelism, and resource allocation.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Enable Asynchronous Task Execution and Monitoring via Celery",
            "description": "Integrate Celery to support asynchronous execution of agent tasks and implement monitoring for workflow progress and agent states.",
            "dependencies": [
              2
            ],
            "details": "Set up Celery workers to handle asynchronous task execution for CrewAI workflows. Ensure tasks can be queued, executed, and monitored independently. Capture logs and state changes for each agent and workflow. Implement error handling and alerting for failed tasks or agent exceptions.",
            "status": "done",
            "testStrategy": "Submit multiple concurrent workflows, monitor execution progress, and verify correct handling of asynchronous tasks and error scenarios.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on crewai multi-agent integration & orchestration."
      },
      {
        "id": 36,
        "title": "CrewAI Asset Generation Agents Implementation",
        "description": "Implement 8 asset generation agents (orchestrator, summarizer, skill, command, agent, prompt, workflow, department classifier) per PRD specs.",
        "details": "Define agent roles, goals, tools, and LLM configs in crewai_agents table. Integrate with CrewAI API for asset generation. Store outputs in B2 processed/ folders.",
        "testStrategy": "Trigger asset generation for sample documents, verify output formats and B2 storage.",
        "priority": "high",
        "dependencies": [
          "35"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define and Configure 8 Asset Generation Agents in crewai_agents Table",
            "description": "Specify roles, goals, tools, and LLM configurations for orchestrator, summarizer, skill, command, agent, prompt, workflow, and department classifier agents as per PRD specifications.",
            "dependencies": [],
            "details": "Draft detailed agent definitions in the crewai_agents table, ensuring each agent's role, goal, toolset, and LLM configuration aligns with PRD requirements. Use YAML or database schema as appropriate. Validate configuration completeness for all 8 agents.",
            "status": "done",
            "testStrategy": "Review crewai_agents table for correct entries and completeness. Validate agent configs load without errors in CrewAI.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Agents with CrewAI API for Asset Generation Workflows",
            "description": "Connect the configured agents to the CrewAI API, enabling them to generate assets according to workflow requirements.",
            "dependencies": [
              1
            ],
            "details": "Implement integration logic to instantiate and orchestrate the 8 agents using the CrewAI API. Ensure agents can receive tasks, execute asset generation, and interact as needed. Handle API authentication and error management.",
            "status": "done",
            "testStrategy": "Trigger asset generation for sample inputs via CrewAI API and verify that each agent performs its designated function.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Store Generated Assets in B2 Processed Folders",
            "description": "Implement logic to save all outputs from asset generation agents into the appropriate B2 processed/ folders.",
            "dependencies": [
              2
            ],
            "details": "Develop or update storage routines to ensure all generated assets are saved in the correct B2 processed/ directory structure. Confirm metadata and output formats match requirements. Handle storage errors and ensure data integrity.",
            "status": "done",
            "testStrategy": "Generate assets through the workflow and verify their presence, structure, and metadata in B2 processed/ folders.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on crewai asset generation agents implementation."
      },
      {
        "id": 37,
        "title": "CrewAI Document Analysis Agents Implementation",
        "description": "Implement 3 document analysis agents (research analyst, content strategist, fact checker) for structured analysis and verification.",
        "details": "Configure agents in crewai_agents table. Integrate with CrewAI API for analysis workflows. Store analysis outputs in Supabase and B2.",
        "testStrategy": "Run analysis workflows, verify structured outputs and fact verification accuracy.",
        "priority": "high",
        "dependencies": [
          "36"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Document Analysis Agents in crewai_agents Table",
            "description": "Define and register the three specialized agents (research analyst, content strategist, fact checker) in the crewai_agents table with appropriate roles, goals, and capabilities.",
            "dependencies": [],
            "details": "Specify agent roles, goals, and backstories in the crewai_agents table or agents.yaml. Ensure each agent is configured for its analysis specialization and can be referenced by workflows. Use CrewAI's agent configuration standards for compatibility.",
            "status": "done",
            "testStrategy": "Verify agents appear in the crewai_agents table and can be instantiated by CrewAI workflows.",
            "parentId": "undefined",
            "updatedAt": "2025-11-14T18:18:43.346Z"
          },
          {
            "id": 2,
            "title": "Integrate Agents with CrewAI API for Analysis Workflows",
            "description": "Connect the configured agents to the CrewAI API, enabling them to participate in document analysis workflows.",
            "dependencies": [
              1
            ],
            "details": "Implement API integration logic to allow the agents to receive tasks, process documents, and return structured outputs. Ensure agents can be triggered via the CrewAI API and handle input/output formats as required by the workflow.",
            "status": "done",
            "testStrategy": "Trigger sample analysis workflows via the API and confirm agents process and return structured results.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Document Analysis Workflow Execution",
            "description": "Design and execute workflows that coordinate the three agents for structured document analysis and verification.",
            "dependencies": [
              2
            ],
            "details": "Define workflow logic that assigns documents to the appropriate agents, sequences their tasks (e.g., research, content strategy, fact checking), and aggregates their outputs. Use CrewAI's workflow orchestration features to manage task flow.",
            "status": "done",
            "testStrategy": "Run end-to-end workflow executions and verify that each agent performs its designated analysis step.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Store Analysis Outputs in Supabase and B2",
            "description": "Persist the structured outputs from each agent in Supabase for structured data and B2 for file storage.",
            "dependencies": [
              3
            ],
            "details": "Implement logic to map agent outputs to Supabase tables for structured results and upload any relevant files or artifacts to B2. Ensure outputs are linked to the correct document and agent metadata.",
            "status": "done",
            "testStrategy": "Check Supabase and B2 for correct storage of outputs after workflow execution; verify data integrity and retrievability.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Test and Validate Agent Output Accuracy and Fact Verification",
            "description": "Systematically test the accuracy of agent outputs, with a focus on fact-checking reliability and structured result formats.",
            "dependencies": [
              4
            ],
            "details": "Develop test cases with known document inputs and expected outputs. Evaluate the correctness of research, content strategy, and fact-checking results. Measure fact-checker precision and recall, and validate output structure.",
            "status": "done",
            "testStrategy": "Run automated and manual tests comparing outputs to ground truth; review fact-checking results for accuracy and completeness.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Break down document analysis agent implementation into subtasks for agent configuration, CrewAI API integration, workflow execution, output storage in Supabase/B2, and accuracy testing.",
        "updatedAt": "2025-11-14T18:18:43.346Z"
      },
      {
        "id": 38,
        "title": "CrewAI Multi-Agent Orchestration Agents Implementation",
        "description": "Implement 4 orchestration agents (research, analysis, writing, review) for complex multi-document workflows.",
        "details": "Configure agents and crews in crewai_crews table. Support sequential and parallel execution modes. Integrate with CrewAI API for orchestration.",
        "testStrategy": "Run multi-agent orchestration workflows, verify execution order and output quality.",
        "priority": "high",
        "dependencies": [
          "37"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure Orchestration Agents and Crews in crewai_crews Table",
            "description": "Define and register the four orchestration agents (research, analysis, writing, review) and their crew configurations in the crewai_crews table.",
            "dependencies": [],
            "details": "Specify agent roles, goals, backstories, and advanced options (e.g., LLM, delegation, tools) for each agent. Ensure each agent is correctly mapped to its crew and that the crew structure supports both sequential and parallel execution modes.",
            "status": "done",
            "testStrategy": "Verify agents and crews are correctly listed in the crewai_crews table and can be retrieved via API.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Sequential and Parallel Execution Logic for Agent Workflows",
            "description": "Develop logic to support both sequential and parallel execution of agent tasks within a crew for multi-document workflows.",
            "dependencies": [
              1
            ],
            "details": "Design execution engine to trigger agents in order (sequential) or concurrently (parallel) based on workflow configuration. Ensure correct handling of dependencies and data flow between agents.",
            "status": "done",
            "testStrategy": "Run sample workflows in both modes, confirm correct execution order and data handoff.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate CrewAI API for Orchestration and Agent Lifecycle Management",
            "description": "Connect orchestration logic to CrewAI API endpoints for agent invocation, status tracking, and result retrieval.",
            "dependencies": [
              2
            ],
            "details": "Implement API calls for agent task submission, monitor agent progress, and handle callbacks or polling for completion. Ensure robust error handling and retries.",
            "status": "done",
            "testStrategy": "Trigger agent workflows via API, verify correct agent lifecycle events and result collection.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Develop Workflow Management and State Tracking Mechanisms",
            "description": "Create workflow management logic to track the state, progress, and dependencies of multi-agent, multi-document workflows.",
            "dependencies": [
              3
            ],
            "details": "Implement state machine or workflow tracker to monitor each agent's status, handle transitions, and manage workflow metadata. Support resumption and recovery from failures.",
            "status": "done",
            "testStrategy": "Simulate workflow interruptions and restarts, verify accurate state tracking and recovery.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Output Validation and Quality Assurance for Agent Results",
            "description": "Design and apply validation checks to ensure agent outputs meet expected quality, format, and completeness standards.",
            "dependencies": [
              4
            ],
            "details": "Define validation rules for each agent type (e.g., research completeness, analysis accuracy, writing coherence, review thoroughness). Integrate automated and optional human-in-the-loop checks.",
            "status": "done",
            "testStrategy": "Run workflows with known-good and intentionally flawed inputs, verify validation catches errors and approves correct outputs.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Develop and Execute Comprehensive Orchestration Testing Suite",
            "description": "Create automated tests to validate orchestration logic, agent integration, workflow management, and output quality across various scenarios.",
            "dependencies": [
              5
            ],
            "details": "Design test cases for sequential and parallel workflows, error handling, state recovery, and output validation. Use both unit and integration tests to ensure system robustness.",
            "status": "done",
            "testStrategy": "Run full test suite, confirm all orchestration paths and edge cases are covered and pass.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Expand orchestration agent implementation into subtasks for agent/crew configuration, sequential/parallel execution logic, CrewAI API integration, workflow management, output validation, and orchestration testing."
      },
      {
        "id": 39,
        "title": "CrewAI Inter-Agent Messaging & Collaboration",
        "description": "Enable inter-agent messaging, task delegation, result sharing, and conflict resolution within CrewAI workflows.",
        "details": "Implement agent interactions in crewai_agent_interactions table. Support direct/broadcast messaging, event publication, and state synchronization.",
        "testStrategy": "Simulate collaborative workflows, verify messaging, delegation, and result aggregation.",
        "priority": "high",
        "dependencies": [
          "38"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Inter-Agent Interaction Schema",
            "description": "Define the database schema and data model for agent interactions, supporting messaging, delegation, event publication, and state synchronization.",
            "dependencies": [],
            "details": "Create or update the crewai_agent_interactions table to capture direct/broadcast messages, event logs, delegation records, and state changes. Ensure extensibility for future collaboration features.",
            "status": "done",
            "testStrategy": "Review schema against requirements; validate with sample interaction records.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Direct and Broadcast Messaging Logic",
            "description": "Develop backend logic for agents to send direct and broadcast messages to other agents within a crew.",
            "dependencies": [
              1
            ],
            "details": "Implement API endpoints and internal functions for direct (agent-to-agent) and broadcast (agent-to-crew) messaging. Store messages in the interaction table and trigger notifications as needed.",
            "status": "done",
            "testStrategy": "Unit test message delivery, verify correct routing and storage for both direct and broadcast cases.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop Event Publication Mechanism",
            "description": "Enable agents to publish events (e.g., task completion, delegation, errors) for workflow coordination and monitoring.",
            "dependencies": [
              1
            ],
            "details": "Implement event publishing logic, allowing agents to emit structured events to the crewai_agent_interactions table. Support event subscription and notification for relevant agents.",
            "status": "done",
            "testStrategy": "Simulate event publication and subscription; verify event propagation and logging.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement State Synchronization Across Agents",
            "description": "Ensure agents maintain consistent shared state during collaborative workflows, including task progress and result sharing.",
            "dependencies": [
              1
            ],
            "details": "Design and implement mechanisms for agents to synchronize state changes (e.g., task status, shared data) via the interaction table or dedicated state sync service. Handle concurrent updates and conflict scenarios.",
            "status": "done",
            "testStrategy": "Test state updates under concurrent agent actions; verify consistency and conflict handling.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Integrate Conflict Resolution Logic",
            "description": "Develop logic for detecting and resolving conflicts between agents, such as task assignment disputes or inconsistent states.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Implement automated and/or human-in-the-loop conflict resolution workflows. Log conflict events, trigger resolution protocols, and update agent states accordingly.",
            "status": "done",
            "testStrategy": "Simulate conflict scenarios; verify detection, resolution, and state updates.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Simulate and Test Collaborative Workflow Scenarios",
            "description": "Create and execute end-to-end workflow simulations to validate inter-agent messaging, delegation, event handling, state sync, and conflict resolution.",
            "dependencies": [
              2,
              3,
              4,
              5
            ],
            "details": "Design test scenarios covering typical and edge-case collaborative workflows. Automate simulation runs and verify expected outcomes in the interaction table and agent states.",
            "status": "done",
            "testStrategy": "Run integration tests for full workflows; check messaging, event logs, state consistency, and conflict resolution.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8.5,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Break down inter-agent messaging and collaboration into subtasks for designing the interaction schema, implementing direct/broadcast messaging, event publication, state synchronization, conflict resolution, and workflow simulation testing."
      },
      {
        "id": 40,
        "title": "CrewAI Asset Storage & Retrieval",
        "description": "Store generated assets in crewai_generated_assets table and B2, enable retrieval by department, type, and confidence.",
        "details": "Implement asset storage logic, organize B2 folders, and support asset retrieval APIs. Track confidence scores and metadata.",
        "testStrategy": "Generate and retrieve assets, verify storage, organization, and retrieval accuracy.",
        "priority": "high",
        "dependencies": [
          "39"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Asset Storage Logic in crewai_generated_assets Table and B2",
            "description": "Design and implement the logic to store generated assets in the crewai_generated_assets database table and organize them in B2 cloud storage.",
            "dependencies": [],
            "details": "Define the schema for asset metadata, including department, type, and confidence score. Integrate asset generation outputs with the database and B2 storage. Ensure assets are stored in organized B2 folders based on department and type, and metadata is consistently tracked in the database.\n<info added on 2025-11-13T20:40:40.237Z>\nIMPLEMENTATION COMPLETE (2025-01-13):\n\n✅ Database Schema:\n- crewai_generated_assets table created in Supabase production\n- All columns implemented: id, execution_id, document_id, department, asset_type, asset_name, content, content_format, b2_path, file_size, mime_type, metadata, confidence_score, created_at\n- Foreign keys configured: execution_id → crewai_executions, document_id → documents\n\n✅ Service Implementation:\n- app/services/crewai_asset_service.py (324 lines)\n- store_asset() method handles both text-based and file-based assets\n- Text assets: stored in DB content column\n- File assets: uploaded to B2, b2_path stored in DB\n- B2 folder organization: crewai/assets/{department}/{asset_type}/{execution_id}/{filename}\n\n✅ Pydantic Models:\n- app/models/crewai_asset.py (173 lines)\n- AssetStorageRequest, AssetResponse, AssetUpdateRequest, AssetListResponse, AssetRetrievalFilters\n- Enums: AssetType, Department, ContentFormat\n\nStatus: READY FOR TESTING\n</info added on 2025-11-13T20:40:40.237Z>",
            "status": "done",
            "testStrategy": "Create sample assets, store them, and verify correct database entries and B2 folder organization.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop Asset Retrieval APIs by Department, Type, and Confidence",
            "description": "Build APIs to enable retrieval of stored assets filtered by department, asset type, and confidence score.",
            "dependencies": [
              1
            ],
            "details": "Design RESTful endpoints for asset retrieval. Implement query logic to filter assets using department, type, and confidence score from the crewai_generated_assets table and B2 storage. Ensure efficient and secure access to asset files and metadata.\n<info added on 2025-11-13T20:41:13.454Z>\nIMPLEMENTATION COMPLETE (2025-01-13):\n\n✅ API Routes Implemented:\n- app/routes/crewai_assets.py (284 lines)\n- Router prefix: /api/crewai/assets\n- Tags: [\"CrewAI Assets\"]\n\n✅ Endpoints:\n1. POST /api/crewai/assets/ - Store asset (text or file-based)\n2. GET /api/crewai/assets/ - Retrieve with filters (department, asset_type, confidence, pagination)\n3. GET /api/crewai/assets/{asset_id} - Get single asset by ID\n4. PATCH /api/crewai/assets/{asset_id} - Update confidence score and metadata\n5. GET /api/crewai/assets/execution/{execution_id} - Get all assets for execution\n\n✅ Filter Implementation:\n- execution_id (UUID)\n- department (enum: marketing, legal, hr, finance, etc.)\n- asset_type (enum: summary, analysis, report, etc.)\n- min_confidence / max_confidence (0-1)\n- limit (max 1000)\n- offset (pagination)\n\n✅ Service Integration:\n- Uses CrewAIAssetService via dependency injection\n- Full error handling (400, 404, 500)\n- Logging for all operations\n\nStatus: IMPLEMENTATION COMPLETE - Need to verify route registration in main.py\n</info added on 2025-11-13T20:41:13.454Z>",
            "status": "done",
            "testStrategy": "Test API endpoints with various filter combinations and validate that correct assets and metadata are returned.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Track and Update Asset Confidence Scores and Metadata",
            "description": "Implement mechanisms to track, update, and manage confidence scores and metadata for each asset throughout its lifecycle.",
            "dependencies": [
              1
            ],
            "details": "Add logic to update confidence scores and metadata in the crewai_generated_assets table as assets are processed or reviewed. Ensure changes are reflected in both the database and B2 storage organization if relevant. Provide audit trails for metadata updates.\n<info added on 2025-11-13T20:41:18.472Z>\nIMPLEMENTATION COMPLETE (2025-01-13):\n\n✅ Confidence Score Tracking:\n- Database column: confidence_score (float, nullable)\n- Validation: 0.0 - 1.0 range enforced in Pydantic models\n- Initial score set during asset creation\n- Update via PATCH /api/crewai/assets/{asset_id}\n\n✅ Metadata Management:\n- Database column: metadata (JSONB, default {})\n- Stored in Supabase as structured JSON\n- Full flexibility for custom metadata fields\n- MERGE behavior: new metadata merged with existing (preserves existing keys)\n- Update via AssetUpdateRequest model\n\n✅ Update Method (app/services/crewai_asset_service.py):\n- update_asset(asset_id, update_request)\n- Fetches existing asset\n- Merges metadata: {**existing.metadata, **update.metadata}\n- Updates confidence_score if provided\n- Returns updated AssetResponse\n\n✅ API Endpoint:\n- PATCH /api/crewai/assets/{asset_id}\n- Request: {confidence_score?: float, metadata?: dict}\n- Response: Updated AssetResponse\n- Errors: 404 (not found), 400 (invalid), 500 (server error)\n\nStatus: READY FOR TESTING\n</info added on 2025-11-13T20:41:18.472Z>",
            "status": "done",
            "testStrategy": "Simulate asset review and update workflows, verify that confidence scores and metadata are correctly updated and tracked.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on crewai asset storage & retrieval."
      },
      {
        "id": 41,
        "title": "Security Hardening & Compliance",
        "description": "Implement JWT authentication, RBAC, encrypted storage, input validation, and compliance features (GDPR, HIPAA, SOC 2).",
        "details": "Use PyJWT for authentication, enforce RBAC, encrypt Supabase volumes and B2 files, validate inputs, and implement audit trails. Support data export/deletion for GDPR.",
        "testStrategy": "Run security tests, penetration testing, and compliance checks.",
        "priority": "high",
        "dependencies": [
          "40"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement JWT Authentication with PyJWT",
            "description": "Set up secure JWT authentication using PyJWT, ensuring best practices for token issuance, validation, and storage.",
            "dependencies": [],
            "details": "Configure PyJWT to use strong signing algorithms (e.g., RS256), set short expiration times, validate all claims (issuer, audience, expiration), and store tokens securely (prefer HttpOnly cookies). Avoid storing sensitive data in JWTs and ensure all token transmission uses HTTPS.\n<info added on 2025-11-14T19:10:23.776Z>\n## Current Status\nJWT authentication implemented via Clerk integration (app/middleware/clerk_auth.py) with session token verification working.\n\n## Required Security Enhancements\n1. Add rate limiting to authentication endpoints using slowapi library\n2. Implement token refresh endpoint with refresh token rotation\n3. Add session timeout middleware with both idle and absolute timeout enforcement\n4. Ensure HTTPS-only transmission in production environment\n\n## Implementation Files\n- Existing: app/middleware/clerk_auth.py (JWT verification)\n- Existing: app/middleware/auth.py (JWT/API key validation)\n- New: app/middleware/rate_limit.py (for API rate limiting)\n- New: app/routes/auth.py (token refresh endpoint)\n\n## Security Assessment\nAuthentication foundation is solid. Focus should be on hardening through rate limiting and robust session management.\n</info added on 2025-11-14T19:10:23.776Z>\n<info added on 2025-11-14T19:38:41.247Z>\n## Implementation Complete\n\nSecurity hardening implementation for JWT authentication has been successfully completed with the following components:\n\n### Rate Limiting\n- Implemented using slowapi>=0.1.9\n- Created app/middleware/rate_limit.py with tiered limits:\n  - Auth endpoints: 5 login attempts/minute, 3 registrations/hour\n  - API key management: 10 creates/hour, 20 revocations/minute\n  - File uploads: 50/hour for single, 10/hour for bulk\n  - Query endpoints: 100/minute for simple, 20/minute for complex\n- Uses Redis in production, in-memory storage in development\n- Per-user and per-IP rate limiting with proper headers\n\n### Security Headers Middleware\n- Created app/middleware/security.py with SecurityHeadersMiddleware\n- Implemented headers: HSTS, X-Content-Type-Options, X-Frame-Options, X-XSS-Protection, Referrer-Policy, Permissions-Policy, and Content-Security-Policy\n- Environment-specific configurations with relaxed settings for documentation endpoints\n\n### CORS Hardening\n- Updated configuration in app/main.py with explicit HTTP methods\n- Environment-based configuration with production warnings\n\n### Testing\n- Created comprehensive test_task41_security.py (320 lines)\n- Tests for headers, rate limiting, CORS, and overall API health\n\n### Files Modified/Created\n- requirements.txt: Added slowapi and redis\n- app/middleware/security.py: NEW (180 lines)\n- app/middleware/rate_limit.py: NEW (260 lines)\n- app/main.py: MODIFIED\n- test_task41_security.py: NEW (320 lines)\n\n### Security Improvements\n- Protection against brute force, clickjacking, MIME sniffing, XSS\n- HTTPS enforcement in production\n- Information disclosure prevention\n- DoS protection through rate limiting\n</info added on 2025-11-14T19:38:41.247Z>",
            "status": "done",
            "testStrategy": "Unit test token issuance and validation, attempt token tampering, and verify rejection of invalid or expired tokens.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enforce Role-Based Access Control (RBAC)",
            "description": "Integrate RBAC to restrict access to resources based on user roles and permissions.",
            "dependencies": [
              1
            ],
            "details": "Design a roles and permissions schema. Implement middleware to check user roles (from identity, not from JWT claims) on each protected endpoint. Ensure permissions are managed in the authorization layer, not embedded in JWTs.\n<info added on 2025-11-14T19:10:28.200Z>\n## Current Status\nRBAC fully implemented with 4 roles (admin, editor, viewer, guest). Complete lifecycle management in app/services/rbac_service.py. Database tables exist (users, roles, user_roles, api_keys).\n\n## Implementation Details\n- Role permission checking: app/middleware/auth.py:require_admin(), require_role()\n- API key lifecycle: generation, rotation, revocation, expiration\n- Bcrypt hashing for API keys (never stores plaintext)\n- Database schema ready in Supabase\n\n## Additional Work Needed\n- Row-Level Security (RLS) policies on all user-facing tables (CRITICAL)\n- API key scope validation (scopes field exists but not enforced)\n- Permission cache invalidation for role updates\n\n## Focus Areas\n1. Design and implement PostgreSQL RLS policies for data isolation\n2. Add scope validation middleware for API keys\n3. Test user data isolation at database level\n\n## Security Assessment\nAuthorization system is production-ready. Main gap is RLS enforcement.\n</info added on 2025-11-14T19:10:28.200Z>",
            "status": "done",
            "testStrategy": "Test endpoints with users of different roles, verify access is correctly granted or denied according to RBAC rules.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Set Up Encrypted Storage for Supabase and B2 Files",
            "description": "Encrypt all data at rest in Supabase volumes and Backblaze B2 file storage.",
            "dependencies": [],
            "details": "Enable encryption for Supabase storage volumes and configure server-side encryption for B2 buckets. Ensure encryption keys are securely managed and rotated according to policy.\n<info added on 2025-11-14T19:10:32.282Z>\n## Current Status\nFile encryption implementation is EXCELLENT with AES-256-GCM in app/services/encryption.py featuring:\n- 256-bit keys with PBKDF2 (100k iterations)\n- Random salts and nonces per file\n- Authenticated encryption with GCM mode\n- B2 integration ready\n- Test coverage in tests/test_encryption.py\n\n## Additional Work Needed\n- Verify Supabase encryption-at-rest is enabled\n- Confirm TLS for all database connections (Neo4j already using TLS with bolt+ssc://localhost:7687)\n- Add key rotation policies\n- Optional: Integrate with AWS KMS or HashiCorp Vault for key management\n\n## Verification Tasks\n1. Check Supabase project settings for encryption-at-rest\n2. Verify B2 server-side encryption configuration\n3. Document encryption key management procedures\n4. Test file encryption/decryption with B2 upload\n\n## Security Assessment\nEncryption implementation is production-grade. Focus should be on verification and key management procedures.\n</info added on 2025-11-14T19:10:32.282Z>",
            "status": "done",
            "testStrategy": "Verify files and database volumes are encrypted at rest, attempt unauthorized access to raw storage, and confirm data is unreadable without decryption keys.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement Comprehensive Input Validation",
            "description": "Validate all user and API inputs to prevent injection and data integrity issues.",
            "dependencies": [],
            "details": "Apply strict input validation on all endpoints using whitelisting and schema validation. Sanitize inputs to prevent SQL injection, XSS, and other common attacks. Use libraries for validation where possible.\n<info added on 2025-11-14T19:10:37.398Z>\n## Current Status\nInput validation implementation is GOOD. Pydantic models are used throughout the codebase (7 model files) with:\n- Type hints and Field() constraints\n- File upload validation (whitelist, 100MB limit, 10 files max)\n- Email validation with EmailStr\n- Custom validators for key fields\n\n## Files With Validation\n- app/models/rbac.py (RBAC validation)\n- app/models/documents.py (document validation)\n- app/models/users.py (user validation)\n- app/api/upload.py (file upload validation)\n\n## Additional Work Needed\n- Request body size limits middleware (prevent DoS)\n- Custom validators for SQL injection prevention\n- Path traversal validation (no ../, null bytes)\n- XSS prevention in metadata fields\n- Rate limiting on all API endpoints\n\n## Hardening Tasks\n1. Add max_body_size middleware\n2. Create security validators for:\n   - Document paths\n   - Query parameters\n   - Metadata values\n3. Audit all database queries for parameterization\n4. Add input sanitization for user-generated content\n\n## Security Assessment\nValidation foundation is solid. Need additional hardening for edge cases.\n</info added on 2025-11-14T19:10:37.398Z>",
            "status": "done",
            "testStrategy": "Fuzz endpoints with invalid and malicious inputs, verify that invalid data is rejected and no vulnerabilities are introduced.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Audit Trail and Logging",
            "description": "Create an audit trail system to log security-relevant events and user actions for compliance and forensic analysis.",
            "dependencies": [
              1,
              2
            ],
            "details": "Log authentication events, access control decisions, data exports/deletions, and administrative actions. Ensure logs are tamper-evident and securely stored. Provide tools for querying and exporting audit logs.\n<info added on 2025-11-14T19:10:44.198Z>\n## Current Status\nAudit logging partially implemented with structlog throughout the application. AuditLogEntry model defined in app/models/rbac.py with all required fields (event_type, actor, target, IP, user_agent, metadata).\n\n## Events Currently Logged\n- Authentication attempts (success/failure)\n- API key creation/rotation/revocation\n- Role assignments\n- Access denials\n\n## Critical Gap\nLogs are only stored in application logs, not persisted to database, preventing querying for compliance or incident investigation purposes.\n\n## Implementation Plan\n1. Create audit_logs table in Supabase with AuditLogEntry schema\n2. Create app/middleware/audit.py to persist all security events\n3. Add audit log query/search endpoints in app/routes/audit.py\n4. Implement log retention policies (90 days active, 7 years archive)\n5. Extract IP address and User-Agent from requests\n6. Make logs tamper-evident (append-only, signed)\n\n## Database Schema\n- Table: audit_logs\n- Columns: id, event_type, actor_user_id, target_user_id, target_resource_type, target_resource_id, action, result, ip_address, user_agent, metadata (JSONB), error_message, created_at\n\n## Security Assessment\nFoundation exists but high priority to persist logs to database for compliance and security investigation capabilities.\n</info added on 2025-11-14T19:10:44.198Z>",
            "status": "done",
            "testStrategy": "Trigger various security events, verify logs are generated, immutable, and contain all required information.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Integrate Compliance Features (GDPR, HIPAA, SOC 2)",
            "description": "Implement features to meet GDPR, HIPAA, and SOC 2 requirements, including data export/deletion and privacy controls.",
            "dependencies": [
              3,
              4,
              5
            ],
            "details": "Support user data export and deletion (GDPR), ensure auditability and access controls (SOC 2), and implement privacy and security safeguards (HIPAA). Document compliance measures and provide user interfaces for data requests.\n<info added on 2025-11-14T19:10:53.454Z>\n## CURRENT STATUS\n- GDPR models exist in app/models/users.py (UserDataExport, GDPRDeleteResponse) but implementation needs verification.\n\n## COMPLIANCE REQUIREMENTS\n- GDPR: User data export, complete deletion, consent tracking, data retention\n- HIPAA: Encryption (✅), access controls (✅), audit trails (⚠️ needs DB persistence)\n- SOC 2: Auditability (⚠️), access controls (✅), security monitoring\n\n## VERIFICATION TASKS\n1. Test GDPR data export endpoint - verify all user PII is included\n2. Test GDPR deletion endpoint - verify complete removal from all tables\n3. Document data retention policies\n4. Add consent tracking for data processing\n5. Create user-facing data request interface\n\n## COMPLIANCE FEATURES TO IMPLEMENT\n- Data export: JSON download of all user data\n- Right to deletion: Remove all PII from documents, embeddings, graphs\n- Data portability: Export in machine-readable format\n- Privacy controls: User-configurable data retention\n- Breach notification: Automated alerts for security incidents\n\n## SOC 2 REQUIREMENTS\n- Access control documentation (✅ via RBAC)\n- Audit trail persistence (⚠️ task 41.5)\n- Security monitoring dashboards\n- Incident response procedures\n\n## HIPAA SAFEGUARDS\n- Technical safeguards: Encryption (✅), access controls (✅)\n- Physical safeguards: Document B2/Supabase security\n- Administrative safeguards: Policies and training documentation\n\n## DEPENDENCIES\nRequires audit logging (41.5) and RLS policies (41.2) to be complete first.\n</info added on 2025-11-14T19:10:53.454Z>",
            "status": "done",
            "testStrategy": "Perform compliance checks, simulate data subject requests, and verify all regulatory requirements are met.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Conduct Security and Compliance Testing",
            "description": "Perform security testing, penetration testing, and compliance verification across all implemented features.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6
            ],
            "details": "Run automated security scans, manual penetration tests, and compliance audits. Address any vulnerabilities or compliance gaps identified. Document test results and remediation steps.\n<info added on 2025-11-14T19:11:00.118Z>\nCURRENT STATUS: No security testing suite exists yet. This is the final validation phase after all security features are implemented.\n\nTESTING PLAN:\n\n1. AUTOMATED SECURITY SCANS:\n   - OWASP ZAP for penetration testing\n   - Bandit for Python code security analysis\n   - Safety for dependency vulnerability scanning\n   - SQLMap for SQL injection testing\n\n2. MANUAL PENETRATION TESTING:\n   - Auth bypass attempts\n   - Token tampering and replay attacks\n   - RBAC privilege escalation tests\n   - Input fuzzing (SQL injection, XSS, path traversal)\n   - Rate limit bypass attempts\n   - CORS misconfiguration exploits\n\n3. COMPLIANCE VERIFICATION:\n   - GDPR data export/deletion validation\n   - HIPAA audit trail completeness\n   - SOC 2 access control verification\n   - Encryption verification (at-rest, in-transit)\n\n4. SECURITY TEST SUITE:\n   - Create tests/security/ directory\n   - Write pytest tests for:\n     - Authentication flows\n     - RBAC enforcement\n     - Input validation edge cases\n     - Audit log persistence\n     - Rate limiting\n     - Session management\n\n5. DOCUMENTATION:\n   - Security architecture document\n   - Threat model and mitigations\n   - Incident response playbook\n   - Compliance certification evidence\n\nDEPENDENCIES: All subtasks 41.1-41.6 must be complete before testing can begin.\n\nDELIVERABLES:\n- Security test report with findings\n- Remediation plan for any issues\n- Compliance certification readiness assessment\n</info added on 2025-11-14T19:11:00.118Z>",
            "status": "done",
            "testStrategy": "Review test reports, verify all critical issues are resolved, and confirm compliance with GDPR, HIPAA, and SOC 2.",
            "parentId": "undefined"
          }
        ],
        "complexity": 9,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Decompose security hardening and compliance into subtasks for JWT authentication, RBAC enforcement, encrypted storage setup, input validation, audit trail implementation, compliance feature integration (GDPR, HIPAA, SOC 2), and security/compliance testing."
      },
      {
        "id": 42,
        "title": "Reliability & Disaster Recovery Implementation",
        "description": "Set up automated backups, health checks, auto-restart, and disaster recovery procedures.",
        "details": "Configure daily B2 backups, implement health endpoints, auto-restart on failure, and document disaster recovery drills. Use Infrastructure as Code (Terraform/Ansible) for fast rebuild.",
        "testStrategy": "Simulate failures, verify backup/restore, health checks, and recovery procedures.",
        "priority": "high",
        "dependencies": [
          "41"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Automated Backups and Restore Procedures",
            "description": "Set up daily automated B2 backups and validate restore processes to ensure data durability and rapid recovery.",
            "dependencies": [],
            "details": "Configure daily automated backups to Backblaze B2 using Infrastructure as Code (Terraform/Ansible). Regularly test backup integrity and perform restore drills to verify data can be recovered quickly and accurately. Document backup schedules, retention policies, and restoration steps.",
            "status": "done",
            "testStrategy": "Simulate data loss scenarios and perform full and partial restores from backups to verify data integrity and recovery time objectives.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Deploy Health Checks and Auto-Restart Mechanisms",
            "description": "Implement health endpoints and configure automated service restarts on failure to maintain high availability.",
            "dependencies": [
              1
            ],
            "details": "Develop and expose health check endpoints for all critical services. Integrate monitoring tools to continuously check service health. Configure auto-restart policies (e.g., systemd, Kubernetes liveness probes) to automatically recover failed services. Ensure monitoring alerts are in place for failed health checks and restarts.",
            "status": "done",
            "testStrategy": "Induce service failures and verify that health checks detect issues and auto-restart mechanisms restore service availability without manual intervention.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Document and Test Disaster Recovery Procedures",
            "description": "Create, document, and regularly test disaster recovery (DR) drills to ensure readiness for major outages.",
            "dependencies": [
              1,
              2
            ],
            "details": "Develop comprehensive disaster recovery documentation covering failover, rebuild, and recovery steps using Infrastructure as Code. Schedule and execute regular DR drills simulating various failure scenarios (e.g., region outage, data corruption). Update documentation based on drill outcomes and lessons learned.",
            "status": "done",
            "testStrategy": "Conduct scheduled disaster recovery drills, measure recovery time and data loss, and review documentation for completeness and clarity after each drill.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on reliability & disaster recovery implementation."
      },
      {
        "id": 43,
        "title": "Load Testing & Performance Optimization",
        "description": "Conduct load testing for document processing, query execution, and WebSocket connections. Optimize for throughput and latency.",
        "details": "Use locust or k6 for load testing. Profile bottlenecks, optimize Celery worker scaling, database indexes, and caching. Tune API and WebSocket performance.",
        "testStrategy": "Run load tests at 2x expected traffic, verify performance metrics and optimize as needed.",
        "priority": "high",
        "dependencies": [
          "42"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Execute Load Testing Scenarios for Document Processing, Query Execution, and WebSocket Connections",
            "description": "Develop and run comprehensive load tests targeting document processing, query execution, and WebSocket endpoints using tools like Locust or k6.",
            "dependencies": [],
            "details": "Identify key user flows and endpoints for document processing, query execution, and WebSocket communication. Create load test scripts in Locust (Python) or k6 (JavaScript), simulating realistic traffic patterns and scaling up to at least 2x expected peak load. Collect baseline metrics for throughput, latency, and error rates.\n<info added on 2025-11-16T19:08:05.314Z>\nAuthentication setup for load testing completed:\n- Fixed bug in app/middleware/clerk_auth.py by replacing non-existent sessions.verify_token() with proper JWT verification\n- Implemented JWT verification using jwt.decode() with CLERK_SECRET_KEY\n- Created generate_test_token.py script to generate valid JWT tokens for load testing\n- Changes committed (6a67a3b) and pushed to main branch\n- System is now ready for authentication-enabled load testing scenarios\n</info added on 2025-11-16T19:08:05.314Z>",
            "status": "done",
            "testStrategy": "Verify that load tests execute as intended, generate reproducible results, and cover all critical workflows. Ensure metrics are collected for throughput, latency, and error rates under varying load conditions.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Profile System Performance and Identify Bottlenecks",
            "description": "Analyze system performance under load to pinpoint bottlenecks in Celery worker scaling, database indexing, caching, and API/WebSocket layers.",
            "dependencies": [
              1
            ],
            "details": "Use profiling tools and application logs to monitor CPU, memory, database query times, and network utilization during load tests. Focus on Celery worker queues, database slow queries, cache hit/miss ratios, and WebSocket throughput. Document all identified bottlenecks with supporting metrics.",
            "status": "done",
            "testStrategy": "Correlate load test results with profiling data to confirm bottleneck locations. Validate findings by reproducing issues under controlled load and measuring impact of each suspected bottleneck.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Optimize and Re-Test for Throughput and Latency Improvements",
            "description": "Implement targeted optimizations (e.g., Celery scaling, database indexes, caching strategies, API/WebSocket tuning) and validate improvements through iterative load testing.",
            "dependencies": [
              2
            ],
            "details": "Apply optimizations based on profiling results: adjust Celery worker counts, add or tune database indexes, refine caching logic, and optimize API/WebSocket configurations. Re-run load tests to measure improvements in throughput and latency. Iterate as needed until performance targets are met.\n<info added on 2025-11-17T00:16:21.618Z>\n## Progress Update (75% Complete)\n\n### Accomplishments\n1. Created comprehensive load testing framework (query_load_test.py)\n2. Identified and fixed 4 critical bugs:\n   - Langfuse decorator async bug (5e8c9c1) - adaptive endpoint 0% → 100% success\n   - Pydantic cache serialization (f2707f5) - enabled cache infrastructure\n   - LangGraph ToolNode error (7e0972f) - fixed 33% failure rate on complex queries\n   - Redis connection for Upstash (7e0972f) - SSL/TLS support for production\n3. Generated comprehensive documentation:\n   - PERFORMANCE_REPORT_TASK43_3.md (8 sections)\n   - TASK43_3_FINAL_STATUS.md (complete status)\n   - 3 JSON test result files\n4. Re-tested and validated all bug fixes in production\n5. Profiled performance bottlenecks and documented optimizations\n\n### Current Performance Metrics\n- Adaptive endpoint: 100% success (was 0%)\n- Auto-routed endpoint: 100% success\n- Cache hit rate: 0% (embedding service unavailable)\n- Adaptive P95 latency: 14.6s (target: <1s)\n- Auto-routed P95 latency: 7.1s (target: <2s)\n\n### Outstanding Issues\n1. Caching not functional - BGE-M3 via Ollama unavailable from Render\n   - Need OpenAI embeddings fallback\n   - Verify Redis connection in logs\n2. Performance too slow - sequential LLM calls taking 12-14s\n   - Need to combine analyze+plan into single call\n   - Add streaming responses\n   - Implement prompt caching\n\n### Next Steps\n- Add OpenAI embeddings fallback for production caching\n- Optimize LangGraph workflow (combine nodes, add streaming)\n- Final validation with working cache and optimized performance\n- Estimated: 2-4 hours to complete remaining 25%\n</info added on 2025-11-17T00:16:21.618Z>",
            "status": "done",
            "testStrategy": "Compare pre- and post-optimization metrics for throughput, latency, and error rates. Confirm that optimizations resolve identified bottlenecks and that the system meets or exceeds performance goals under 2x expected load.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on load testing & performance optimization."
      },
      {
        "id": 44,
        "title": "Documentation Finalization & User Onboarding",
        "description": "Prepare comprehensive documentation for developers and users. Implement onboarding flows and training materials.",
        "details": "Document API endpoints, workflows, agent configurations, and UI usage. Create onboarding guides and training videos.",
        "testStrategy": "Review documentation for completeness and clarity. Test onboarding flows with new users.",
        "priority": "medium",
        "dependencies": [
          "43"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Comprehensive API & Workflow Documentation",
            "description": "Create detailed, accurate documentation covering all API endpoints, workflows, agent configurations, and UI usage for both developers and end-users.",
            "dependencies": [
              43
            ],
            "details": "Document each API endpoint with request/response examples, authentication details, and error codes. Outline workflows with diagrams and step-by-step instructions. Describe agent configuration options and UI navigation paths. Use clear headings, code samples, and visuals to enhance readability and accessibility[1][2]. Ensure documentation is reviewed by technical stakeholders for accuracy before finalization.",
            "status": "done",
            "testStrategy": "Conduct peer reviews with developers and QA to verify completeness, clarity, and technical accuracy. Test documented workflows against the live system to ensure they match actual behavior.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Onboarding Guide & Training Material Development",
            "description": "Develop onboarding guides and training materials tailored to different user roles, including step-by-step tutorials, FAQs, and best practices.",
            "dependencies": [
              43
            ],
            "details": "Write onboarding guides for new users and developers, focusing on getting started, common tasks, and troubleshooting. Create training videos (e.g., using Loom or similar tools) demonstrating key features and workflows. Include exercises and real-world examples to reinforce learning. Structure content for easy navigation and quick reference, using consistent formatting and visual aids[1][2]. Collaborate with support and training teams to ensure materials address common user pain points.",
            "status": "done",
            "testStrategy": "Pilot onboarding materials with a group of new users and gather feedback on clarity, usefulness, and ease of understanding. Revise materials based on feedback before broad release.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Documentation Maintenance & Continuous Improvement Plan",
            "description": "Establish processes for ongoing documentation review, updates, and user feedback integration to keep materials accurate and relevant.",
            "dependencies": [
              43
            ],
            "details": "Set up a schedule for regular documentation reviews, especially after product updates or releases. Implement a feedback loop where users can report issues or suggest improvements. Use version control to track changes and ensure all stakeholders have access to the latest documentation. Standardize templates and update procedures to maintain consistency across all docs[2][4]. Assign clear ownership for documentation maintenance within the team.",
            "status": "done",
            "testStrategy": "Monitor documentation usage analytics and user feedback channels. Periodically audit docs for outdated information and verify that updates are correctly propagated. Test revised documentation with both new and experienced users to ensure continued effectiveness.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on documentation finalization & user onboarding."
      },
      {
        "id": 45,
        "title": "Integrate RAGAS Metrics Evaluation and Visualization for RAG Pipeline",
        "description": "Implement automated RAG quality evaluation using the RAGAS framework with 4 core metrics (Faithfulness, Answer Relevancy, Context Precision, Context Recall). Store results in Supabase and visualize in Grafana dashboards.",
        "details": "- Set up RAGAS framework integration for automated evaluation of RAG pipeline quality\n- Implement evaluation of 4 core metrics:\n  * Faithfulness (0-1): Measures if the generated answer is factually consistent with the retrieved context\n  * Answer Relevancy (0-1): Measures if the answer addresses the query intent\n  * Context Precision (0-1): Measures the proportion of relevant context chunks\n  * Context Recall (0-1): Measures if all necessary information is present in context\n- Create a test dataset of 30 curated samples from Empire documentation stored in .taskmaster/docs/ragas_test_dataset.json\n- Design and implement Supabase ragas_evaluations table with schema including:\n  * evaluation_id (UUID)\n  * timestamp (TIMESTAMP)\n  * query_text (TEXT)\n  * answer_text (TEXT)\n  * context_chunks (JSONB array)\n  * faithfulness_score (FLOAT)\n  * answer_relevancy_score (FLOAT)\n  * context_precision_score (FLOAT)\n  * context_recall_score (FLOAT)\n  * overall_score (FLOAT)\n  * metadata (JSONB)\n- Develop scripts/ragas_evaluation.py for batch evaluation with:\n  * Command-line interface for running evaluations\n  * Integration with existing RAG pipeline components\n  * Configurable parameters for evaluation settings\n  * Automatic storage of results in Supabase\n- Create Grafana dashboards showing:\n  * Metric trends over time\n  * Comparison between different RAG configurations\n  * Alerts when metrics fall below threshold (0.70)\n  * Drill-down capability to examine specific evaluation runs\n- Document expected baseline performance (0.70-0.85 overall scores)\n- Calculate and document cost estimates (~$0.20 per evaluation run for 30 samples)\n- Integrate with existing observability infrastructure from Task 25",
        "testStrategy": "1. Prepare test environment with sample RAG pipeline and test dataset\n2. Run baseline evaluation on the 30-sample test dataset from .taskmaster/docs/ragas_test_dataset.json\n3. Validate all 4 metrics (Faithfulness, Answer Relevancy, Context Precision, Context Recall) are calculated correctly\n4. Verify scores are within expected ranges (0-1) and reasonable for test data\n5. Confirm results are properly stored in Supabase ragas_evaluations table\n6. Check that all required fields in the schema are populated correctly\n7. Verify Grafana dashboard correctly displays:\n   - Individual metric scores\n   - Overall score trends\n   - Comparison between evaluation runs\n8. Test alert triggers by artificially setting scores below the 0.70 threshold\n9. Validate dashboard filtering and drill-down capabilities\n10. Perform a complete end-to-end test with a new document to ensure the entire evaluation pipeline works\n11. Measure performance and resource usage during evaluation runs\n12. Document baseline scores for the current RAG implementation",
        "status": "done",
        "dependencies": [
          "18",
          "25"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up RAGAS framework integration and test dataset",
            "description": "Integrate the RAGAS framework into the project and prepare the test dataset for evaluation.",
            "dependencies": [],
            "details": "Install RAGAS library and dependencies. Configure the framework to work with the existing RAG pipeline. Prepare and validate the test dataset of 30 curated samples from Empire documentation stored in .taskmaster/docs/ragas_test_dataset.json. Ensure the dataset contains appropriate query-answer-context triplets for evaluation.",
            "status": "done",
            "testStrategy": "Verify RAGAS installation and imports work correctly. Validate test dataset structure and content. Ensure sample queries cover diverse use cases from Empire documentation.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement core metrics evaluation logic",
            "description": "Develop the core functionality to evaluate the 4 RAGAS metrics: Faithfulness, Answer Relevancy, Context Precision, and Context Recall.",
            "dependencies": [
              1
            ],
            "details": "Create evaluation functions for each metric. Implement Faithfulness calculation to measure factual consistency between answers and context. Develop Answer Relevancy evaluation to assess query intent alignment. Build Context Precision measurement for relevant chunk proportion. Implement Context Recall to verify information completeness. Calculate overall combined score from individual metrics.",
            "status": "done",
            "testStrategy": "Run evaluations on sample data and verify each metric produces values between 0-1. Compare results with manual assessments of a subset of examples to validate accuracy.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Create Supabase ragas_evaluations table and storage logic",
            "description": "Design and implement the Supabase database schema for storing RAGAS evaluation results and develop storage functionality.",
            "dependencies": [
              2
            ],
            "details": "Create ragas_evaluations table with schema including evaluation_id, timestamp, query_text, answer_text, context_chunks, all metric scores (faithfulness, answer_relevancy, context_precision, context_recall), overall_score, and metadata fields. Implement functions to store evaluation results in the database. Add batch processing capabilities for multiple evaluations.",
            "status": "done",
            "testStrategy": "Test database schema creation and data insertion. Verify all fields are properly stored and retrieved. Check batch processing with multiple evaluation records.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Develop scripts/ragas_evaluation.py with CLI interface",
            "description": "Create a command-line script for running RAGAS evaluations with configurable parameters and Supabase integration.",
            "dependencies": [
              3
            ],
            "details": "Develop scripts/ragas_evaluation.py with command-line arguments for evaluation settings. Integrate with existing RAG pipeline components to access retrieval and generation functions. Implement configurable parameters for batch size, metric weights, and thresholds. Add automatic storage of results in Supabase. Include logging and error handling. Document cost estimates (~$0.20 per evaluation run for 30 samples).",
            "status": "done",
            "testStrategy": "Test CLI with various parameter combinations. Verify integration with RAG pipeline components. Confirm results are properly stored in Supabase. Validate error handling for edge cases.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create Grafana dashboards for metrics visualization",
            "description": "Design and implement Grafana dashboards to visualize RAGAS metrics and integrate with existing observability infrastructure.",
            "dependencies": [
              4
            ],
            "details": "Create Grafana dashboards showing metric trends over time. Implement comparison views between different RAG configurations. Set up alerts when metrics fall below threshold (0.70). Add drill-down capability to examine specific evaluation runs. Document expected baseline performance (0.70-0.85 overall scores). Integrate with existing observability infrastructure from Task 25.",
            "status": "done",
            "testStrategy": "Verify dashboard displays all metrics correctly. Test alert functionality with below-threshold values. Confirm drill-down navigation works properly. Validate integration with existing observability infrastructure.",
            "parentId": "undefined"
          }
        ]
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-11-14T18:18:43.347Z",
      "taskCount": 45,
      "completedCount": 39,
      "tags": [
        "master"
      ],
      "created": "2025-11-14T19:10:19.748Z",
      "description": "Tasks for master context",
      "updated": "2025-11-17T18:28:30.661Z"
    }
  },
  "v7_3_features": {
    "tasks": [
      {
        "id": "59",
        "title": "Create project_sources database table",
        "description": "Design and implement the new project_sources table in Supabase with RLS policies for project-scoped source management",
        "details": "CREATE TABLE project_sources (id UUID PRIMARY KEY DEFAULT gen_random_uuid(), project_id UUID REFERENCES projects(id) ON DELETE CASCADE, user_id UUID REFERENCES auth.users(id), source_type TEXT CHECK (source_type IN ('file','url','youtube')), source_url TEXT, file_name TEXT, file_size BIGINT, status TEXT CHECK (status IN ('pending','processing','ready','failed')) DEFAULT 'pending', progress INTEGER DEFAULT 0, error_message TEXT, metadata JSONB, content_length INTEGER, created_at TIMESTAMP DEFAULT NOW(), updated_at TIMESTAMP DEFAULT NOW()); Add RLS policies: ENABLE RLS; CREATE POLICY 'Users can view own project sources' ON project_sources FOR SELECT USING (auth.uid() = user_id); CREATE POLICY 'Users can insert own project sources' ON project_sources FOR INSERT WITH CHECK (auth.uid() = user_id); CREATE POLICY 'Users can update own project sources' ON project_sources FOR UPDATE USING (auth.uid() = user_id); Add indexes: CREATE INDEX idx_project_sources_project_id_status ON project_sources(project_id, status); CREATE INDEX idx_project_sources_user_id ON project_sources(user_id);",
        "testStrategy": "Verify table creation with schema inspection, test RLS by inserting/updating as different users, confirm ON DELETE CASCADE removes sources when project deleted, validate CHECK constraints reject invalid status/source_type values",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T00:38:44.993Z"
      },
      {
        "id": "60",
        "title": "Implement Source CRUD API endpoints",
        "description": "Create FastAPI endpoints for adding, listing, updating status, retrying, and deleting project sources",
        "details": "Add endpoints: POST /api/projects/{project_id}/sources (multipart/form-data for files + URLs), GET /api/projects/{project_id}/sources (with sort/filter/query params), PATCH /api/projects/{project_id}/sources/{source_id} (status/progress updates), DELETE /api/projects/{project_id}/sources/{source_id}, POST /api/projects/{project_id}/sources/{source_id}/retry. Implement file upload to Supabase storage with magic byte validation for 40+ types, URL validation with regex for http/https/youtube patterns, duplicate detection by hash/url, enforce 100MB limit and 100 sources/project cap. Return source_id and initial 'pending' status. Use Supabase Python client with row-level security.",
        "testStrategy": "Test file uploads (PDF/DOCX/YT/URL) with valid/invalid types/sizes/duplicates, verify 80%/100% capacity warnings, test list with sorting (date,name,type,status) and search, confirm delete cascades embeddings, test retry increments attempt_count",
        "priority": "high",
        "dependencies": [
          "59"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T00:46:06.907Z"
      },
      {
        "id": "61",
        "title": "Develop Celery task for source processing pipeline",
        "description": "Create unified Celery task that handles type-specific content extraction, summary generation, embedding creation, and status updates",
        "details": "Implement @celery.task def process_source(source_id): source = fetch_source(source_id); update_status('processing', 10); content = extract_content(source.type) # LlamaParse/PyPDF/python-docx/pandas/yt-dlp/BeautifulSoup/Soniox per spec; update_progress(40); summary = claude.generate_summary(content); update_progress(60); embeddings = bge_m3.embed_chunks(chunk_content(content, 512)); store_embeddings(embeddings, source_id, project_id); update_status('ready', 100); Handle errors with max 3 retries, update 'failed' with error_message. Use existing processing libs: yt-dlp for YouTube transcripts/chapters/thumbnails, BeautifulSoup for web (respect robots.txt), Soniox for audio/video. Store metadata (title/author/date/duration).",
        "testStrategy": "Queue tasks for each source type, verify status transitions (pending->processing->ready/failed), check progress updates via WebSocket, validate content extraction accuracy, confirm embeddings stored with correct project_id, test retry logic (3 attempts max)",
        "priority": "high",
        "dependencies": [
          "59",
          "60"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T00:59:11.752Z"
      },
      {
        "id": "62",
        "title": "Build real-time status updates with WebSocket",
        "description": "Implement Supabase Realtime subscriptions for live source status and progress updates in Project Detail view",
        "details": "Frontend: use supabase.realtime.subscribe('project_sources', { project_id }, callback); Backend: Use Supabase triggers AFTER INSERT/UPDATE on project_sources to broadcast via pg_notify. Handle reconnect with full sources refresh. Include estimated time (e.g., PDF pages*2s, YT duration/60s). Visual indicators: green ● ready, blue ◐ processing+%, gray ○ pending, red ✕ failed+retry.",
        "testStrategy": "Simulate processing updates, verify UI reflects changes in <2s, test disconnect/reconnect syncs correctly, confirm progress animation and ETR display, test error messages and retry button triggers re-queue",
        "priority": "high",
        "dependencies": [
          "60",
          "61"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T01:04:16.003Z"
      },
      {
        "id": "63",
        "title": "Frontend Sources UI component",
        "description": "Build drag & drop Sources section in Project Detail view with unified input, grid/list view, cards, search/filter/sort",
        "details": "React component with: Dropzone for files+URLs (textarea multi-line), auto-detect type, Add button queues to backend. Source cards: type icon [PDF]/[YT]/[URL], status badge, metadata (size/pages/duration), thumbnail for YT, delete/retry buttons with confirm. Grid responsive, sort by added/date/name/type/status, search by name. Summary footer: X sources • Y ready • Z processing • progress bar. File type icons per spec table.",
        "testStrategy": "Test drag/drop multi-file/URL input validation, verify card rendering for all types/statuses, confirm sort/filter/search functional, test responsive grid, validate delete confirm and immediate UI update",
        "priority": "high",
        "dependencies": [
          "60",
          "62"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T18:37:48.409Z"
      },
      {
        "id": "64",
        "title": "Implement project-scoped hybrid RAG query endpoint",
        "description": "Modify RAG pipeline for parallel vector search: project sources (primary, wt 1.0, LIMIT 8) + global KB (secondary, wt 0.7, LIMIT 5), merge/rerank/deduplicate",
        "details": "POST /api/rag/query {project_id, query}: query_emb = bge_m3.embed(query); project_results = supabase.rpc('match_documents', {'query_embedding': query_emb, 'project_id': project_id, 'limit': 8, 'status': 'ready'}); global_results = supabase.rpc('match_documents', {'query_embedding': query_emb, 'limit': 5}); merged = rerank_combine(project_results*1.0 + global_results*0.7, dedupe similarity>0.9); response = claude.generate(prompt + merged_context, citations=true); Track source_ids used for citations.",
        "testStrategy": "Query with/without project sources, verify project results prioritized and filtered by project_id/status='ready', confirm global KB supplements, test response time <3s, validate weighting in reranking scores",
        "priority": "high",
        "dependencies": [
          "59",
          "61"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T18:53:30.338Z"
      },
      {
        "id": "65",
        "title": "Integrate project-scoped RAG into Project Chat",
        "description": "Update Project Chat to use new hybrid RAG endpoint, show scoped indicator, pass project_id automatically",
        "details": "In ProjectChat component: onSend(message) => POST /api/rag/query({project_id, query: message}); Display 'Project-scoped chat (X ready sources)' banner. Fallback to global-only if no ready sources. Ensure chat history ties to project_id.",
        "testStrategy": "Create project chats with/without sources, verify queries only use project+global (not other projects), confirm scoped indicator visible, test empty sources fallback gracefully",
        "priority": "high",
        "dependencies": [
          "64",
          "63"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T20:23:40.569Z"
      },
      {
        "id": "66",
        "title": "Add source citations to chat responses",
        "description": "Parse LLM citations and display clickable source links below responses with name/type/excerpt/page/timestamp",
        "details": "Backend: Claude prompt instructs '[cite source_id:excerpt]' format; parse response for citations, enrich with source metadata. Frontend: Render citations list under AI message: [PDF] filename (p.23) • click => view source (PDF page/YT timestamp/URL open). Context-aware: extract page/chunk/timestamp from metadata.",
        "testStrategy": "Send queries hitting multiple source types, verify citations appear with correct metadata, test click handlers (PDF jump/YT seek/URL open), confirm excerpts match relevant content",
        "priority": "medium",
        "dependencies": [
          "64",
          "65"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-06T02:20:47.683Z"
      },
      {
        "id": "67",
        "title": "File type validation and security scanning",
        "description": "Implement magic byte validation for 40+ types, URL sanitization, content scanning before processing",
        "details": "Use python-magic for file type detection (not extension), block executables/scripts. Sanitize URLs (whitelist schemes, block javascript:). Scan content with ClamAV or similar for malware. Reject at upload if invalid. Log security events.",
        "testStrategy": "Upload valid/invalid files (rename .pdf to .exe), test URL sanitization (malformed/js), simulate malware files rejected, confirm processing only starts on clean validated sources",
        "priority": "high",
        "dependencies": [
          "60"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T20:15:22.872Z"
      },
      {
        "id": "68",
        "title": "Add capacity warnings and limits enforcement",
        "description": "Implement per-project limits: 100 sources, 500MB total, warnings at 80%, soft block at 100%",
        "details": "API check: SELECT COUNT(*), SUM(file_size) FROM project_sources WHERE project_id=?; Block adds if >100 or >500MB, warn if >80%. Return HTTP 429 with cleanup suggestions/upgrade prompt.",
        "testStrategy": "Fill project to 79/99, 80/100, 101/501 thresholds, verify warnings/blocks, test across concurrent uploads",
        "priority": "medium",
        "dependencies": [
          "60"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T20:32:33.327Z"
      },
      {
        "id": "69",
        "title": "E2E testing and performance optimization",
        "description": "Comprehensive testing covering full user flows, optimize for specified performance metrics",
        "details": "Cypress E2E: upload file/URL/YT -> monitor status -> chat query -> verify citations. Profile processing times (PDF<60s, YT<30s), add Celery queue prioritization, cache processed content, index optimizations. Load test 10 concurrent sources.",
        "testStrategy": "Run full flows for all source types, measure metrics vs targets (>95% success, <3s RAG), stress test concurrency/scalability, verify retry/auto-failover works",
        "priority": "medium",
        "dependencies": [
          "63",
          "65",
          "66",
          "67",
          "68"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-06T03:04:20.031Z"
      },
      {
        "id": "70",
        "title": "Create Database Migrations for AI Studio",
        "description": "Implement database migrations for the new tables required by AI Studio: generated_assets, content_classifications, user_workflow_preferences, studio_kb_sessions, studio_kb_messages, and agent_usage_stats.",
        "details": "Create migration files for all new tables specified in the PRD section 3.1. Ensure proper relationships, constraints, and indexes are set up.\n\nMigration should include:\n1. generated_assets table with asset_type, department, content fields\n2. content_classifications table for department classifications\n3. user_workflow_preferences table for user settings\n4. studio_kb_sessions and studio_kb_messages tables for KB chat\n5. agent_usage_stats table for tracking agent performance\n\nEnsure RLS policies are implemented for security. Use the exact schema definitions from the PRD with appropriate data types, constraints, and indexes.\n\nPseudo-code:\n```sql\n-- Example for generated_assets table\nCREATE TABLE generated_assets (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    user_id UUID REFERENCES auth.users(id) NOT NULL,\n    asset_type TEXT NOT NULL CHECK (asset_type IN ('skill', 'command', 'agent', 'prompt', 'workflow')),\n    department TEXT NOT NULL,\n    title TEXT NOT NULL,\n    content TEXT NOT NULL,\n    format TEXT NOT NULL CHECK (format IN ('yaml', 'md', 'json')),\n    -- Additional fields as per PRD\n);\n\n-- Add RLS policy\nALTER TABLE generated_assets ENABLE ROW LEVEL SECURITY;\nCREATE POLICY \"Users can only see their own assets\" \n    ON generated_assets FOR ALL \n    USING (auth.uid() = user_id);\n```",
        "testStrategy": "1. Verify migrations run successfully in development environment\n2. Test RLS policies by attempting to access data from different user contexts\n3. Validate constraints by inserting valid and invalid data\n4. Verify indexes are created correctly using EXPLAIN ANALYZE\n5. Test foreign key constraints and cascading deletes\n6. Verify generated columns calculate correctly\n7. Run rollback and re-apply to ensure idempotence",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-06T20:19:57.621Z"
      },
      {
        "id": "71",
        "title": "Implement AI Studio Navigation in Desktop App",
        "description": "Add the AI Studio navigation item to the sidebar between File Uploads and Settings, with appropriate icon and notification badge for pending feedback.",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "Update the desktop app navigation to include the new AI Studio section with CKO Conversation as the main view and collapsible sidebar panels:\n\n1. Create a new navigation item in the sidebar between File Uploads and Settings\n2. Use an AI/brain/neural network icon for the navigation item\n3. Add notification badge logic to show count of pending feedback items\n4. Implement CKO Conversation as the main view with 4 collapsible sidebar panels: Assets, Classifications, Weights, Feedback\n5. Create the main container view for AI Studio with collapsible sidebar logic\n\nPseudo-code:\n```tsx\n// In SidebarNavigation.tsx\nconst navItems = [\n  // existing items\n  { name: 'File Uploads', icon: <UploadIcon />, path: '/uploads' },\n  { \n    name: 'AI Studio', \n    icon: <BrainIcon />, \n    path: '/studio',\n    badge: pendingFeedbackCount > 0 ? pendingFeedbackCount : null \n  },\n  { name: 'Settings', icon: <SettingsIcon />, path: '/settings' },\n];\n\n// In AIStudioView.tsx\nconst AIStudioView = () => {\n  const [activeSidebarPanel, setActiveSidebarPanel] = useState(null);\n  \n  return (\n    <div className=\"ai-studio-container\">\n      <div className=\"main-content\">\n        <CKOConversationView />\n      </div>\n      \n      <CollapsibleSidebar\n        panels={[\n          { id: 'assets', label: 'Assets' },\n          { id: 'classifications', label: 'Classifications' },\n          { id: 'weights', label: 'Weights' },\n          { id: 'feedback', label: 'Feedback' }\n        ]}\n        activePanel={activeSidebarPanel}\n        onTogglePanel={setActiveSidebarPanel}\n      />\n      \n      {activeSidebarPanel === 'assets' && <AssetsPanel />}\n      {activeSidebarPanel === 'classifications' && <ClassificationsPanel />}\n      {activeSidebarPanel === 'weights' && <WeightsPanel />}\n      {activeSidebarPanel === 'feedback' && <FeedbackPanel />}\n    </div>\n  );\n};\n```",
        "testStrategy": "1. Verify navigation item appears in correct position in sidebar\n2. Test notification badge appears when feedback is pending\n3. Verify clicking on AI Studio opens the view with CKO Conversation as the main view\n4. Test collapsible sidebar panels can be opened and closed correctly\n5. Verify active sidebar panel is highlighted correctly\n6. Test responsive design on different screen sizes\n7. Verify keyboard navigation works for accessibility\n8. Test that CKO Conversation remains visible when sidebar panels are toggled",
        "subtasks": [],
        "updatedAt": "2026-01-06T20:50:31.335Z"
      },
      {
        "id": "72",
        "title": "Implement Knowledge Base Chat Service",
        "description": "Create the backend service for the Chief Knowledge Officer (CKO) persona for conversational knowledge base interaction, reusing patterns from the existing project_rag_service but without project context.",
        "status": "done",
        "dependencies": [
          "70"
        ],
        "priority": "high",
        "details": "Implement the studio_cko_conversation_service.py to handle global knowledge base conversation functionality via the CKO persona:\n\n1. Reuse the hybrid RAG (vector + knowledge graph) approach from project_rag_service\n2. Modify to use global knowledge base without project context (weight project=0, global=1.0)\n3. Implement source citation tracking and document linking\n4. Support WebSocket for real-time streaming responses\n5. Add persistence for conversation history\n6. Implement response rating functionality\n\nPseudo-code:\n```python\n# studio_cko_conversation_service.py\nfrom app.services.project_rag_service import get_rag_response\n\nclass StudioCKOConversationService:\n    async def create_session(self, user_id):\n        \"\"\"Create a new CKO conversation session\"\"\"\n        session_id = await db.studio_cko_sessions.insert({\n            'user_id': user_id,\n            'title': 'New CKO Conversation',\n            'created_at': datetime.now()\n        })\n        return session_id\n    \n    async def send_message(self, session_id, user_id, message):\n        \"\"\"Process a user message and generate CKO response\"\"\"\n        # Save user message\n        await db.studio_cko_messages.insert({\n            'session_id': session_id,\n            'role': 'user',\n            'content': message,\n            'created_at': datetime.now()\n        })\n        \n        # Get RAG response (reuse project_rag_service but with global KB only)\n        response, sources = await get_rag_response(\n            query=message,\n            user_id=user_id,\n            project_id=None,  # No project context\n            weights={'global': 1.0, 'project': 0.0}\n        )\n        \n        # Save assistant message with sources\n        message_id = await db.studio_cko_messages.insert({\n            'session_id': session_id,\n            'role': 'assistant',\n            'content': response,\n            'sources': sources,\n            'created_at': datetime.now()\n        })\n        \n        # Update session metadata\n        await db.studio_cko_sessions.update(\n            {'id': session_id},\n            {\n                'message_count': db.raw('message_count + 2'),\n                'last_message_at': datetime.now(),\n                'updated_at': datetime.now()\n            }\n        )\n        \n        return {\n            'message_id': message_id,\n            'content': response,\n            'sources': sources\n        }\n    \n    async def rate_message(self, message_id, rating):\n        \"\"\"Rate a CKO response (thumbs up/down)\"\"\"\n        await db.studio_cko_messages.update(\n            {'id': message_id},\n            {'rating': rating}\n        )\n        \n        # If negative rating, create feedback entry\n        if rating < 0:\n            await db.agent_feedback.insert({\n                'message_id': message_id,\n                'feedback_type': 'cko_conversation_rating',\n                'rating': rating\n            })\n```",
        "testStrategy": "1. Unit test each method in the service with mocked database\n2. Test RAG response with various query types\n3. Verify source citations are correctly captured\n4. Test WebSocket streaming with simulated delays\n5. Verify conversation history persistence across sessions\n6. Test rating functionality and feedback creation\n7. Verify performance with large knowledge bases\n8. Test error handling for invalid inputs",
        "subtasks": [],
        "updatedAt": "2026-01-07T17:32:46.589Z"
      },
      {
        "id": "73",
        "title": "Create KB Chat API Routes",
        "description": "Implement the API routes for the Chief Knowledge Officer (CKO) Conversation functionality, including session management, message sending, history retrieval, and response rating.",
        "status": "done",
        "dependencies": [
          "72"
        ],
        "priority": "high",
        "details": "Create the studio_cko_conversation.py routes file with the following endpoints:\n\n1. POST /api/studio/cko-conversation - Send message to CKO\n2. GET /api/studio/cko-conversation/history - Get chat history\n3. POST /api/studio/cko-conversation/{message_id}/rate - Rate a response\n4. WebSocket /ws/studio/cko-conversation - Real-time streaming\n\nEnsure all routes are authenticated and validate input parameters.\n\nPseudo-code:\n```python\n# studio_cko_conversation.py\nfrom fastapi import APIRouter, Depends, WebSocket, WebSocketDisconnect\nfrom app.services.studio_cko_conversation_service import StudioCKOConversationService\nfrom app.auth import get_current_user\n\nrouter = APIRouter(prefix=\"/api/studio/cko-conversation\", tags=[\"studio\"])\ncko_conversation_service = StudioCKOConversationService()\n\n@router.post(\"/\")\nasync def send_message(request: CKOConversationRequest, user=Depends(get_current_user)):\n    \"\"\"Send a message to the Chief Knowledge Officer and get a response\"\"\"\n    result = await cko_conversation_service.send_message(\n        session_id=request.session_id,\n        user_id=user.id,\n        message=request.message\n    )\n    return result\n\n@router.get(\"/history\")\nasync def get_chat_history(session_id: str, user=Depends(get_current_user)):\n    \"\"\"Get chat history for a session\"\"\"\n    # Verify session belongs to user\n    session = await cko_conversation_service.get_session(session_id)\n    if session['user_id'] != user.id:\n        raise HTTPException(status_code=403, detail=\"Not authorized\")\n    \n    messages = await cko_conversation_service.get_messages(session_id)\n    return {\"messages\": messages}\n\n@router.post(\"/{message_id}/rate\")\nasync def rate_message(message_id: str, rating: int, user=Depends(get_current_user)):\n    \"\"\"Rate an AI response (thumbs up/down)\"\"\"\n    # Verify message belongs to user\n    message = await cko_conversation_service.get_message(message_id)\n    session = await cko_conversation_service.get_session(message['session_id'])\n    if session['user_id'] != user.id:\n        raise HTTPException(status_code=403, detail=\"Not authorized\")\n    \n    await cko_conversation_service.rate_message(message_id, rating)\n    return {\"success\": True}\n\n@router.websocket(\"/ws\")\nasync def websocket_endpoint(websocket: WebSocket, token: str):\n    \"\"\"WebSocket endpoint for streaming responses\"\"\"\n    # Authenticate user from token\n    user = await get_user_from_token(token)\n    if not user:\n        await websocket.close(code=1008)  # Policy violation\n        return\n    \n    await websocket.accept()\n    try:\n        while True:\n            data = await websocket.receive_json()\n            # Stream response tokens\n            async for token in cko_conversation_service.stream_response(\n                session_id=data['session_id'],\n                user_id=user.id,\n                message=data['message']\n            ):\n                await websocket.send_json({\"token\": token})\n    except WebSocketDisconnect:\n        pass\n```",
        "testStrategy": "1. Test each API endpoint with valid and invalid inputs\n2. Verify authentication and authorization checks\n3. Test WebSocket connection and streaming\n4. Verify error handling and appropriate status codes\n5. Test rate limiting and performance under load\n6. Verify session and message ownership validation\n7. Test concurrent WebSocket connections\n8. Verify response format matches schema",
        "subtasks": [],
        "updatedAt": "2026-01-07T17:32:57.172Z"
      },
      {
        "id": "74",
        "title": "Develop KB Chat Frontend with WebSocket Streaming",
        "description": "Create the frontend components for the CKO Conversation interface with real-time response streaming via WebSocket.",
        "status": "done",
        "dependencies": [
          "71",
          "73"
        ],
        "priority": "high",
        "details": "Implement the CKO Conversation frontend components:\n\n1. Create CKOConversationView.tsx as the main container component\n2. Implement CKOConversationMessage.tsx for displaying messages with source citations\n3. Set up WebSocket connection for real-time streaming responses\n4. Create chat input with send button\n5. Implement message history with AI/User distinction\n6. Add collapsible source citations panel\n7. Add \"New Chat\" button to start fresh conversations\n\nPseudo-code:\n```tsx\n// CKOConversationView.tsx\nimport { useState, useEffect, useRef } from 'react';\nimport CKOConversationMessage from './CKOConversationMessage';\n\nconst CKOConversationView = () => {\n  const [messages, setMessages] = useState([]);\n  const [input, setInput] = useState('');\n  const [sessionId, setSessionId] = useState(null);\n  const [isStreaming, setIsStreaming] = useState(false);\n  const wsRef = useRef(null);\n  \n  // Initialize WebSocket connection\n  useEffect(() => {\n    const token = getAuthToken();\n    wsRef.current = new WebSocket(`ws://api.example.com/api/studio/cko-conversation/ws?token=${token}`);\n    \n    wsRef.current.onmessage = (event) => {\n      const data = JSON.parse(event.data);\n      if (data.token) {\n        // Append token to current message\n        setMessages(prev => {\n          const updated = [...prev];\n          const lastMsg = updated[updated.length - 1];\n          lastMsg.content += data.token;\n          return updated;\n        });\n      }\n    };\n    \n    return () => {\n      if (wsRef.current) wsRef.current.close();\n    };\n  }, []);\n  \n  // Create new session if needed\n  useEffect(() => {\n    if (!sessionId) {\n      createNewSession();\n    }\n  }, [sessionId]);\n  \n  const createNewSession = async () => {\n    const response = await fetch('/api/studio/cko-conversation/session', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' }\n    });\n    const data = await response.json();\n    setSessionId(data.session_id);\n    setMessages([]);\n  };\n  \n  const sendMessage = () => {\n    if (!input.trim()) return;\n    \n    // Add user message\n    const userMessage = { role: 'user', content: input, id: Date.now() };\n    setMessages(prev => [...prev, userMessage]);\n    \n    // Add empty AI message that will be filled by streaming\n    const aiMessage = { role: 'assistant', content: '', id: Date.now() + 1, sources: [] };\n    setMessages(prev => [...prev, aiMessage]);\n    \n    // Send via WebSocket for streaming\n    wsRef.current.send(JSON.stringify({\n      session_id: sessionId,\n      message: input\n    }));\n    \n    setInput('');\n    setIsStreaming(true);\n  };\n  \n  return (\n    <div className=\"cko-conversation-container\">\n      <div className=\"cko-conversation-header\">\n        <h2>CKO Conversation</h2>\n        <button onClick={createNewSession}>New Chat</button>\n      </div>\n      \n      <div className=\"cko-conversation-messages\">\n        {messages.map(message => (\n          <CKOConversationMessage \n            key={message.id}\n            message={message}\n            onRate={rating => rateMessage(message.id, rating)}\n          />\n        ))}\n      </div>\n      \n      <div className=\"cko-conversation-input\">\n        <input\n          type=\"text\"\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          onKeyDown={e => e.key === 'Enter' && sendMessage()}\n          disabled={isStreaming}\n        />\n        <button onClick={sendMessage} disabled={isStreaming}>\n          Send\n        </button>\n      </div>\n    </div>\n  );\n};\n\n// CKOConversationMessage.tsx\nconst CKOConversationMessage = ({ message, onRate }) => {\n  const [showSources, setShowSources] = useState(false);\n  \n  return (\n    <div className={`cko-conversation-message ${message.role}`}>\n      <div className=\"message-avatar\">\n        {message.role === 'user' ? '👤' : '🤖'}\n      </div>\n      \n      <div className=\"message-content\">\n        <div className=\"message-text\">{message.content}</div>\n        \n        {message.role === 'assistant' && message.sources?.length > 0 && (\n          <div className=\"message-sources\">\n            <button onClick={() => setShowSources(!showSources)}>\n              {showSources ? 'Hide Sources' : 'Show Sources'}\n            </button>\n            \n            {showSources && (\n              <div className=\"sources-list\">\n                {message.sources.map(source => (\n                  <div key={source.id} className=\"source-item\">\n                    <a href={`/documents/${source.id}`}>{source.title}</a>\n                    <div className=\"source-excerpt\">{source.excerpt}</div>\n                  </div>\n                ))}\n              </div>\n            )}\n          </div>\n        )}\n        \n        {message.role === 'assistant' && (\n          <div className=\"message-rating\">\n            <button onClick={() => onRate(1)}>👍</button>\n            <button onClick={() => onRate(-1)}>👎</button>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n};\n```",
        "testStrategy": "1. Test WebSocket connection establishment and reconnection\n2. Verify streaming updates message content in real-time\n3. Test message sending and receiving\n4. Verify source citations display correctly\n5. Test rating functionality\n6. Verify new chat creation clears history\n7. Test responsive design on different screen sizes\n8. Verify accessibility for screen readers\n9. Test keyboard navigation\n10. Verify error handling for network issues",
        "subtasks": [],
        "updatedAt": "2026-01-07T17:42:36.141Z"
      },
      {
        "id": "75",
        "title": "Implement Asset Management Service",
        "description": "Create the backend service for managing the 5 asset types (Skills, Commands, Agents, Prompts, Workflows) generated from user content.",
        "details": "Implement the asset_management_service.py to handle CRUD operations for the 5 asset types:\n\n1. Create functions to list assets with filtering by type, department, status\n2. Implement asset detail retrieval with metadata\n3. Add update functionality for editing asset content\n4. Implement status changes (draft/published/archived)\n5. Add versioning support\n6. Implement asset reclassification\n\nPseudo-code:\n```python\n# asset_management_service.py\nclass AssetManagementService:\n    async def list_assets(self, user_id, filters=None):\n        \"\"\"List assets with optional filtering\"\"\"\n        query = {'user_id': user_id}\n        \n        # Apply filters\n        if filters:\n            if filters.get('asset_type'):\n                query['asset_type'] = filters['asset_type']\n            if filters.get('department'):\n                query['department'] = filters['department']\n            if filters.get('status'):\n                query['status'] = filters['status']\n        \n        assets = await db.generated_assets.find(\n            query,\n            order_by=['-created_at']\n        )\n        \n        return assets\n    \n    async def get_asset(self, asset_id, user_id):\n        \"\"\"Get asset details\"\"\"\n        asset = await db.generated_assets.find_one({\n            'id': asset_id,\n            'user_id': user_id\n        })\n        \n        if not asset:\n            raise AssetNotFoundError(f\"Asset {asset_id} not found\")\n        \n        return asset\n    \n    async def update_asset(self, asset_id, user_id, updates):\n        \"\"\"Update asset content or metadata\"\"\"\n        asset = await self.get_asset(asset_id, user_id)\n        \n        # Create new version if content is changing\n        if 'content' in updates and updates['content'] != asset['content']:\n            # Create new version\n            new_version = asset['version'] + 1\n            \n            # Insert as new record with parent reference\n            new_asset_id = await db.generated_assets.insert({\n                **asset,\n                'id': None,  # Generate new ID\n                'content': updates['content'],\n                'version': new_version,\n                'parent_version_id': asset_id,\n                'updated_at': datetime.now()\n            })\n            \n            return await self.get_asset(new_asset_id, user_id)\n        else:\n            # Simple update without versioning\n            allowed_updates = ['title', 'status']\n            update_data = {k: v for k, v in updates.items() if k in allowed_updates}\n            update_data['updated_at'] = datetime.now()\n            \n            if updates.get('status') == 'published':\n                update_data['published_at'] = datetime.now()\n            elif updates.get('status') == 'archived':\n                update_data['archived_at'] = datetime.now()\n            \n            await db.generated_assets.update(\n                {'id': asset_id},\n                update_data\n            )\n            \n            return await self.get_asset(asset_id, user_id)\n    \n    async def reclassify_asset(self, asset_id, user_id, new_type, new_department=None):\n        \"\"\"Change asset type or department\"\"\"\n        asset = await self.get_asset(asset_id, user_id)\n        \n        updates = {'asset_type': new_type}\n        if new_department:\n            updates['department'] = new_department\n        \n        # Update format based on new type\n        if new_type in ['skill', 'agent']:\n            updates['format'] = 'yaml'\n        elif new_type in ['command', 'prompt']:\n            updates['format'] = 'md'\n        elif new_type == 'workflow':\n            updates['format'] = 'json'\n        \n        await db.generated_assets.update(\n            {'id': asset_id},\n            updates\n        )\n        \n        # Log reclassification for feedback\n        await db.agent_feedback.insert({\n            'asset_id': asset_id,\n            'feedback_type': 'asset_reclassification',\n            'previous_type': asset['asset_type'],\n            'new_type': new_type,\n            'previous_department': asset['department'],\n            'new_department': new_department or asset['department'],\n            'user_id': user_id\n        })\n        \n        return await self.get_asset(asset_id, user_id)\n```",
        "testStrategy": "1. Unit test each method with mocked database\n2. Test filtering with various combinations\n3. Verify versioning creates new records correctly\n4. Test status changes update timestamps\n5. Verify reclassification updates format correctly\n6. Test error handling for invalid inputs\n7. Verify feedback is created on reclassification\n8. Test performance with large asset collections",
        "priority": "medium",
        "dependencies": [
          "70"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T17:51:25.474Z"
      },
      {
        "id": "76",
        "title": "Create Asset Management API Routes",
        "description": "Implement the API routes for asset management, including listing, filtering, detail view, updating, and reclassification.",
        "details": "Create the studio_assets.py routes file with the following endpoints:\n\n1. GET /api/studio/assets - List all assets (filterable)\n2. GET /api/studio/assets/{asset_id} - Get asset details\n3. PATCH /api/studio/assets/{asset_id} - Update asset content\n4. POST /api/studio/assets/{asset_id}/publish - Publish draft\n5. POST /api/studio/assets/{asset_id}/archive - Archive asset\n6. GET /api/studio/assets/{asset_id}/history - Get version history\n7. POST /api/studio/assets/{asset_id}/reclassify - Change asset type\n\nEnsure all routes are authenticated and validate input parameters.\n\nPseudo-code:\n```python\n# studio_assets.py\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom app.services.asset_management_service import AssetManagementService\nfrom app.auth import get_current_user\n\nrouter = APIRouter(prefix=\"/api/studio/assets\", tags=[\"studio\"])\nasset_service = AssetManagementService()\n\n@router.get(\"/\")\nasync def list_assets(\n    asset_type: str = None,\n    department: str = None,\n    status: str = None,\n    user=Depends(get_current_user)\n):\n    \"\"\"List assets with optional filtering\"\"\"\n    filters = {}\n    if asset_type:\n        filters['asset_type'] = asset_type\n    if department:\n        filters['department'] = department\n    if status:\n        filters['status'] = status\n    \n    assets = await asset_service.list_assets(user.id, filters)\n    return {\"assets\": assets}\n\n@router.get(\"/{asset_id}\")\nasync def get_asset(asset_id: str, user=Depends(get_current_user)):\n    \"\"\"Get asset details\"\"\"\n    try:\n        asset = await asset_service.get_asset(asset_id, user.id)\n        return asset\n    except AssetNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n\n@router.patch(\"/{asset_id}\")\nasync def update_asset(\n    asset_id: str, \n    updates: AssetUpdateRequest, \n    user=Depends(get_current_user)\n):\n    \"\"\"Update asset content or metadata\"\"\"\n    try:\n        updated_asset = await asset_service.update_asset(\n            asset_id, \n            user.id, \n            updates.dict(exclude_unset=True)\n        )\n        return updated_asset\n    except AssetNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n\n@router.post(\"/{asset_id}/publish\")\nasync def publish_asset(asset_id: str, user=Depends(get_current_user)):\n    \"\"\"Publish a draft asset\"\"\"\n    try:\n        updated_asset = await asset_service.update_asset(\n            asset_id,\n            user.id,\n            {\"status\": \"published\"}\n        )\n        return updated_asset\n    except AssetNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n\n@router.post(\"/{asset_id}/archive\")\nasync def archive_asset(asset_id: str, user=Depends(get_current_user)):\n    \"\"\"Archive an asset\"\"\"\n    try:\n        updated_asset = await asset_service.update_asset(\n            asset_id,\n            user.id,\n            {\"status\": \"archived\"}\n        )\n        return updated_asset\n    except AssetNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n\n@router.get(\"/{asset_id}/history\")\nasync def get_asset_history(asset_id: str, user=Depends(get_current_user)):\n    \"\"\"Get asset version history\"\"\"\n    try:\n        asset = await asset_service.get_asset(asset_id, user.id)\n        history = await asset_service.get_asset_history(asset_id, user.id)\n        return {\"asset\": asset, \"history\": history}\n    except AssetNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n\n@router.post(\"/{asset_id}/reclassify\")\nasync def reclassify_asset(\n    asset_id: str,\n    request: AssetReclassifyRequest,\n    user=Depends(get_current_user)\n):\n    \"\"\"Change asset type or department\"\"\"\n    try:\n        updated_asset = await asset_service.reclassify_asset(\n            asset_id,\n            user.id,\n            request.new_type,\n            request.new_department\n        )\n        return updated_asset\n    except AssetNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n```",
        "testStrategy": "1. Test each API endpoint with valid and invalid inputs\n2. Verify authentication and authorization checks\n3. Test filtering with various combinations\n4. Verify error handling and appropriate status codes\n5. Test versioning through update endpoint\n6. Verify status changes through publish/archive endpoints\n7. Test reclassification with different type combinations\n8. Verify history retrieval returns correct versions",
        "priority": "medium",
        "dependencies": [
          "75"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T18:03:57.764Z"
      },
      {
        "id": "77",
        "title": "Develop Asset Management Frontend",
        "description": "Create the frontend components for viewing, filtering, and managing the 5 asset types (Skills, Commands, Agents, Prompts, Workflows).",
        "details": "Implement the Assets frontend components:\n\n1. Create AssetsView.tsx as the main container component\n2. Implement AssetCard.tsx for displaying asset summaries\n3. Create AssetDetailModal.tsx for viewing and editing assets\n4. Implement filters for asset type, department, and status\n5. Add search functionality across asset content\n6. Implement asset versioning UI\n7. Create status change buttons (publish/archive)\n\nPseudo-code:\n```tsx\n// AssetsView.tsx\nimport { useState, useEffect } from 'react';\nimport AssetCard from './AssetCard';\nimport AssetDetailModal from './AssetDetailModal';\nimport AssetTypeFilter from './AssetTypeFilter';\nimport DepartmentFilter from './DepartmentFilter';\n\nconst AssetsView = () => {\n  const [assets, setAssets] = useState([]);\n  const [filters, setFilters] = useState({\n    assetType: null,\n    department: null,\n    status: 'all'\n  });\n  const [selectedAsset, setSelectedAsset] = useState(null);\n  const [isDetailModalOpen, setIsDetailModalOpen] = useState(false);\n  const [searchQuery, setSearchQuery] = useState('');\n  \n  // Fetch assets on mount and when filters change\n  useEffect(() => {\n    fetchAssets();\n  }, [filters]);\n  \n  const fetchAssets = async () => {\n    let url = '/api/studio/assets?';\n    if (filters.assetType) url += `asset_type=${filters.assetType}&`;\n    if (filters.department) url += `department=${filters.department}&`;\n    if (filters.status !== 'all') url += `status=${filters.status}&`;\n    \n    const response = await fetch(url);\n    const data = await response.json();\n    setAssets(data.assets);\n  };\n  \n  const handleAssetClick = (asset) => {\n    setSelectedAsset(asset);\n    setIsDetailModalOpen(true);\n  };\n  \n  const handleAssetUpdate = async (assetId, updates) => {\n    const response = await fetch(`/api/studio/assets/${assetId}`, {\n      method: 'PATCH',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(updates)\n    });\n    \n    if (response.ok) {\n      // Refresh assets\n      fetchAssets();\n      // If detail modal is open, refresh selected asset\n      if (selectedAsset?.id === assetId) {\n        const updatedAsset = await response.json();\n        setSelectedAsset(updatedAsset);\n      }\n    }\n  };\n  \n  const handleStatusChange = async (assetId, newStatus) => {\n    const endpoint = newStatus === 'published' ? 'publish' : 'archive';\n    const response = await fetch(`/api/studio/assets/${assetId}/${endpoint}`, {\n      method: 'POST'\n    });\n    \n    if (response.ok) {\n      fetchAssets();\n    }\n  };\n  \n  const handleReclassify = async (assetId, newType, newDepartment) => {\n    const response = await fetch(`/api/studio/assets/${assetId}/reclassify`, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ new_type: newType, new_department: newDepartment })\n    });\n    \n    if (response.ok) {\n      fetchAssets();\n      setIsDetailModalOpen(false);\n    }\n  };\n  \n  // Filter assets by search query\n  const filteredAssets = searchQuery\n    ? assets.filter(asset => \n        asset.title.toLowerCase().includes(searchQuery.toLowerCase()) ||\n        asset.content.toLowerCase().includes(searchQuery.toLowerCase())\n      )\n    : assets;\n  \n  return (\n    <div className=\"assets-container\">\n      <div className=\"assets-header\">\n        <h2>Assets</h2>\n        <div className=\"assets-filters\">\n          <input\n            type=\"text\"\n            placeholder=\"Search assets...\"\n            value={searchQuery}\n            onChange={e => setSearchQuery(e.target.value)}\n          />\n          <AssetTypeFilter\n            selected={filters.assetType}\n            onChange={type => setFilters({...filters, assetType: type})}\n          />\n          <DepartmentFilter\n            selected={filters.department}\n            onChange={dept => setFilters({...filters, department: dept})}\n          />\n          <select\n            value={filters.status}\n            onChange={e => setFilters({...filters, status: e.target.value})}\n          >\n            <option value=\"all\">All Statuses</option>\n            <option value=\"draft\">Drafts</option>\n            <option value=\"published\">Published</option>\n            <option value=\"archived\">Archived</option>\n          </select>\n        </div>\n      </div>\n      \n      <div className=\"assets-grid\">\n        {filteredAssets.map(asset => (\n          <AssetCard\n            key={asset.id}\n            asset={asset}\n            onClick={() => handleAssetClick(asset)}\n            onStatusChange={status => handleStatusChange(asset.id, status)}\n          />\n        ))}\n      </div>\n      \n      {isDetailModalOpen && selectedAsset && (\n        <AssetDetailModal\n          asset={selectedAsset}\n          onClose={() => setIsDetailModalOpen(false)}\n          onUpdate={updates => handleAssetUpdate(selectedAsset.id, updates)}\n          onReclassify={(newType, newDept) => \n            handleReclassify(selectedAsset.id, newType, newDept)\n          }\n        />\n      )}\n    </div>\n  );\n};\n\n// AssetCard.tsx\nconst AssetCard = ({ asset, onClick, onStatusChange }) => {\n  // Map asset type to icon and color\n  const typeConfig = {\n    skill: { icon: '⚙️', color: 'blue' },\n    command: { icon: '⚡', color: 'green' },\n    agent: { icon: '🤖', color: 'purple' },\n    prompt: { icon: '📝', color: 'orange' },\n    workflow: { icon: '🔄', color: 'teal' }\n  };\n  \n  const config = typeConfig[asset.asset_type] || { icon: '📄', color: 'gray' };\n  \n  return (\n    <div \n      className={`asset-card ${asset.status}`}\n      style={{ borderColor: config.color }}\n      onClick={onClick}\n    >\n      <div className=\"asset-header\">\n        <span className=\"asset-icon\">{config.icon}</span>\n        <span className=\"asset-title\">{asset.title}</span>\n      </div>\n      \n      <div className=\"asset-meta\">\n        <span className=\"asset-department\">{asset.department}</span>\n        <span className=\"asset-status\">{asset.status}</span>\n      </div>\n      \n      <div className=\"asset-preview\">\n        {asset.content.substring(0, 100)}...\n      </div>\n      \n      <div className=\"asset-actions\" onClick={e => e.stopPropagation()}>\n        {asset.status === 'draft' && (\n          <button onClick={() => onStatusChange('published')}>Publish</button>\n        )}\n        {asset.status !== 'archived' && (\n          <button onClick={() => onStatusChange('archived')}>Archive</button>\n        )}\n      </div>\n    </div>\n  );\n};\n\n// AssetDetailModal.tsx\nconst AssetDetailModal = ({ asset, onClose, onUpdate, onReclassify }) => {\n  const [editedContent, setEditedContent] = useState(asset.content);\n  const [editedTitle, setEditedTitle] = useState(asset.title);\n  const [newType, setNewType] = useState(asset.asset_type);\n  const [newDepartment, setNewDepartment] = useState(asset.department);\n  \n  const handleSave = () => {\n    onUpdate({\n      title: editedTitle,\n      content: editedContent\n    });\n  };\n  \n  const handleReclassify = () => {\n    onReclassify(newType, newDepartment);\n  };\n  \n  return (\n    <div className=\"modal-overlay\">\n      <div className=\"asset-detail-modal\">\n        <div className=\"modal-header\">\n          <input\n            type=\"text\"\n            value={editedTitle}\n            onChange={e => setEditedTitle(e.target.value)}\n            className=\"asset-title-input\"\n          />\n          <button onClick={onClose}>×</button>\n        </div>\n        \n        <div className=\"asset-metadata\">\n          <div>\n            <strong>Type:</strong> {asset.asset_type}\n            <strong>Department:</strong> {asset.department}\n            <strong>Status:</strong> {asset.status}\n          </div>\n          <div>\n            <strong>Created:</strong> {new Date(asset.created_at).toLocaleString()}\n            <strong>Version:</strong> {asset.version}\n          </div>\n        </div>\n        \n        <div className=\"asset-content-editor\">\n          <textarea\n            value={editedContent}\n            onChange={e => setEditedContent(e.target.value)}\n            rows={20}\n          />\n        </div>\n        \n        <div className=\"asset-source\">\n          <strong>Source:</strong>\n          {asset.source_document_title && (\n            <a href={`/documents/${asset.source_document_id}`}>\n              {asset.source_document_title}\n            </a>\n          )}\n          <div>\n            <strong>Confidence:</strong> {(asset.classification_confidence * 100).toFixed(0)}%\n          </div>\n        </div>\n        \n        <div className=\"asset-actions\">\n          <button onClick={handleSave}>Save Changes</button>\n          \n          <div className=\"reclassify-section\">\n            <h4>Reclassify Asset</h4>\n            <select value={newType} onChange={e => setNewType(e.target.value)}>\n              <option value=\"skill\">Skill (YAML)</option>\n              <option value=\"command\">Command (MD)</option>\n              <option value=\"agent\">Agent (YAML)</option>\n              <option value=\"prompt\">Prompt (MD)</option>\n              <option value=\"workflow\">Workflow (JSON)</option>\n            </select>\n            \n            <select value={newDepartment} onChange={e => setNewDepartment(e.target.value)}>\n              <option value=\"it-engineering\">IT & Engineering</option>\n              <option value=\"sales-marketing\">Sales & Marketing</option>\n              {/* Other departments */}\n            </select>\n            \n            <button onClick={handleReclassify}>Reclassify</button>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n```",
        "testStrategy": "1. Test asset listing with different filter combinations\n2. Verify search functionality works across content\n3. Test asset detail modal opens with correct data\n4. Verify editing and saving asset content\n5. Test status changes (publish/archive)\n6. Verify reclassification updates asset type and format\n7. Test responsive design on different screen sizes\n8. Verify accessibility for screen readers\n9. Test keyboard navigation in modal\n10. Verify error handling for failed API calls",
        "priority": "medium",
        "dependencies": [
          "71",
          "76"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T18:09:02.442Z"
      },
      {
        "id": "78",
        "title": "Implement Department Classification Management",
        "description": "Create the backend and frontend components for viewing and correcting department classifications of user content.",
        "details": "Implement the department classification management functionality:\n\n1. Create classification_service.py for backend operations\n2. Implement API routes in studio_classifications.py\n3. Create ClassificationsView.tsx frontend component\n4. Implement classification correction UI\n5. Add re-processing functionality for corrected classifications\n\nBackend Pseudo-code:\n```python\n# classification_service.py\nclass ClassificationService:\n    async def list_classifications(self, user_id, filters=None):\n        \"\"\"List content classifications with optional filtering\"\"\"\n        query = {'user_id': user_id}\n        \n        # Apply filters\n        if filters:\n            if filters.get('department'):\n                query['department'] = filters['department']\n            if filters.get('confidence_min'):\n                query['confidence'] = {'$gte': filters['confidence_min']}\n            if filters.get('corrected'):\n                query['user_corrected_department'] = {'$ne': None}\n        \n        classifications = await db.content_classifications.find(\n            query,\n            order_by=['-created_at']\n        )\n        \n        return classifications\n    \n    async def get_classification(self, classification_id, user_id):\n        \"\"\"Get classification details\"\"\"\n        classification = await db.content_classifications.find_one({\n            'id': classification_id,\n            'user_id': user_id\n        })\n        \n        if not classification:\n            raise ClassificationNotFoundError(f\"Classification {classification_id} not found\")\n        \n        return classification\n    \n    async def correct_classification(self, classification_id, user_id, new_department, reason=None):\n        \"\"\"Correct a misclassified content\"\"\"\n        classification = await self.get_classification(classification_id, user_id)\n        \n        # Update classification\n        await db.content_classifications.update(\n            {'id': classification_id},\n            {\n                'user_corrected_department': new_department,\n                'correction_reason': reason,\n                'corrected_at': datetime.now()\n            }\n        )\n        \n        # Add feedback for model improvement\n        await db.agent_feedback.insert({\n            'classification_id': classification_id,\n            'feedback_type': 'classification_correction',\n            'previous_department': classification['department'],\n            'new_department': new_department,\n            'reason': reason,\n            'user_id': user_id\n        })\n        \n        return await self.get_classification(classification_id, user_id)\n    \n    async def reprocess_classification(self, classification_id, user_id):\n        \"\"\"Re-run AGENT-001 with corrected classification\"\"\"\n        classification = await self.get_classification(classification_id, user_id)\n        \n        # Only reprocess if there's a user correction\n        if not classification.get('user_corrected_department'):\n            raise ValueError(\"Cannot reprocess without user correction\")\n        \n        # Get document content\n        document = await db.documents.find_one({\n            'id': classification['source_document_id'],\n            'user_id': user_id\n        })\n        \n        if not document:\n            raise DocumentNotFoundError(\"Source document not found\")\n        \n        # Queue reprocessing job with corrected department\n        job_id = await queue_manager.enqueue(\n            'reprocess_document_with_classification',\n            {\n                'document_id': document['id'],\n                'user_id': user_id,\n                'department_override': classification['user_corrected_department']\n            }\n        )\n        \n        # Update classification with job reference\n        await db.content_classifications.update(\n            {'id': classification_id},\n            {'reprocessing_job_id': job_id}\n        )\n        \n        return {'job_id': job_id}\n\n# studio_classifications.py (API routes)\n@router.get(\"/\")\nasync def list_classifications(\n    department: str = None,\n    confidence_min: float = None,\n    corrected: bool = None,\n    user=Depends(get_current_user)\n):\n    \"\"\"List classifications with optional filtering\"\"\"\n    filters = {}\n    if department:\n        filters['department'] = department\n    if confidence_min is not None:\n        filters['confidence_min'] = confidence_min\n    if corrected is not None:\n        filters['corrected'] = corrected\n    \n    classifications = await classification_service.list_classifications(user.id, filters)\n    return {\"classifications\": classifications}\n\n@router.patch(\"/{classification_id}\")\nasync def correct_classification(\n    classification_id: str,\n    request: ClassificationCorrectionRequest,\n    user=Depends(get_current_user)\n):\n    \"\"\"Correct a misclassified content\"\"\"\n    try:\n        updated = await classification_service.correct_classification(\n            classification_id,\n            user.id,\n            request.new_department,\n            request.reason\n        )\n        return updated\n    except ClassificationNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Classification not found\")\n\n@router.post(\"/{classification_id}/reprocess\")\nasync def reprocess_classification(\n    classification_id: str,\n    user=Depends(get_current_user)\n):\n    \"\"\"Re-run AGENT-001 with corrected classification\"\"\"\n    try:\n        result = await classification_service.reprocess_classification(\n            classification_id,\n            user.id\n        )\n        return result\n    except ClassificationNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Classification not found\")\n    except ValueError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n```\n\nFrontend Pseudo-code:\n```tsx\n// ClassificationsView.tsx\nimport { useState, useEffect } from 'react';\nimport ClassificationCard from './ClassificationCard';\nimport DepartmentFilter from './DepartmentFilter';\nimport ConfidenceBadge from '../common/ConfidenceBadge';\n\nconst ClassificationsView = () => {\n  const [classifications, setClassifications] = useState([]);\n  const [filters, setFilters] = useState({\n    department: null,\n    confidenceMin: null,\n    corrected: null\n  });\n  \n  useEffect(() => {\n    fetchClassifications();\n  }, [filters]);\n  \n  const fetchClassifications = async () => {\n    let url = '/api/studio/classifications?';\n    if (filters.department) url += `department=${filters.department}&`;\n    if (filters.confidenceMin) url += `confidence_min=${filters.confidenceMin}&`;\n    if (filters.corrected !== null) url += `corrected=${filters.corrected}&`;\n    \n    const response = await fetch(url);\n    const data = await response.json();\n    setClassifications(data.classifications);\n  };\n  \n  const handleCorrection = async (id, newDepartment, reason) => {\n    const response = await fetch(`/api/studio/classifications/${id}`, {\n      method: 'PATCH',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ new_department: newDepartment, reason })\n    });\n    \n    if (response.ok) {\n      fetchClassifications();\n    }\n  };\n  \n  const handleReprocess = async (id) => {\n    const response = await fetch(`/api/studio/classifications/${id}/reprocess`, {\n      method: 'POST'\n    });\n    \n    if (response.ok) {\n      // Show processing indicator\n      const updatedClassifications = classifications.map(c => \n        c.id === id ? {...c, reprocessing: true} : c\n      );\n      setClassifications(updatedClassifications);\n    }\n  };\n  \n  return (\n    <div className=\"classifications-container\">\n      <div className=\"classifications-header\">\n        <h2>Department Classifications</h2>\n        <div className=\"classifications-filters\">\n          <DepartmentFilter\n            selected={filters.department}\n            onChange={dept => setFilters({...filters, department: dept})}\n          />\n          <select\n            value={filters.confidenceMin || ''}\n            onChange={e => setFilters({\n              ...filters, \n              confidenceMin: e.target.value ? parseFloat(e.target.value) : null\n            })}\n          >\n            <option value=\"\">All Confidence</option>\n            <option value=\"0.9\">High (>90%)</option>\n            <option value=\"0.7\">Medium (>70%)</option>\n            <option value=\"0.5\">Low (>50%)</option>\n          </select>\n          <select\n            value={filters.corrected === null ? '' : filters.corrected.toString()}\n            onChange={e => setFilters({\n              ...filters, \n              corrected: e.target.value === '' ? null : e.target.value === 'true'\n            })}\n          >\n            <option value=\"\">All</option>\n            <option value=\"true\">Corrected</option>\n            <option value=\"false\">Not Corrected</option>\n          </select>\n        </div>\n      </div>\n      \n      <div className=\"classifications-list\">\n        {classifications.map(classification => (\n          <ClassificationCard\n            key={classification.id}\n            classification={classification}\n            onCorrect={(newDept, reason) => \n              handleCorrection(classification.id, newDept, reason)\n            }\n            onReprocess={() => handleReprocess(classification.id)}\n          />\n        ))}\n      </div>\n    </div>\n  );\n};\n\n// ClassificationCard.tsx\nconst ClassificationCard = ({ classification, onCorrect, onReprocess }) => {\n  const [isEditing, setIsEditing] = useState(false);\n  const [newDepartment, setNewDepartment] = useState('');\n  const [reason, setReason] = useState('');\n  \n  const handleSubmit = () => {\n    onCorrect(newDepartment, reason);\n    setIsEditing(false);\n  };\n  \n  return (\n    <div className=\"classification-card\">\n      <div className=\"classification-header\">\n        <div className=\"document-title\">\n          {classification.filename || 'Untitled Document'}\n        </div>\n        <ConfidenceBadge confidence={classification.confidence} />\n      </div>\n      \n      <div className=\"classification-content\">\n        <div className=\"content-preview\">{classification.content_preview}</div>\n        \n        <div className=\"classification-details\">\n          <div className=\"department\">\n            <strong>Department:</strong> {classification.department}\n            {classification.user_corrected_department && (\n              <span className=\"corrected\">\n                Corrected to: {classification.user_corrected_department}\n              </span>\n            )}\n          </div>\n          \n          {classification.secondary_department && (\n            <div className=\"secondary-department\">\n              <strong>Secondary:</strong> {classification.secondary_department}\n              ({(classification.secondary_confidence * 100).toFixed(0)}%)\n            </div>\n          )}\n          \n          <div className=\"keywords\">\n            <strong>Keywords:</strong>\n            {classification.keywords_matched.map(kw => (\n              <span key={kw} className=\"keyword\">{kw}</span>\n            ))}\n          </div>\n          \n          {classification.reasoning && (\n            <div className=\"reasoning\">\n              <strong>Reasoning:</strong> {classification.reasoning}\n            </div>\n          )}\n        </div>\n      </div>\n      \n      <div className=\"classification-actions\">\n        {!isEditing ? (\n          <>\n            <button onClick={() => setIsEditing(true)}>\n              Correct Classification\n            </button>\n            {classification.user_corrected_department && (\n              <button \n                onClick={onReprocess}\n                disabled={classification.reprocessing}\n              >\n                {classification.reprocessing ? 'Processing...' : 'Reprocess Content'}\n              </button>\n            )}\n          </>\n        ) : (\n          <div className=\"correction-form\">\n            <select \n              value={newDepartment} \n              onChange={e => setNewDepartment(e.target.value)}\n              required\n            >\n              <option value=\"\">Select Department</option>\n              <option value=\"it-engineering\">IT & Engineering</option>\n              <option value=\"sales-marketing\">Sales & Marketing</option>\n              {/* Other departments */}\n            </select>\n            \n            <textarea\n              placeholder=\"Reason for correction\"\n              value={reason}\n              onChange={e => setReason(e.target.value)}\n            />\n            \n            <div className=\"form-actions\">\n              <button onClick={handleSubmit}>Submit</button>\n              <button onClick={() => setIsEditing(false)}>Cancel</button>\n            </div>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n};\n```",
        "testStrategy": "1. Test classification listing with different filter combinations\n2. Verify confidence badge displays correctly based on confidence level\n3. Test correction form submission with different departments\n4. Verify reprocessing triggers the correct backend job\n5. Test error handling for invalid inputs\n6. Verify corrected classifications show both original and corrected departments\n7. Test responsive design on different screen sizes\n8. Verify accessibility for screen readers\n9. Test keyboard navigation in correction form\n10. Verify reprocessing status indicator works correctly",
        "priority": "medium",
        "dependencies": [
          "70",
          "71"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T18:24:29.657Z"
      },
      {
        "id": "79",
        "title": "Implement Feedback Collection and Dashboard",
        "description": "Create the feedback collection system and dashboard for viewing, analyzing, and responding to user feedback on AI responses.",
        "details": "Implement the feedback collection and dashboard functionality:\n\n1. Create feedback_service.py for backend operations\n2. Implement API routes in studio_feedback.py\n3. Create FeedbackDashboardView.tsx frontend component\n4. Implement FeedbackForm.tsx for detailed feedback collection\n5. Add feedback impact tracking and reporting\n\nBackend Pseudo-code:\n```python\n# feedback_service.py\nclass FeedbackService:\n    async def list_feedback(self, user_id, filters=None):\n        \"\"\"List feedback with optional filtering\"\"\"\n        query = {'user_id': user_id}\n        \n        # Apply filters\n        if filters:\n            if filters.get('feedback_type'):\n                query['feedback_type'] = filters['feedback_type']\n            if filters.get('rating'):\n                query['rating'] = filters['rating']\n        \n        feedback = await db.agent_feedback.find(\n            query,\n            order_by=['-created_at']\n        )\n        \n        return feedback\n    \n    async def submit_feedback(self, user_id, feedback_data):\n        \"\"\"Submit new feedback\"\"\"\n        feedback_id = await db.agent_feedback.insert({\n            **feedback_data,\n            'user_id': user_id,\n            'created_at': datetime.now()\n        })\n        \n        # If message_id is provided, update the message with feedback reference\n        if feedback_data.get('message_id'):\n            await db.studio_kb_messages.update(\n                {'id': feedback_data['message_id']},\n                {'feedback_id': feedback_id}\n            )\n        \n        return await db.agent_feedback.find_one({'id': feedback_id})\n    \n    async def get_feedback_stats(self, user_id):\n        \"\"\"Get feedback statistics\"\"\"\n        stats = await db.query(\"\"\"\n            SELECT \n                feedback_type, \n                COUNT(*) as count,\n                AVG(rating) as avg_rating\n            FROM agent_feedback\n            WHERE user_id = :user_id\n            GROUP BY feedback_type\n        \"\"\", {'user_id': user_id})\n        \n        return stats\n    \n    async def get_feedback_impact(self, user_id):\n        \"\"\"Show how feedback improved responses\"\"\"\n        # Get feedback with corrections\n        corrections = await db.agent_feedback.find({\n            'user_id': user_id,\n            'feedback_type': 'correction',\n            'improvement_suggestions': {'$ne': None}\n        })\n        \n        # For each correction, find similar queries and compare responses\n        impact_data = []\n        for correction in corrections:\n            similar_queries = await self._find_similar_queries(\n                correction['query_text'],\n                user_id\n            )\n            \n            if similar_queries:\n                # Compare response quality before and after feedback\n                before_quality = await self._calculate_response_quality(\n                    similar_queries['before'],\n                    correction\n                )\n                \n                after_quality = await self._calculate_response_quality(\n                    similar_queries['after'],\n                    correction\n                )\n                \n                impact_data.append({\n                    'feedback_id': correction['id'],\n                    'query_text': correction['query_text'],\n                    'before_quality': before_quality,\n                    'after_quality': after_quality,\n                    'improvement': after_quality - before_quality\n                })\n        \n        return impact_data\n    \n    async def _find_similar_queries(self, query_text, user_id):\n        \"\"\"Find similar queries before and after feedback\"\"\"\n        # Implementation would use vector similarity search\n        # This is a simplified placeholder\n        return {\n            'before': [...],  # Similar queries before feedback\n            'after': [...]    # Similar queries after feedback\n        }\n    \n    async def _calculate_response_quality(self, queries, correction):\n        \"\"\"Calculate response quality score\"\"\"\n        # Implementation would use various metrics\n        # This is a simplified placeholder\n        return 0.75  # Example score\n\n# studio_feedback.py (API routes)\n@router.get(\"/\")\nasync def list_feedback(\n    feedback_type: str = None,\n    rating: int = None,\n    user=Depends(get_current_user)\n):\n    \"\"\"List feedback with optional filtering\"\"\"\n    filters = {}\n    if feedback_type:\n        filters['feedback_type'] = feedback_type\n    if rating is not None:\n        filters['rating'] = rating\n    \n    feedback = await feedback_service.list_feedback(user.id, filters)\n    return {\"feedback\": feedback}\n\n@router.post(\"/\")\nasync def submit_feedback(\n    request: FeedbackSubmitRequest,\n    user=Depends(get_current_user)\n):\n    \"\"\"Submit new feedback\"\"\"\n    feedback = await feedback_service.submit_feedback(\n        user.id,\n        request.dict()\n    )\n    return feedback\n\n@router.get(\"/stats\")\nasync def get_feedback_stats(user=Depends(get_current_user)):\n    \"\"\"Get feedback statistics\"\"\"\n    stats = await feedback_service.get_feedback_stats(user.id)\n    return {\"stats\": stats}\n\n@router.get(\"/impact\")\nasync def get_feedback_impact(user=Depends(get_current_user)):\n    \"\"\"Show how feedback improved responses\"\"\"\n    impact = await feedback_service.get_feedback_impact(user.id)\n    return {\"impact\": impact}\n```\n\nFrontend Pseudo-code:\n```tsx\n// FeedbackDashboardView.tsx\nimport { useState, useEffect } from 'react';\nimport FeedbackItem from './FeedbackItem';\nimport FeedbackStats from './FeedbackStats';\nimport FeedbackImpact from './FeedbackImpact';\n\nconst FeedbackDashboardView = () => {\n  const [feedback, setFeedback] = useState([]);\n  const [stats, setStats] = useState([]);\n  const [impact, setImpact] = useState([]);\n  const [filters, setFilters] = useState({\n    feedbackType: null,\n    rating: null\n  });\n  const [activeTab, setActiveTab] = useState('feedback');\n  \n  useEffect(() => {\n    fetchFeedback();\n    fetchStats();\n    fetchImpact();\n  }, [filters]);\n  \n  const fetchFeedback = async () => {\n    let url = '/api/studio/feedback?';\n    if (filters.feedbackType) url += `feedback_type=${filters.feedbackType}&`;\n    if (filters.rating !== null) url += `rating=${filters.rating}&`;\n    \n    const response = await fetch(url);\n    const data = await response.json();\n    setFeedback(data.feedback);\n  };\n  \n  const fetchStats = async () => {\n    const response = await fetch('/api/studio/feedback/stats');\n    const data = await response.json();\n    setStats(data.stats);\n  };\n  \n  const fetchImpact = async () => {\n    const response = await fetch('/api/studio/feedback/impact');\n    const data = await response.json();\n    setImpact(data.impact);\n  };\n  \n  return (\n    <div className=\"feedback-dashboard-container\">\n      <div className=\"feedback-header\">\n        <h2>Feedback Dashboard</h2>\n        <div className=\"feedback-tabs\">\n          <button\n            className={activeTab === 'feedback' ? 'active' : ''}\n            onClick={() => setActiveTab('feedback')}\n          >\n            Feedback\n          </button>\n          <button\n            className={activeTab === 'stats' ? 'active' : ''}\n            onClick={() => setActiveTab('stats')}\n          >\n            Statistics\n          </button>\n          <button\n            className={activeTab === 'impact' ? 'active' : ''}\n            onClick={() => setActiveTab('impact')}\n          >\n            Impact\n          </button>\n        </div>\n      </div>\n      \n      {activeTab === 'feedback' && (\n        <div className=\"feedback-list-container\">\n          <div className=\"feedback-filters\">\n            <select\n              value={filters.feedbackType || ''}\n              onChange={e => setFilters({\n                ...filters, \n                feedbackType: e.target.value || null\n              })}\n            >\n              <option value=\"\">All Types</option>\n              <option value=\"kb_chat_rating\">KB Chat Rating</option>\n              <option value=\"classification_correction\">Classification Correction</option>\n              <option value=\"asset_reclassification\">Asset Reclassification</option>\n              <option value=\"correction\">Response Correction</option>\n            </select>\n            \n            <select\n              value={filters.rating === null ? '' : filters.rating.toString()}\n              onChange={e => setFilters({\n                ...filters, \n                rating: e.target.value === '' ? null : parseInt(e.target.value)\n              })}\n            >\n              <option value=\"\">All Ratings</option>\n              <option value=\"1\">Positive</option>\n              <option value=\"0\">Neutral</option>\n              <option value=\"-1\">Negative</option>\n            </select>\n          </div>\n          \n          <div className=\"feedback-list\">\n            {feedback.map(item => (\n              <FeedbackItem key={item.id} feedback={item} />\n            ))}\n          </div>\n        </div>\n      )}\n      \n      {activeTab === 'stats' && (\n        <FeedbackStats stats={stats} />\n      )}\n      \n      {activeTab === 'impact' && (\n        <FeedbackImpact impact={impact} />\n      )}\n    </div>\n  );\n};\n\n// FeedbackItem.tsx\nconst FeedbackItem = ({ feedback }) => {\n  return (\n    <div className=\"feedback-item\">\n      <div className=\"feedback-header\">\n        <div className=\"feedback-type\">{feedback.feedback_type}</div>\n        <div className=\"feedback-rating\">\n          {feedback.rating > 0 ? '👍' : feedback.rating < 0 ? '👎' : '😐'}\n        </div>\n        <div className=\"feedback-date\">\n          {new Date(feedback.created_at).toLocaleString()}\n        </div>\n      </div>\n      \n      {feedback.query_text && (\n        <div className=\"feedback-query\">\n          <strong>Query:</strong> {feedback.query_text}\n        </div>\n      )}\n      \n      {feedback.feedback_text && (\n        <div className=\"feedback-text\">\n          <strong>Feedback:</strong> {feedback.feedback_text}\n        </div>\n      )}\n      \n      {feedback.improvement_suggestions && (\n        <div className=\"feedback-suggestions\">\n          <strong>Suggestions:</strong> {feedback.improvement_suggestions}\n        </div>\n      )}\n      \n      {feedback.previous_department && (\n        <div className=\"feedback-correction\">\n          <strong>Corrected:</strong> \n          {feedback.previous_department} → {feedback.new_department}\n        </div>\n      )}\n    </div>\n  );\n};\n\n// FeedbackForm.tsx (for detailed feedback collection)\nconst FeedbackForm = ({ messageId, queryText, onSubmit, onCancel }) => {\n  const [rating, setRating] = useState(0);\n  const [feedbackText, setFeedbackText] = useState('');\n  const [suggestions, setSuggestions] = useState('');\n  const [routingCorrect, setRoutingCorrect] = useState(true);\n  \n  const handleSubmit = () => {\n    onSubmit({\n      message_id: messageId,\n      query_text: queryText,\n      feedback_type: 'correction',\n      rating,\n      feedback_text: feedbackText,\n      improvement_suggestions: suggestions,\n      was_routing_correct: routingCorrect\n    });\n  };\n  \n  return (\n    <div className=\"feedback-form\">\n      <h3>Provide Detailed Feedback</h3>\n      \n      <div className=\"rating-section\">\n        <div>How would you rate this response?</div>\n        <div className=\"rating-buttons\">\n          <button \n            className={rating === 1 ? 'active' : ''}\n            onClick={() => setRating(1)}\n          >\n            👍 Helpful\n          </button>\n          <button \n            className={rating === 0 ? 'active' : ''}\n            onClick={() => setRating(0)}\n          >\n            😐 Neutral\n          </button>\n          <button \n            className={rating === -1 ? 'active' : ''}\n            onClick={() => setRating(-1)}\n          >\n            👎 Not Helpful\n          </button>\n        </div>\n      </div>\n      \n      <div className=\"feedback-section\">\n        <label>What was wrong with the response?</label>\n        <textarea\n          value={feedbackText}\n          onChange={e => setFeedbackText(e.target.value)}\n          placeholder=\"Please describe what was wrong...\"\n        />\n      </div>\n      \n      <div className=\"suggestions-section\">\n        <label>How could the response be improved?</label>\n        <textarea\n          value={suggestions}\n          onChange={e => setSuggestions(e.target.value)}\n          placeholder=\"Please suggest improvements...\"\n        />\n      </div>\n      \n      <div className=\"routing-section\">\n        <label>\n          <input\n            type=\"checkbox\"\n            checked={routingCorrect}\n            onChange={e => setRoutingCorrect(e.target.checked)}\n          />\n          Was this query routed to the right workflow?\n        </label>\n      </div>\n      \n      <div className=\"form-actions\">\n        <button onClick={handleSubmit}>Submit Feedback</button>\n        <button onClick={onCancel}>Cancel</button>\n      </div>\n    </div>\n  );\n};\n```",
        "testStrategy": "1. Test feedback listing with different filter combinations\n2. Verify feedback submission with various feedback types\n3. Test statistics calculation and display\n4. Verify impact tracking shows improvement metrics\n5. Test detailed feedback form submission\n6. Verify feedback is linked to messages correctly\n7. Test responsive design on different screen sizes\n8. Verify accessibility for screen readers\n9. Test keyboard navigation in feedback form\n10. Verify error handling for failed API calls",
        "priority": "high",
        "dependencies": [
          "70",
          "71"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T19:14:54.238Z"
      },
      {
        "id": "80",
        "title": "Implement Main Chat Integration with KB Mode",
        "description": "Enhance the main chat interface with KB Chat mode toggle, feedback buttons, and response metadata to provide alternative access to AI Studio features.",
        "details": "Implement the main chat integration with KB mode:\n\n1. Add \"Chat with KB\" mode toggle in main chat\n2. Add feedback buttons to all chat responses\n3. Add \"Improve this\" action button on AI responses\n4. Show agent/workflow used for transparency\n5. Add quick link to AI Studio for advanced settings\n6. Show department classification for queries\n\nPseudo-code:\n```tsx\n// ChatView.tsx (existing component)\nimport { useState, useEffect } from 'react';\nimport KBModeToggle from './KBModeToggle';\nimport FeedbackButtons from './FeedbackButtons';\nimport ResponseMetadata from './ResponseMetadata';\nimport FeedbackForm from '../studio/FeedbackForm';\n\nconst ChatView = ({ projectId }) => {\n  // Existing state\n  const [messages, setMessages] = useState([]);\n  const [input, setInput] = useState('');\n  \n  // New state for KB mode\n  const [isKBMode, setIsKBMode] = useState(false);\n  const [selectedMessageId, setSelectedMessageId] = useState(null);\n  const [showFeedbackForm, setShowFeedbackForm] = useState(false);\n  \n  // Fetch messages on mount\n  useEffect(() => {\n    fetchMessages();\n  }, [projectId, isKBMode]);\n  \n  const fetchMessages = async () => {\n    // If KB mode, fetch from KB chat API\n    // Otherwise fetch from project chat API\n    const endpoint = isKBMode \n      ? '/api/studio/kb-chat/history'\n      : `/api/projects/${projectId}/chat/messages`;\n    \n    const response = await fetch(endpoint);\n    const data = await response.json();\n    setMessages(data.messages);\n  };\n  \n  const sendMessage = async () => {\n    if (!input.trim()) return;\n    \n    // Add user message\n    const userMessage = { role: 'user', content: input, id: Date.now() };\n    setMessages(prev => [...prev, userMessage]);\n    \n    // Send to appropriate endpoint based on mode\n    const endpoint = isKBMode\n      ? '/api/studio/kb-chat'\n      : `/api/projects/${projectId}/chat/messages`;\n    \n    const response = await fetch(endpoint, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ message: input })\n    });\n    \n    const data = await response.json();\n    \n    // Add AI response\n    const aiMessage = {\n      role: 'assistant',\n      content: data.content,\n      id: data.message_id,\n      sources: data.sources || [],\n      workflow: data.workflow_used,\n      department: data.department,\n      agent: data.agent_id\n    };\n    \n    setMessages(prev => [...prev, aiMessage]);\n    setInput('');\n  };\n  \n  const handleRating = async (messageId, rating) => {\n    const endpoint = isKBMode\n      ? `/api/studio/kb-chat/${messageId}/rate`\n      : `/api/projects/${projectId}/chat/messages/${messageId}/rate`;\n    \n    await fetch(endpoint, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ rating })\n    });\n    \n    // If negative rating, show detailed feedback form\n    if (rating < 0) {\n      setSelectedMessageId(messageId);\n      setShowFeedbackForm(true);\n    }\n  };\n  \n  const handleDetailedFeedback = async (feedbackData) => {\n    await fetch('/api/studio/feedback', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(feedbackData)\n    });\n    \n    setShowFeedbackForm(false);\n    setSelectedMessageId(null);\n  };\n  \n  const handleImprove = (messageId) => {\n    setSelectedMessageId(messageId);\n    setShowFeedbackForm(true);\n  };\n  \n  return (\n    <div className=\"chat-container\">\n      <div className=\"chat-header\">\n        <h2>{isKBMode ? 'Knowledge Base Chat' : 'Project Chat'}</h2>\n        <KBModeToggle \n          isKBMode={isKBMode} \n          onChange={setIsKBMode} \n        />\n        {isKBMode && (\n          <a href=\"/studio/kb-chat\" className=\"studio-link\">\n            Open in AI Studio\n          </a>\n        )}\n      </div>\n      \n      <div className=\"chat-messages\">\n        {messages.map(message => (\n          <div key={message.id} className={`chat-message ${message.role}`}>\n            <div className=\"message-content\">{message.content}</div>\n            \n            {message.role === 'assistant' && (\n              <>\n                <ResponseMetadata\n                  workflow={message.workflow}\n                  agent={message.agent}\n                  department={message.department}\n                  sources={message.sources}\n                />\n                \n                <div className=\"message-actions\">\n                  <FeedbackButtons\n                    onRate={rating => handleRating(message.id, rating)}\n                  />\n                  <button \n                    className=\"improve-button\"\n                    onClick={() => handleImprove(message.id)}\n                  >\n                    Improve this\n                  </button>\n                </div>\n              </>\n            )}\n          </div>\n        ))}\n      </div>\n      \n      <div className=\"chat-input\">\n        <input\n          type=\"text\"\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          onKeyDown={e => e.key === 'Enter' && sendMessage()}\n          placeholder={isKBMode ? \"Ask your knowledge base...\" : \"Chat with your project...\"}\n        />\n        <button onClick={sendMessage}>Send</button>\n      </div>\n      \n      {showFeedbackForm && (\n        <FeedbackForm\n          messageId={selectedMessageId}\n          queryText={messages.find(m => m.role === 'user' && \n            messages.findIndex(am => am.id === selectedMessageId) > \n            messages.findIndex(um => um.id === m.id))?.content}\n          onSubmit={handleDetailedFeedback}\n          onCancel={() => setShowFeedbackForm(false)}\n        />\n      )}\n    </div>\n  );\n};\n\n// KBModeToggle.tsx\nconst KBModeToggle = ({ isKBMode, onChange }) => {\n  return (\n    <div className=\"kb-mode-toggle\">\n      <button\n        className={!isKBMode ? 'active' : ''}\n        onClick={() => onChange(false)}\n      >\n        Project Chat\n      </button>\n      <button\n        className={isKBMode ? 'active' : ''}\n        onClick={() => onChange(true)}\n      >\n        KB Chat\n      </button>\n    </div>\n  );\n};\n\n// ResponseMetadata.tsx\nconst ResponseMetadata = ({ workflow, agent, department, sources }) => {\n  const [showDetails, setShowDetails] = useState(false);\n  \n  return (\n    <div className=\"response-metadata\">\n      <button \n        className=\"metadata-toggle\"\n        onClick={() => setShowDetails(!showDetails)}\n      >\n        {showDetails ? 'Hide Details' : 'Show Details'}\n      </button>\n      \n      {showDetails && (\n        <div className=\"metadata-details\">\n          {workflow && (\n            <div className=\"metadata-item\">\n              <span className=\"metadata-label\">Workflow:</span>\n              <span className=\"metadata-value\">{workflow}</span>\n            </div>\n          )}\n          \n          {agent && (\n            <div className=\"metadata-item\">\n              <span className=\"metadata-label\">Agent:</span>\n              <span className=\"metadata-value\">{agent}</span>\n            </div>\n          )}\n          \n          {department && (\n            <div className=\"metadata-item\">\n              <span className=\"metadata-label\">Department:</span>\n              <span className=\"metadata-value\">{department}</span>\n            </div>\n          )}\n          \n          {sources && sources.length > 0 && (\n            <div className=\"metadata-sources\">\n              <span className=\"metadata-label\">Sources:</span>\n              <ul>\n                {sources.map(source => (\n                  <li key={source.id}>\n                    <a href={`/documents/${source.id}`}>{source.title}</a>\n                  </li>\n                ))}\n              </ul>\n            </div>\n          )}\n        </div>\n      )}\n    </div>\n  );\n};\n\n// FeedbackButtons.tsx\nconst FeedbackButtons = ({ onRate }) => {\n  return (\n    <div className=\"feedback-buttons\">\n      <button onClick={() => onRate(1)} className=\"thumbs-up\">👍</button>\n      <button onClick={() => onRate(-1)} className=\"thumbs-down\">👎</button>\n    </div>\n  );\n};\n```",
        "testStrategy": "1. Test KB mode toggle switches between project and KB chat\n2. Verify feedback buttons trigger rating API calls\n3. Test \"Improve this\" button shows detailed feedback form\n4. Verify response metadata displays workflow, agent, and department\n5. Test source citations display correctly\n6. Verify quick link to AI Studio works\n7. Test responsive design on different screen sizes\n8. Verify accessibility for screen readers\n9. Test keyboard navigation\n10. Verify error handling for failed API calls",
        "priority": "medium",
        "dependencies": [
          "72",
          "73",
          "74",
          "79"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T19:33:40.604Z"
      },
      {
        "id": "81",
        "title": "Create AI Studio Navigation Item",
        "description": "Implement the AI Studio navigation item in the sidebar between File Uploads and Settings, including notification badge for pending clarifications.",
        "details": "Add a new navigation item for AI Studio in the sidebar menu between File Uploads and Settings. The navigation item should include:\n\n1. Icon representing AI Studio (brain or knowledge icon)\n2. Text label \"AI Studio\"\n3. Notification badge that shows count of pending clarifications\n4. Yellow dot when clarifications are pending\n5. Red dot when clarifications are pending > 24 hours\n\nImplementation steps:\n1. Update the sidebar navigation component to include the new item\n2. Create a notification badge component that can display counts\n3. Implement the logic to determine badge color based on clarification status\n4. Connect to the backend API to fetch pending clarification counts\n5. Add click handler to navigate to AI Studio view\n\nExample code:\n```jsx\nconst AIStudioNavItem = () => {\n  const [pendingCount, setPendingCount] = useState(0);\n  const [oldestPending, setOldestPending] = useState(null);\n  \n  useEffect(() => {\n    // Fetch pending clarifications\n    const fetchPendingClarifications = async () => {\n      const response = await api.getClarificationCounts();\n      setPendingCount(response.count);\n      setOldestPending(response.oldestTimestamp);\n    };\n    \n    fetchPendingClarifications();\n    const interval = setInterval(fetchPendingClarifications, 60000);\n    return () => clearInterval(interval);\n  }, []);\n  \n  const getNotificationColor = () => {\n    if (!pendingCount) return null;\n    if (oldestPending && (new Date() - new Date(oldestPending)) > 24 * 60 * 60 * 1000) {\n      return 'red';\n    }\n    return 'yellow';\n  };\n  \n  return (\n    <NavItem \n      to=\"/ai-studio\"\n      icon={<BrainIcon />}\n      label=\"AI Studio\"\n      notificationDot={getNotificationColor()}\n      badge={pendingCount > 0 ? pendingCount : null}\n    />\n  );\n};\n```",
        "testStrategy": "1. Unit test the navigation component to verify it renders correctly\n2. Test the notification badge logic with different pending clarification counts\n3. Test the color logic for yellow and red notifications based on time thresholds\n4. Integration test to verify the navigation item appears in the correct position in the sidebar\n5. E2E test to verify clicking the navigation item navigates to AI Studio\n6. Verify the badge updates when clarifications are added or resolved",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T19:49:39.504Z"
      },
      {
        "id": "82",
        "title": "Implement CKO Conversation Interface",
        "description": "Create the core conversational interface for the Chief Knowledge Officer (CKO) persona with real-time response streaming via WebSocket, supporting NFR-011 for conversation history management.",
        "status": "done",
        "dependencies": [
          "81"
        ],
        "priority": "high",
        "details": "Implement the primary conversation interface for interacting with the CKO. This is the main component of AI Studio and should be the default view when navigating to AI Studio.\n\nKey components:\n1. Message thread display showing conversation history\n2. Input field for user messages\n3. Real-time streaming of CKO responses via WebSocket\n4. Source citation display with expandable details\n5. Conversation history persistence (supporting NFR-011: retain last 50 conversations)\n6. Support for creating new conversations and switching between them\n7. Conversation pruning and context summarization for memory management\n\nImplementation steps:\n1. Create the conversation container component\n2. Implement WebSocket connection for real-time streaming\n3. Build message display components with different styling for user vs CKO\n4. Create expandable citation component for source references\n5. Implement conversation history storage and retrieval with 50-conversation limit\n6. Add conversation management UI (new, switch, etc.)\n7. Implement conversation pruning logic to maintain only the 50 most recent conversations\n8. Create context summarization for older conversations to optimize LLM context window usage\n\nExample WebSocket implementation:\n```javascript\nconst setupWebSocket = (sessionId) => {\n  const ws = new WebSocket(`${WS_BASE_URL}/cko/session/${sessionId}`);\n  \n  ws.onopen = () => {\n    console.log('WebSocket connection established');\n    setConnectionStatus('connected');\n  };\n  \n  ws.onmessage = (event) => {\n    const data = JSON.parse(event.data);\n    if (data.type === 'token') {\n      // Handle streaming token\n      appendToCurrentMessage(data.content);\n    } else if (data.type === 'message_complete') {\n      // Handle message completion\n      finalizeCurrentMessage(data.messageId, data.sources);\n    }\n  };\n  \n  ws.onclose = () => {\n    console.log('WebSocket connection closed');\n    setConnectionStatus('disconnected');\n    // Attempt reconnection after delay\n    setTimeout(() => setupWebSocket(sessionId), 3000);\n  };\n  \n  return ws;\n};\n```\n\nCitation component:\n```jsx\nconst SourceCitation = ({ source }) => {\n  const [expanded, setExpanded] = useState(false);\n  \n  return (\n    <div className=\"citation\">\n      <button onClick={() => setExpanded(!expanded)}>\n        {source.title} {expanded ? '▼' : '▶'}\n      </button>\n      {expanded && (\n        <div className=\"citation-details\">\n          <p>Document: {source.documentName}</p>\n          <p>Department: {source.department}</p>\n          <p>Confidence: {source.confidence}%</p>\n          <p>Extract: \"{source.extract}\"</p>\n        </div>\n      )}\n    </div>\n  );\n};\n```\n\nConversation History Management (NFR-011):\n```javascript\nconst manageConversationHistory = async (userId) => {\n  // Get all user conversations\n  const conversations = await fetchUserConversations(userId);\n  \n  // If more than 50 conversations exist, prune the oldest\n  if (conversations.length > 50) {\n    const conversationsToKeep = conversations.slice(0, 50);\n    const conversationsToPrune = conversations.slice(50);\n    \n    // For pruned conversations, generate and store summaries\n    for (const conv of conversationsToPrune) {\n      const summary = await generateConversationSummary(conv.id);\n      await storeConversationSummary(conv.id, summary);\n      await archiveConversation(conv.id);\n    }\n    \n    // Update active conversations list\n    await updateActiveConversations(userId, conversationsToKeep.map(c => c.id));\n  }\n  \n  return conversations.slice(0, 50);\n};\n\nconst generateConversationSummary = async (conversationId) => {\n  const messages = await fetchConversationMessages(conversationId);\n  // Use LLM to generate a concise summary of the conversation\n  // This summary will be used when the conversation needs to be referenced\n  // but full context isn't needed in the active memory\n  return await callSummarizationEndpoint(messages);\n};\n```",
        "testStrategy": "1. Unit test the conversation components (message display, input field, etc.)\n2. Test WebSocket connection and message streaming with mock server\n3. Verify source citations display correctly and can be expanded/collapsed\n4. Test conversation persistence by creating a conversation, refreshing the page, and verifying history is maintained\n5. Test conversation switching functionality\n6. Performance test response streaming with various message sizes\n7. Verify first-token response time is < 3 seconds for 95% of queries (SC-001)\n8. Verify CKO provides relevant source citations in > 90% of factual responses (SC-002)\n9. Test NFR-011 compliance by creating more than 50 conversations and verifying:\n   - Only the 50 most recent conversations are readily accessible\n   - Older conversations are properly summarized and archived\n   - Memory usage stays within expected bounds\n10. Verify context summarization produces accurate and useful summaries\n11. Test memory management optimizations under high load conditions",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement conversation history pruning",
            "description": "Create a system to maintain only the 50 most recent conversations in active memory as required by NFR-011.",
            "dependencies": [],
            "details": "Implement logic to track conversation count per user and automatically prune conversations when the count exceeds 50. The pruning process should:\n1. Identify the oldest conversations beyond the 50-conversation limit\n2. Mark these conversations for archiving\n3. Update the UI to show only the 50 most recent conversations\n4. Provide a mechanism to access archived conversations if needed\n\nThis should be implemented as a background process that runs periodically and after new conversation creation.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement conversation context summarization",
            "description": "Create a system to generate and store summaries of older conversations to optimize LLM context window usage.",
            "dependencies": [],
            "details": "Implement a summarization service that:\n1. Processes conversations marked for archiving\n2. Uses the LLM to generate concise summaries capturing key points and decisions\n3. Stores these summaries alongside the full conversation data\n4. Provides an API to retrieve summaries when older context is needed\n\nThe summarization should preserve important factual information while reducing token count by at least 70% compared to the full conversation.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement memory management optimizations",
            "description": "Create a system to optimize LLM context window usage based on conversation relevance and recency.",
            "dependencies": [],
            "details": "Implement memory management that:\n1. Prioritizes recent and relevant conversations in the context window\n2. Uses conversation summaries for older but potentially relevant conversations\n3. Implements a sliding window approach for very long active conversations\n4. Tracks token usage to ensure we stay within LLM context limits\n5. Provides metrics on memory usage and optimization effectiveness\n\nThe system should dynamically adjust what's included in the context based on the current conversation topic and available context space.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-07T19:56:01.341Z"
      },
      {
        "id": "83",
        "title": "Implement CKO Clarification System",
        "description": "Create the clarification system that allows CKO to ask questions when classification confidence is below 70% and track user responses.",
        "details": "Implement the clarification system that enables CKO to ask users for input when it's uncertain about classifications. This system is critical for improving accuracy through human-in-the-loop feedback.\n\nKey components:\n1. Clarification message display with yellow highlight (#FEF3C7 background)\n2. Inline response buttons for quick user selection\n3. Skip option with \"best guess\" fallback\n4. Persistence of user preferences from clarification responses\n5. Auto-skip logic for clarifications pending > 7 days\n\nImplementation steps:\n1. Create clarification message component with distinct styling\n2. Implement inline response buttons for quick selection\n3. Add skip functionality with best guess option\n4. Create backend API for storing and retrieving user preferences\n5. Implement auto-skip logic for old clarifications\n\nExample clarification component:\n```jsx\nconst ClarificationMessage = ({ clarification, onRespond, onSkip }) => {\n  return (\n    <div className=\"message clarification\" style={{ backgroundColor: '#FEF3C7' }}>\n      <div className=\"message-content\">\n        <p>{clarification.question}</p>\n        <div className=\"clarification-options\">\n          {clarification.options.map(option => (\n            <button \n              key={option.value} \n              onClick={() => onRespond(clarification.id, option.value)}\n              className=\"option-button\"\n            >\n              {option.label}\n            </button>\n          ))}\n          <button \n            onClick={() => onSkip(clarification.id)}\n            className=\"skip-button\"\n          >\n            Skip (use best guess)\n          </button>\n        </div>\n      </div>\n    </div>\n  );\n};\n```\n\nBackend logic for auto-skip:\n```javascript\n// Scheduled job to auto-skip old clarifications\nconst autoSkipOldClarifications = async () => {\n  const sevenDaysAgo = new Date();\n  sevenDaysAgo.setDate(sevenDaysAgo.getDate() - 7);\n  \n  const oldClarifications = await db.query(\n    'SELECT * FROM cko_messages WHERE is_clarification = true AND created_at < $1 AND status = \\'pending\\'',\n    [sevenDaysAgo]\n  );\n  \n  for (const clarification of oldClarifications) {\n    await db.query(\n      'UPDATE cko_messages SET status = \\'auto_skipped\\', best_guess = $1, updated_at = NOW() WHERE id = $2',\n      [clarification.best_guess, clarification.id]\n    );\n    \n    // Log the auto-skip decision\n    await db.query(\n      'INSERT INTO cko_logs (message_id, action, details) VALUES ($1, \\'auto_skip\\', $2)',\n      [clarification.id, JSON.stringify({ reason: 'Exceeded 7-day wait period' })]\n    );\n  }\n};\n```",
        "testStrategy": "1. Unit test the clarification message component with various options\n2. Test the response handling for clarification buttons\n3. Verify skip functionality works correctly\n4. Test that user preferences are correctly stored and retrieved\n5. Test auto-skip logic with clarifications of different ages\n6. Verify clarification messages are highlighted with the correct background color\n7. Measure time to complete clarification response (should be < 10 seconds per SC-003)\n8. Test that the notification system correctly shows pending clarifications\n9. Verify that CKO remembers and applies user preferences from previous clarifications",
        "priority": "high",
        "dependencies": [
          "82"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T19:56:50.128Z"
      },
      {
        "id": "84",
        "title": "Implement Data Weights Configuration System",
        "description": "Create the system for configuring how CKO weighs different content sources by department, recency, and source type.",
        "status": "done",
        "dependencies": [
          "82"
        ],
        "priority": "high",
        "details": "Implement the data weights configuration system that allows users to personalize how CKO prioritizes different content sources. This system is essential for ensuring CKO responses are relevant to user priorities.\n\nKey components:\n1. Department weight sliders (0.0-2.0 range)\n2. Recency weighting options (last 30 days, last year, older)\n3. Source type weighting (PDF, video, audio, web, notes)\n4. Document pinning and muting functionality\n5. Weight presets (Balanced, Recent Focus, Verified Only)\n6. Conversational weight adjustment via CKO\n\nImplementation steps:\n1. Create weights configuration UI with sliders and toggles\n2. Implement backend storage for user weight preferences\n3. Create API for retrieving and applying weights during retrieval\n4. Implement document pinning and muting functionality\n5. Add preset configurations for quick selection\n6. Enable CKO to adjust weights via conversation commands\n\nExample weights configuration component:\n```jsx\nconst WeightsConfiguration = ({ weights, onChange }) => {\n  const departments = [\n    { id: 'it-engineering', name: 'IT & Engineering' },\n    { id: 'sales-marketing', name: 'Sales & Marketing' },\n    // ... other departments\n  ];\n  \n  const handleDepartmentChange = (deptId, value) => {\n    onChange({\n      ...weights,\n      departments: {\n        ...weights.departments,\n        [deptId]: parseFloat(value)\n      }\n    });\n  };\n  \n  const handleRecencyChange = (recencyKey, value) => {\n    onChange({\n      ...weights,\n      recency: {\n        ...weights.recency,\n        [recencyKey]: parseFloat(value)\n      }\n    });\n  };\n  \n  const applyPreset = (presetKey) => {\n    const presets = {\n      balanced: { /* default balanced weights */ },\n      recentFocus: { /* weights prioritizing recent content */ },\n      verifiedOnly: { /* weights for verified content only */ }\n    };\n    onChange(presets[presetKey]);\n  };\n  \n  return (\n    <div className=\"weights-configuration\">\n      <div className=\"presets\">\n        <button onClick={() => applyPreset('balanced')}>Balanced</button>\n        <button onClick={() => applyPreset('recentFocus')}>Recent Focus</button>\n        <button onClick={() => applyPreset('verifiedOnly')}>Verified Only</button>\n      </div>\n      \n      <h3>Department Weights</h3>\n      {departments.map(dept => (\n        <div key={dept.id} className=\"weight-slider\">\n          <label>{dept.name}</label>\n          <input \n            type=\"range\" \n            min=\"0\" \n            max=\"2\" \n            step=\"0.1\" \n            value={weights.departments[dept.id] || 1.0}\n            onChange={(e) => handleDepartmentChange(dept.id, e.target.value)}\n          />\n          <span>{weights.departments[dept.id] || 1.0}</span>\n        </div>\n      ))}\n      \n      <h3>Recency Weights</h3>\n      {/* Similar sliders for recency weights */}\n      \n      <h3>Source Type Weights</h3>\n      {/* Similar sliders for source type weights */}\n    </div>\n  );\n};\n```\n\nBackend implementation for applying weights during retrieval:\n```javascript\nconst applyWeightsToQuery = async (userId, query, rawResults) => {\n  // Get user weights configuration\n  const userWeights = await getUserWeights(userId);\n  \n  // Apply weights to raw results\n  const weightedResults = rawResults.map(result => {\n    let score = result.base_score;\n    \n    // Apply department weights\n    const deptWeight = userWeights.departments[result.department] || 1.0;\n    score *= deptWeight;\n    \n    // Apply recency weights\n    const docDate = new Date(result.created_at);\n    const now = new Date();\n    const daysDiff = (now - docDate) / (1000 * 60 * 60 * 24);\n    \n    if (daysDiff <= 30 && userWeights.recency.last30Days) {\n      score *= userWeights.recency.last30Days;\n    } else if (daysDiff <= 365 && userWeights.recency.lastYear) {\n      score *= userWeights.recency.lastYear;\n    } else if (userWeights.recency.older) {\n      score *= userWeights.recency.older;\n    }\n    \n    // Apply source type weights\n    const typeWeight = userWeights.sourceTypes[result.source_type] || 1.0;\n    score *= typeWeight;\n    \n    // Apply pinned/muted status\n    if (userWeights.pinnedIds.includes(result.id)) {\n      score *= 2.0;\n    }\n    if (userWeights.mutedIds.includes(result.id)) {\n      score = 0;\n    }\n    \n    return {\n      ...result,\n      weighted_score: score\n    };\n  });\n  \n  // Filter out muted results and sort by weighted score\n  return weightedResults\n    .filter(result => result.weighted_score > 0)\n    .sort((a, b) => b.weighted_score - a.weighted_score);\n};\n```\n\nConversational weight adjustment implementation:\n```javascript\nconst handleWeightAdjustmentIntent = async (userId, message) => {\n  // Parse natural language intent for weight adjustments\n  const intent = await parseWeightAdjustmentIntent(message);\n  \n  if (!intent) return null; // Not a weight adjustment request\n  \n  // Get current user weights\n  const currentWeights = await getUserWeights(userId);\n  \n  // Apply the requested adjustments\n  const updatedWeights = applyWeightAdjustments(currentWeights, intent);\n  \n  // Save the updated weights\n  await saveUserWeights(userId, updatedWeights);\n  \n  // Generate confirmation message for the user\n  return generateWeightAdjustmentConfirmation(intent, updatedWeights);\n};\n\nconst parseWeightAdjustmentIntent = async (message) => {\n  // Example patterns for weight adjustment requests\n  const patterns = [\n    { regex: /prioritize (recent|new) (documents|content)/i, type: 'recency', value: 'last30Days', action: 'increase' },\n    { regex: /focus (more )?on (sales|marketing|engineering|it)/i, type: 'department', action: 'increase' },\n    { regex: /(show|include) (more|less) (pdf|video|audio|web)/i, type: 'sourceType', action: 'dynamic' },\n    // Additional patterns for other weight adjustment requests\n  ];\n  \n  // Check message against patterns\n  for (const pattern of patterns) {\n    const match = message.match(pattern.regex);\n    if (match) {\n      // Extract specific parameters based on the pattern\n      return buildWeightAdjustmentIntent(pattern, match);\n    }\n  }\n  \n  return null; // No recognized weight adjustment intent\n};\n```",
        "testStrategy": "1. Unit test the weights configuration UI components\n2. Test weight adjustment sliders and verify they update correctly\n3. Test preset configurations to ensure they apply the correct weights\n4. Verify document pinning and muting functionality works as expected\n5. Test the weight application logic with various document types and ages\n6. Verify CKO can adjust weights via conversation commands\n7. Test that Sales documents are weighted 2x higher when Sales department weight is set to 2.0\n8. Verify recent documents score 50% higher when recency weight is enabled\n9. Test that pinned documents are always included with 2.0x weight\n10. Verify muted documents are excluded from results\n11. Test FR-018: Users can adjust data weights via natural language in CKO conversation\n    a. Test parsing of various weight adjustment intents (e.g., \"prioritize recent documents\", \"focus more on sales\")\n    b. Verify weights are correctly updated based on conversational commands\n    c. Test confirmation messages accurately reflect the changes made\n    d. Verify multiple weight adjustments in a single conversation are handled correctly\n    e. Test edge cases like ambiguous requests or conflicting adjustments",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement natural language weight adjustment parser",
            "description": "Create a system to parse user messages for weight adjustment intents in natural language conversations with CKO.",
            "dependencies": [],
            "details": "Implement the parseWeightAdjustmentIntent function that analyzes user messages for patterns indicating weight adjustment requests. The parser should:\n\n1. Recognize common phrases like \"prioritize recent documents\", \"focus more on sales\", \"show more PDFs\"\n2. Extract the specific weight category (department, recency, source type)\n3. Determine the adjustment direction (increase, decrease)\n4. Handle ambiguous requests by prompting for clarification\n5. Support compound requests (e.g., \"prioritize recent engineering documents\")\n\nThe implementation should use a combination of regex patterns and NLP techniques to accurately identify user intent.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement weight adjustment via conversation",
            "description": "Create the system for applying weight adjustments based on parsed natural language intents in CKO conversations.",
            "dependencies": [],
            "details": "Implement the applyWeightAdjustments and handleWeightAdjustmentIntent functions that:\n\n1. Take the parsed intent and current weight configuration\n2. Apply appropriate adjustments to the weights based on the intent\n3. Handle relative adjustments (\"more\", \"less\") and absolute settings (\"only\", \"ignore\")\n4. Ensure weights stay within valid ranges (0.0-2.0)\n5. Save the updated weights to user preferences\n6. Track weight adjustment history for potential rollback\n\nThe implementation should integrate with the existing weight application system.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement weight adjustment confirmation messages",
            "description": "Create a system for generating clear confirmation messages after weight adjustments via conversation.",
            "dependencies": [],
            "details": "Implement the generateWeightAdjustmentConfirmation function that:\n\n1. Takes the applied weight adjustment and generates a natural language confirmation\n2. Clearly communicates what was changed and the new settings\n3. Provides examples of how results will be affected (e.g., \"You'll now see more recent engineering documents\")\n4. Offers options to further refine or revert the changes\n5. Uses consistent terminology that matches the UI labels\n\nThe confirmation messages should be conversational but precise, helping users understand exactly how their request was interpreted and applied.",
            "status": "pending",
            "testStrategy": null,
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-07T19:58:59.198Z"
      },
      {
        "id": "85",
        "title": "Implement Asset Management System",
        "description": "Create the system for viewing and managing the 5 types of generated assets (Skill, Command, Agent, Prompt, Workflow).",
        "details": "Implement the asset management system that allows users to view, edit, publish, and archive AI-generated content across 5 asset types. This system provides visibility and control over the outputs of AGENT-001 processing.\n\nKey components:\n1. Asset list with type icons and department badges\n2. Filtering by asset type, department, and status\n3. Asset detail modal for viewing and editing content\n4. Version tracking and history\n5. Publishing functionality to B2 storage\n6. Archiving functionality for unwanted assets\n\nImplementation steps:\n1. Create asset list component with filtering options\n2. Implement asset detail modal with editing capabilities\n3. Add version tracking system\n4. Implement publishing functionality to B2 storage\n5. Add archiving functionality\n\nExample asset list component:\n```jsx\nconst AssetList = () => {\n  const [assets, setAssets] = useState([]);\n  const [filters, setFilters] = useState({\n    type: null,\n    department: null,\n    status: null\n  });\n  const [selectedAsset, setSelectedAsset] = useState(null);\n  \n  useEffect(() => {\n    const fetchAssets = async () => {\n      const response = await api.getAssets(filters);\n      setAssets(response.data);\n    };\n    \n    fetchAssets();\n  }, [filters]);\n  \n  const handleFilterChange = (key, value) => {\n    setFilters(prev => ({\n      ...prev,\n      [key]: value\n    }));\n  };\n  \n  const handleAssetClick = (asset) => {\n    setSelectedAsset(asset);\n  };\n  \n  const getAssetIcon = (type) => {\n    switch (type) {\n      case 'skill': return <SkillIcon />;\n      case 'command': return <CommandIcon />;\n      case 'agent': return <AgentIcon />;\n      case 'prompt': return <PromptIcon />;\n      case 'workflow': return <WorkflowIcon />;\n      default: return null;\n    }\n  };\n  \n  return (\n    <div className=\"asset-management\">\n      <div className=\"filters\">\n        <select \n          value={filters.type || ''} \n          onChange={(e) => handleFilterChange('type', e.target.value || null)}\n        >\n          <option value=\"\">All Types</option>\n          <option value=\"skill\">Skill</option>\n          <option value=\"command\">Command</option>\n          <option value=\"agent\">Agent</option>\n          <option value=\"prompt\">Prompt</option>\n          <option value=\"workflow\">Workflow</option>\n        </select>\n        \n        {/* Similar dropdowns for department and status */}\n      </div>\n      \n      <div className=\"asset-list\">\n        {assets.map(asset => (\n          <div \n            key={asset.id} \n            className=\"asset-item\"\n            onClick={() => handleAssetClick(asset)}\n          >\n            <div className=\"asset-icon\">{getAssetIcon(asset.type)}</div>\n            <div className=\"asset-info\">\n              <h4>{asset.title}</h4>\n              <div className=\"asset-meta\">\n                <span className=\"department-badge\">{asset.department}</span>\n                <span className=\"status-badge\">{asset.status}</span>\n                <span className=\"version\">v{asset.version}</span>\n              </div>\n            </div>\n          </div>\n        ))}\n      </div>\n      \n      {selectedAsset && (\n        <AssetDetailModal \n          asset={selectedAsset} \n          onClose={() => setSelectedAsset(null)} \n          onUpdate={(updatedAsset) => {\n            // Update asset in list\n            setAssets(prev => prev.map(a => \n              a.id === updatedAsset.id ? updatedAsset : a\n            ));\n          }}\n        />\n      )}\n    </div>\n  );\n};\n```\n\nAsset detail modal with publishing functionality:\n```jsx\nconst AssetDetailModal = ({ asset, onClose, onUpdate }) => {\n  const [editedContent, setEditedContent] = useState(asset.content);\n  const [isPublishing, setIsPublishing] = useState(false);\n  \n  const handleSave = async () => {\n    try {\n      const updatedAsset = await api.updateAsset(asset.id, {\n        content: editedContent\n      });\n      onUpdate(updatedAsset);\n    } catch (error) {\n      console.error('Failed to save asset:', error);\n    }\n  };\n  \n  const handlePublish = async () => {\n    setIsPublishing(true);\n    try {\n      const publishedAsset = await api.publishAsset(asset.id);\n      onUpdate(publishedAsset);\n    } catch (error) {\n      console.error('Failed to publish asset:', error);\n    } finally {\n      setIsPublishing(false);\n    }\n  };\n  \n  const handleArchive = async () => {\n    try {\n      const archivedAsset = await api.archiveAsset(asset.id);\n      onUpdate(archivedAsset);\n      onClose();\n    } catch (error) {\n      console.error('Failed to archive asset:', error);\n    }\n  };\n  \n  return (\n    <Modal onClose={onClose}>\n      <div className=\"asset-detail\">\n        <div className=\"asset-header\">\n          <h3>{asset.title}</h3>\n          <div className=\"asset-meta\">\n            <span className=\"type-badge\">{asset.type}</span>\n            <span className=\"department-badge\">{asset.department}</span>\n            <span className=\"status-badge\">{asset.status}</span>\n            <span className=\"version\">v{asset.version}</span>\n          </div>\n        </div>\n        \n        <div className=\"asset-content\">\n          <CodeEditor \n            value={editedContent} \n            onChange={setEditedContent} \n            language={getLanguageForAssetType(asset.type)}\n          />\n        </div>\n        \n        <div className=\"asset-source\">\n          <h4>Source Document</h4>\n          <p>{asset.source_document}</p>\n          <p>Classification Confidence: {asset.classification_confidence}%</p>\n          <p>Reasoning: {asset.reasoning}</p>\n        </div>\n        \n        <div className=\"asset-actions\">\n          <button onClick={handleSave}>Save</button>\n          {asset.status === 'draft' && (\n            <button \n              onClick={handlePublish}\n              disabled={isPublishing}\n            >\n              {isPublishing ? 'Publishing...' : 'Publish'}\n            </button>\n          )}\n          <button onClick={handleArchive}>Archive</button>\n          <button onClick={onClose}>Close</button>\n        </div>\n      </div>\n    </Modal>\n  );\n};\n```",
        "testStrategy": "1. Unit test the asset list component with various filter combinations\n2. Test the asset detail modal for viewing and editing content\n3. Verify version tracking works correctly when editing assets\n4. Test publishing functionality to ensure assets are correctly stored in B2\n5. Verify archiving functionality correctly removes assets from active view\n6. Test filtering by asset type to ensure only matching assets are shown\n7. Verify asset operations (view, edit, publish) complete in < 2 seconds (SC-010)\n8. Test concurrent edits to the same asset and verify conflict handling\n9. Verify all 5 asset types display correctly with appropriate icons and formatting",
        "priority": "medium",
        "dependencies": [
          "81"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T20:05:26.040Z"
      },
      {
        "id": "86",
        "title": "Implement Classification Management System",
        "description": "Create the system for viewing and correcting how content is classified into the 12 departments.",
        "details": "Implement the classification management system that allows users to view and correct how their content is classified across the 12 departments. This system is important for improving classification accuracy over time.\n\nKey components:\n1. Classification list with department, confidence score, and correction indicator\n2. Color-coded confidence scores for quick assessment\n3. Department correction functionality\n4. Classification reasoning and keyword display\n5. Correction tracking for accuracy metrics\n\nImplementation steps:\n1. Create classification list component with filtering options\n2. Implement confidence score visualization with color coding\n3. Add department correction functionality\n4. Display classification reasoning and matched keywords\n5. Implement correction tracking system\n\nExample classification list component:\n```jsx\nconst ClassificationList = () => {\n  const [classifications, setClassifications] = useState([]);\n  const [filters, setFilters] = useState({\n    department: null,\n    confidenceRange: [0, 100],\n    corrected: null\n  });\n  \n  useEffect(() => {\n    const fetchClassifications = async () => {\n      const response = await api.getClassifications(filters);\n      setClassifications(response.data);\n    };\n    \n    fetchClassifications();\n  }, [filters]);\n  \n  const handleFilterChange = (key, value) => {\n    setFilters(prev => ({\n      ...prev,\n      [key]: value\n    }));\n  };\n  \n  const handleCorrection = async (classificationId, newDepartment) => {\n    try {\n      const updatedClassification = await api.correctClassification(\n        classificationId, \n        newDepartment\n      );\n      \n      // Update the classification in the list\n      setClassifications(prev => prev.map(c => \n        c.id === updatedClassification.id ? updatedClassification : c\n      ));\n    } catch (error) {\n      console.error('Failed to correct classification:', error);\n    }\n  };\n  \n  const getConfidenceColor = (confidence) => {\n    if (confidence >= 90) return 'green';\n    if (confidence >= 70) return 'yellow';\n    return 'red';\n  };\n  \n  return (\n    <div className=\"classification-management\">\n      <div className=\"filters\">\n        {/* Department filter dropdown */}\n        {/* Confidence range slider */}\n        {/* Corrected toggle */}\n      </div>\n      \n      <div className=\"classification-list\">\n        {classifications.map(classification => (\n          <div key={classification.id} className=\"classification-item\">\n            <div className=\"document-info\">\n              <h4>{classification.document_title}</h4>\n              <p>{classification.document_snippet}</p>\n            </div>\n            \n            <div className=\"classification-info\">\n              <div className=\"department\">\n                <span>Department:</span>\n                <select\n                  value={classification.department}\n                  onChange={(e) => handleCorrection(classification.id, e.target.value)}\n                >\n                  <option value=\"it-engineering\">IT & Engineering</option>\n                  <option value=\"sales-marketing\">Sales & Marketing</option>\n                  {/* Other department options */}\n                </select>\n                {classification.user_corrected && (\n                  <span className=\"corrected-badge\">Corrected</span>\n                )}\n              </div>\n              \n              <div \n                className=\"confidence-score\"\n                style={{ color: getConfidenceColor(classification.confidence) }}\n              >\n                Confidence: {classification.confidence}%\n              </div>\n              \n              <button \n                className=\"show-reasoning-btn\"\n                onClick={() => toggleReasoning(classification.id)}\n              >\n                Show Reasoning\n              </button>\n              \n              {expandedReasonings[classification.id] && (\n                <div className=\"classification-reasoning\">\n                  <h5>Classification Reasoning:</h5>\n                  <p>{classification.reasoning}</p>\n                  <h5>Matched Keywords:</h5>\n                  <ul>\n                    {classification.keywords.map((keyword, index) => (\n                      <li key={index}>{keyword}</li>\n                    ))}\n                  </ul>\n                </div>\n              )}\n            </div>\n          </div>\n        ))}\n      </div>\n    </div>\n  );\n};\n```\n\nBackend implementation for correction tracking:\n```javascript\nconst correctClassification = async (req, res) => {\n  const { classificationId, newDepartment } = req.body;\n  const userId = req.user.id;\n  \n  try {\n    // Get the original classification\n    const classification = await db.query(\n      'SELECT * FROM classifications WHERE id = $1',\n      [classificationId]\n    );\n    \n    if (!classification.rows.length) {\n      return res.status(404).json({ error: 'Classification not found' });\n    }\n    \n    const originalClassification = classification.rows[0];\n    \n    // Update the classification\n    const updatedClassification = await db.query(\n      'UPDATE classifications SET department = $1, user_corrected = true, updated_at = NOW() WHERE id = $2 RETURNING *',\n      [newDepartment, classificationId]\n    );\n    \n    // Log the correction for learning\n    await db.query(\n      'INSERT INTO classification_corrections (classification_id, user_id, original_department, new_department) VALUES ($1, $2, $3, $4)',\n      [classificationId, userId, originalClassification.department, newDepartment]\n    );\n    \n    // Update correction rate metrics\n    await updateCorrectionRateMetrics();\n    \n    return res.json(updatedClassification.rows[0]);\n  } catch (error) {\n    console.error('Error correcting classification:', error);\n    return res.status(500).json({ error: 'Failed to correct classification' });\n  }\n};\n```",
        "testStrategy": "1. Unit test the classification list component with various filter combinations\n2. Test the department correction functionality\n3. Verify confidence score color coding works correctly\n4. Test the reasoning display toggle\n5. Verify correction tracking correctly logs changes\n6. Test that CKO learns from corrections to similar content\n7. Verify classification accuracy improves by > 10% after 50 user corrections (SC-004)\n8. Test the filter functionality to ensure only matching classifications are shown\n9. Verify all 12 departments are available for selection when correcting",
        "priority": "medium",
        "dependencies": [
          "81"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T20:05:55.800Z"
      },
      {
        "id": "87",
        "title": "Implement Global Search Functionality",
        "description": "Create the global search functionality that allows searching across all AI Studio content (conversations, assets, documents, classifications).",
        "details": "Implement the global search functionality that enables users to quickly find content across all AI Studio data types. This search system should provide a unified interface for accessing conversations, assets, documents, and classifications.\n\nKey components:\n1. Global search bar with keyboard shortcut (Cmd+K)\n2. Search results with type icons and snippets\n3. Filtering options by content type\n4. Navigation to search result items\n\nImplementation steps:\n1. Create global search bar component\n2. Implement keyboard shortcut activation\n3. Build search results display with type icons\n4. Add filtering functionality by content type\n5. Implement navigation to search result items\n\nExample global search component:\n```jsx\nconst GlobalSearch = () => {\n  const [isOpen, setIsOpen] = useState(false);\n  const [query, setQuery] = useState('');\n  const [results, setResults] = useState([]);\n  const [activeFilter, setActiveFilter] = useState('all');\n  const [isLoading, setIsLoading] = useState(false);\n  \n  // Set up keyboard shortcut\n  useEffect(() => {\n    const handleKeyDown = (e) => {\n      if ((e.metaKey || e.ctrlKey) && e.key === 'k') {\n        e.preventDefault();\n        setIsOpen(true);\n      }\n      if (e.key === 'Escape') {\n        setIsOpen(false);\n      }\n    };\n    \n    window.addEventListener('keydown', handleKeyDown);\n    return () => window.removeEventListener('keydown', handleKeyDown);\n  }, []);\n  \n  // Search when query changes\n  useEffect(() => {\n    if (!query.trim() || query.length < 2) {\n      setResults([]);\n      return;\n    }\n    \n    const searchTimeout = setTimeout(async () => {\n      setIsLoading(true);\n      try {\n        const response = await api.search(query, activeFilter);\n        setResults(response.data);\n      } catch (error) {\n        console.error('Search failed:', error);\n      } finally {\n        setIsLoading(false);\n      }\n    }, 300);\n    \n    return () => clearTimeout(searchTimeout);\n  }, [query, activeFilter]);\n  \n  const handleFilterChange = (filter) => {\n    setActiveFilter(filter);\n  };\n  \n  const navigateToResult = (result) => {\n    setIsOpen(false);\n    \n    // Navigate based on result type\n    switch (result.type) {\n      case 'conversation':\n        navigate(`/ai-studio/conversation/${result.id}`, {\n          state: { messageId: result.messageId }\n        });\n        break;\n      case 'asset':\n        navigate(`/ai-studio/assets`, {\n          state: { selectedAssetId: result.id }\n        });\n        break;\n      case 'document':\n        navigate(`/documents/${result.id}`);\n        break;\n      case 'classification':\n        navigate(`/ai-studio/classifications`, {\n          state: { selectedClassificationId: result.id }\n        });\n        break;\n      default:\n        break;\n    }\n  };\n  \n  const getResultIcon = (type) => {\n    switch (type) {\n      case 'conversation': return <ChatIcon />;\n      case 'asset': return <AssetIcon />;\n      case 'document': return <DocumentIcon />;\n      case 'classification': return <TagIcon />;\n      default: return null;\n    }\n  };\n  \n  if (!isOpen) return null;\n  \n  return (\n    <div className=\"global-search-overlay\">\n      <div className=\"global-search-modal\">\n        <div className=\"search-header\">\n          <SearchIcon />\n          <input\n            type=\"text\"\n            placeholder=\"Search AI Studio...\"\n            value={query}\n            onChange={(e) => setQuery(e.target.value)}\n            autoFocus\n          />\n          <button onClick={() => setIsOpen(false)}>ESC</button>\n        </div>\n        \n        <div className=\"search-filters\">\n          <button \n            className={activeFilter === 'all' ? 'active' : ''}\n            onClick={() => handleFilterChange('all')}\n          >\n            All\n          </button>\n          <button \n            className={activeFilter === 'conversation' ? 'active' : ''}\n            onClick={() => handleFilterChange('conversation')}\n          >\n            Conversations\n          </button>\n          <button \n            className={activeFilter === 'asset' ? 'active' : ''}\n            onClick={() => handleFilterChange('asset')}\n          >\n            Assets\n          </button>\n          <button \n            className={activeFilter === 'document' ? 'active' : ''}\n            onClick={() => handleFilterChange('document')}\n          >\n            Documents\n          </button>\n          <button \n            className={activeFilter === 'classification' ? 'active' : ''}\n            onClick={() => handleFilterChange('classification')}\n          >\n            Classifications\n          </button>\n        </div>\n        \n        <div className=\"search-results\">\n          {isLoading ? (\n            <div className=\"loading\">Searching...</div>\n          ) : results.length > 0 ? (\n            results.map(result => (\n              <div \n                key={`${result.type}-${result.id}`}\n                className=\"search-result\"\n                onClick={() => navigateToResult(result)}\n              >\n                <div className=\"result-icon\">{getResultIcon(result.type)}</div>\n                <div className=\"result-content\">\n                  <h4>{result.title}</h4>\n                  <p>{result.snippet}</p>\n                  <div className=\"result-meta\">\n                    <span className=\"result-type\">{result.type}</span>\n                    {result.department && (\n                      <span className=\"result-department\">{result.department}</span>\n                    )}\n                    <span className=\"result-date\">{formatDate(result.date)}</span>\n                  </div>\n                </div>\n              </div>\n            ))\n          ) : query.length >= 2 ? (\n            <div className=\"no-results\">No results found</div>\n          ) : (\n            <div className=\"search-prompt\">Type at least 2 characters to search</div>\n          )}\n        </div>\n      </div>\n    </div>\n  );\n};\n```\n\nBackend search implementation:\n```javascript\nconst searchAIStudioContent = async (req, res) => {\n  const { query, filter } = req.query;\n  const userId = req.user.id;\n  \n  if (!query || query.length < 2) {\n    return res.json([]);\n  }\n  \n  try {\n    const results = [];\n    const searchPromises = [];\n    \n    // Search conversations if filter is 'all' or 'conversation'\n    if (filter === 'all' || filter === 'conversation') {\n      searchPromises.push(\n        db.query(\n          `SELECT \n            c.id, \n            c.title, \n            m.content, \n            m.id as message_id, \n            m.created_at as date\n          FROM cko_sessions c\n          JOIN cko_messages m ON c.id = m.session_id\n          WHERE c.user_id = $1\n          AND (c.title ILIKE $2 OR m.content ILIKE $2)\n          ORDER BY m.created_at DESC\n          LIMIT 10`,\n          [userId, `%${query}%`]\n        ).then(result => {\n          results.push(...result.rows.map(row => ({\n            id: row.id,\n            messageId: row.message_id,\n            title: row.title,\n            snippet: truncate(row.content, 100),\n            date: row.date,\n            type: 'conversation'\n          })));\n        })\n      );\n    }\n    \n    // Similar queries for assets, documents, and classifications\n    // ...\n    \n    await Promise.all(searchPromises);\n    \n    // Sort results by relevance and recency\n    const sortedResults = results.sort((a, b) => {\n      // Calculate relevance score based on match quality\n      // and recency\n      return b.relevanceScore - a.relevanceScore;\n    });\n    \n    return res.json(sortedResults.slice(0, 20)); // Limit to top 20 results\n  } catch (error) {\n    console.error('Search error:', error);\n    return res.status(500).json({ error: 'Search failed' });\n  }\n};\n```",
        "testStrategy": "1. Unit test the global search component with various queries\n2. Test keyboard shortcut activation (Cmd+K)\n3. Verify search results display correctly with type icons\n4. Test filtering by content type\n5. Verify navigation to search result items works correctly\n6. Performance test search response time (should be < 500ms per SC-009)\n7. Test search with various query lengths and special characters\n8. Verify search works across all content types (conversations, assets, documents, classifications)\n9. Test that clicking a conversation result navigates to that specific message",
        "priority": "medium",
        "dependencies": [
          "82",
          "85",
          "86"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T20:12:12.266Z"
      },
      {
        "id": "88",
        "title": "Implement Feedback & Learning System",
        "description": "Create the feedback system that allows users to rate CKO responses and see how their feedback improves future responses.",
        "details": "Implement the feedback and learning system that enables users to provide ratings on CKO responses and track how their feedback influences future interactions. This system is important for building trust and improving CKO over time.\n\nKey components:\n1. Thumbs up/down rating on CKO responses\n2. Text feedback option for negative ratings\n3. Feedback history panel\n4. CKO acknowledgments of feedback\n5. Learning mechanism to adjust responses based on feedback patterns\n\nImplementation steps:\n1. Create response rating component with thumbs up/down buttons\n2. Implement text feedback form for negative ratings\n3. Build feedback history panel\n4. Add CKO acknowledgment responses\n5. Implement learning mechanism for feedback patterns\n\nExample response rating component:\n```jsx\nconst ResponseRating = ({ messageId, onRatingSubmitted }) => {\n  const [rating, setRating] = useState(null);\n  const [showFeedbackForm, setShowFeedbackForm] = useState(false);\n  const [feedbackText, setFeedbackText] = useState('');\n  const [isSubmitting, setIsSubmitting] = useState(false);\n  \n  const handleRating = async (value) => {\n    setRating(value);\n    \n    if (value === 'down') {\n      setShowFeedbackForm(true);\n    } else {\n      // Submit positive rating immediately\n      await submitFeedback(value);\n    }\n  };\n  \n  const submitFeedback = async (ratingValue, text = '') => {\n    setIsSubmitting(true);\n    try {\n      await api.submitFeedback({\n        messageId,\n        rating: ratingValue,\n        feedback: text\n      });\n      \n      setShowFeedbackForm(false);\n      onRatingSubmitted(ratingValue, text);\n    } catch (error) {\n      console.error('Failed to submit feedback:', error);\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n  \n  const handleFeedbackSubmit = async (e) => {\n    e.preventDefault();\n    await submitFeedback(rating, feedbackText);\n  };\n  \n  return (\n    <div className=\"response-rating\">\n      {!rating ? (\n        <div className=\"rating-buttons\">\n          <button \n            onClick={() => handleRating('up')} \n            aria-label=\"Thumbs up\"\n          >\n            <ThumbsUpIcon />\n          </button>\n          <button \n            onClick={() => handleRating('down')} \n            aria-label=\"Thumbs down\"\n          >\n            <ThumbsDownIcon />\n          </button>\n        </div>\n      ) : (\n        <div className=\"rating-submitted\">\n          {rating === 'up' ? <ThumbsUpIcon /> : <ThumbsDownIcon />}\n          <span>Thank you for your feedback</span>\n        </div>\n      )}\n      \n      {showFeedbackForm && (\n        <form onSubmit={handleFeedbackSubmit} className=\"feedback-form\">\n          <textarea\n            placeholder=\"What could be improved?\"\n            value={feedbackText}\n            onChange={(e) => setFeedbackText(e.target.value)}\n            rows={3}\n          />\n          <div className=\"form-actions\">\n            <button \n              type=\"button\" \n              onClick={() => setShowFeedbackForm(false)}\n              disabled={isSubmitting}\n            >\n              Cancel\n            </button>\n            <button \n              type=\"submit\"\n              disabled={isSubmitting}\n            >\n              {isSubmitting ? 'Submitting...' : 'Submit'}\n            </button>\n          </div>\n        </form>\n      )}\n    </div>\n  );\n};\n```\n\nFeedback history panel:\n```jsx\nconst FeedbackPanel = () => {\n  const [feedbackHistory, setFeedbackHistory] = useState([]);\n  const [isLoading, setIsLoading] = useState(true);\n  \n  useEffect(() => {\n    const fetchFeedbackHistory = async () => {\n      setIsLoading(true);\n      try {\n        const response = await api.getFeedbackHistory();\n        setFeedbackHistory(response.data);\n      } catch (error) {\n        console.error('Failed to fetch feedback history:', error);\n      } finally {\n        setIsLoading(false);\n      }\n    };\n    \n    fetchFeedbackHistory();\n  }, []);\n  \n  return (\n    <div className=\"feedback-panel\">\n      <h3>Your Feedback History</h3>\n      \n      {isLoading ? (\n        <div className=\"loading\">Loading feedback history...</div>\n      ) : feedbackHistory.length > 0 ? (\n        <div className=\"feedback-list\">\n          {feedbackHistory.map(item => (\n            <div key={item.id} className=\"feedback-item\">\n              <div className=\"feedback-header\">\n                <span className={`rating ${item.rating}`}>\n                  {item.rating === 'up' ? <ThumbsUpIcon /> : <ThumbsDownIcon />}\n                </span>\n                <span className=\"date\">{formatDate(item.created_at)}</span>\n              </div>\n              \n              <div className=\"feedback-content\">\n                <div className=\"message\">\n                  <h4>CKO Response:</h4>\n                  <p>{item.message_content}</p>\n                </div>\n                \n                {item.feedback && (\n                  <div className=\"user-feedback\">\n                    <h4>Your Feedback:</h4>\n                    <p>{item.feedback}</p>\n                  </div>\n                )}\n                \n                {item.acknowledgment && (\n                  <div className=\"cko-acknowledgment\">\n                    <h4>CKO Acknowledgment:</h4>\n                    <p>{item.acknowledgment}</p>\n                  </div>\n                )}\n              </div>\n              \n              <div className=\"feedback-impact\">\n                <h4>Impact:</h4>\n                <p>{item.impact_description || 'Feedback recorded for learning'}</p>\n              </div>\n            </div>\n          ))}\n        </div>\n      ) : (\n        <div className=\"empty-state\">\n          <p>No feedback submitted yet. Rate CKO responses to help improve future interactions.</p>\n        </div>\n      )}\n    </div>\n  );\n};\n```\n\nBackend implementation for learning from feedback:\n```javascript\nconst processFeedbackPatterns = async () => {\n  try {\n    // Find patterns in negative feedback\n    const negativeFeedbackPatterns = await db.query(\n      `SELECT \n        COUNT(*) as count,\n        ARRAY_AGG(message_id) as message_ids,\n        ARRAY_AGG(feedback) as feedback_texts,\n        ARRAY_AGG(session_id) as session_ids\n      FROM feedback\n      WHERE rating = 'down'\n      AND created_at > NOW() - INTERVAL '30 days'\n      GROUP BY user_id\n      HAVING COUNT(*) >= 3`\n    );\n    \n    // Process each user's feedback patterns\n    for (const pattern of negativeFeedbackPatterns.rows) {\n      // Analyze feedback texts for common themes\n      const commonThemes = analyzeTextForThemes(pattern.feedback_texts);\n      \n      // Get the messages that received negative feedback\n      const messages = await db.query(\n        'SELECT * FROM cko_messages WHERE id = ANY($1)',\n        [pattern.message_ids]\n      );\n      \n      // Analyze messages for patterns\n      const messagePatterns = analyzeMessagesForPatterns(messages.rows);\n      \n      // Create learning entry\n      await db.query(\n        `INSERT INTO cko_learning (user_id, pattern_type, pattern_data, action_taken)\n        VALUES ($1, $2, $3, $4)`,\n        [\n          messages.rows[0].user_id,\n          'negative_feedback',\n          JSON.stringify({\n            themes: commonThemes,\n            messagePatterns: messagePatterns\n          }),\n          'adjust_response_style'\n        ]\n      );\n    }\n    \n    console.log('Feedback patterns processed successfully');\n  } catch (error) {\n    console.error('Error processing feedback patterns:', error);\n  }\n};\n```",
        "testStrategy": "1. Unit test the response rating component with both positive and negative ratings\n2. Test the feedback form for negative ratings\n3. Verify feedback history panel displays correctly\n4. Test CKO acknowledgment responses\n5. Verify learning mechanism correctly identifies and responds to feedback patterns\n6. Test that multiple negative ratings on similar responses leads to CKO adjusting its approach\n7. Verify feedback submission rate > 10% of CKO responses (SC-007)\n8. Test that user satisfaction (thumbs up rate) > 80% (SC-008)\n9. Verify the feedback impact description accurately reflects how feedback influenced CKO behavior",
        "priority": "medium",
        "dependencies": [
          "82"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T20:06:20.866Z"
      },
      {
        "id": "89",
        "title": "Implement Database Schema and API Endpoints",
        "description": "Create the database schema and API endpoints required for the AI Studio and CKO functionality.",
        "details": "Implement the database schema and API endpoints that will support all AI Studio and CKO functionality. This includes tables for sessions, messages, weights, assets, classifications, and feedback, as well as the API endpoints for interacting with these entities.\n\nKey components:\n1. Database schema for all required entities\n2. API endpoints for CKO conversation\n3. API endpoints for clarification system\n4. API endpoints for data weights configuration\n5. API endpoints for asset management\n6. API endpoints for classification management\n7. API endpoints for search\n8. API endpoints for feedback\n\nImplementation steps:\n1. Create database migration scripts for all required tables\n2. Implement API endpoints for CKO conversation\n3. Implement API endpoints for clarification system\n4. Implement API endpoints for data weights configuration\n5. Implement API endpoints for asset management\n6. Implement API endpoints for classification management\n7. Implement API endpoints for search\n8. Implement API endpoints for feedback\n\nExample database schema:\n```sql\n-- CKO Sessions\nCREATE TABLE cko_sessions (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  user_id UUID NOT NULL REFERENCES users(id),\n  title TEXT NOT NULL,\n  message_count INTEGER NOT NULL DEFAULT 0,\n  pending_clarifications INTEGER NOT NULL DEFAULT 0,\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\n-- CKO Messages\nCREATE TABLE cko_messages (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  session_id UUID NOT NULL REFERENCES cko_sessions(id),\n  role TEXT NOT NULL CHECK (role IN ('user', 'assistant')),\n  content TEXT NOT NULL,\n  is_clarification BOOLEAN NOT NULL DEFAULT FALSE,\n  sources JSONB,\n  rating TEXT CHECK (rating IN ('up', 'down')),\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\n-- User Weights\nCREATE TABLE user_weights (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  user_id UUID NOT NULL REFERENCES users(id),\n  weights JSONB NOT NULL,\n  pinned_ids TEXT[] NOT NULL DEFAULT '{}',\n  muted_ids TEXT[] NOT NULL DEFAULT '{}',\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\n-- Assets\nCREATE TABLE assets (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  user_id UUID NOT NULL REFERENCES users(id),\n  asset_type TEXT NOT NULL CHECK (asset_type IN ('skill', 'command', 'agent', 'prompt', 'workflow')),\n  department TEXT NOT NULL,\n  title TEXT NOT NULL,\n  content TEXT NOT NULL,\n  format TEXT NOT NULL,\n  status TEXT NOT NULL CHECK (status IN ('draft', 'published', 'archived')),\n  version INTEGER NOT NULL DEFAULT 1,\n  source_document_id UUID,\n  classification_confidence NUMERIC,\n  reasoning TEXT,\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\n-- Classifications\nCREATE TABLE classifications (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  user_id UUID NOT NULL REFERENCES users(id),\n  document_id UUID NOT NULL,\n  department TEXT NOT NULL,\n  confidence NUMERIC NOT NULL,\n  user_corrected BOOLEAN NOT NULL DEFAULT FALSE,\n  keywords TEXT[] NOT NULL DEFAULT '{}',\n  reasoning TEXT,\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\n-- Feedback\nCREATE TABLE feedback (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  user_id UUID NOT NULL REFERENCES users(id),\n  message_id UUID NOT NULL REFERENCES cko_messages(id),\n  session_id UUID NOT NULL REFERENCES cko_sessions(id),\n  rating TEXT NOT NULL CHECK (rating IN ('up', 'down')),\n  feedback TEXT,\n  acknowledgment TEXT,\n  impact_description TEXT,\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n\n-- CKO Learning\nCREATE TABLE cko_learning (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  user_id UUID NOT NULL REFERENCES users(id),\n  pattern_type TEXT NOT NULL,\n  pattern_data JSONB NOT NULL,\n  action_taken TEXT NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()\n);\n```\n\nExample API endpoints:\n```javascript\n// CKO Conversation endpoints\napp.post('/api/cko/sessions', authenticateUser, createSession);\napp.get('/api/cko/sessions', authenticateUser, getSessions);\napp.get('/api/cko/sessions/:id', authenticateUser, getSession);\napp.post('/api/cko/sessions/:id/messages', authenticateUser, sendMessage);\napp.get('/api/cko/sessions/:id/messages', authenticateUser, getMessages);\n\n// Clarification endpoints\napp.get('/api/cko/clarifications/pending', authenticateUser, getPendingClarifications);\napp.post('/api/cko/clarifications/:id/respond', authenticateUser, respondToClarification);\napp.post('/api/cko/clarifications/:id/skip', authenticateUser, skipClarification);\n\n// Data Weights endpoints\napp.get('/api/cko/weights', authenticateUser, getUserWeights);\napp.put('/api/cko/weights', authenticateUser, updateUserWeights);\napp.post('/api/cko/weights/preset/:preset', authenticateUser, applyWeightPreset);\napp.post('/api/cko/weights/pin/:documentId', authenticateUser, pinDocument);\napp.post('/api/cko/weights/mute/:documentId', authenticateUser, muteDocument);\n\n// Asset Management endpoints\napp.get('/api/assets', authenticateUser, getAssets);\napp.get('/api/assets/:id', authenticateUser, getAsset);\napp.put('/api/assets/:id', authenticateUser, updateAsset);\napp.post('/api/assets/:id/publish', authenticateUser, publishAsset);\napp.post('/api/assets/:id/archive', authenticateUser, archiveAsset);\n\n// Classification Management endpoints\napp.get('/api/classifications', authenticateUser, getClassifications);\napp.put('/api/classifications/:id', authenticateUser, correctClassification);\n\n// Search endpoints\napp.get('/api/search', authenticateUser, searchAIStudioContent);\n\n// Feedback endpoints\napp.post('/api/feedback', authenticateUser, submitFeedback);\napp.get('/api/feedback', authenticateUser, getFeedbackHistory);\n```",
        "testStrategy": "1. Unit test database schema creation with test data\n2. Test API endpoints with valid and invalid requests\n3. Verify authentication and authorization for all endpoints\n4. Test database queries for performance with large datasets\n5. Verify RLS policies enforce user-level data isolation\n6. Test WebSocket connections for scalability (support for 1000+ concurrent sessions)\n7. Verify all tables have appropriate indexes for query patterns\n8. Test error handling and validation for all API endpoints\n9. Verify data integrity constraints are enforced\n10. Test transaction handling for operations that update multiple tables",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T19:49:39.548Z"
      },
      {
        "id": "90",
        "title": "Implement Error Handling and Graceful Degradation",
        "description": "Create the error handling and graceful degradation mechanisms for AI Studio and CKO functionality.",
        "details": "Implement comprehensive error handling and graceful degradation mechanisms to ensure AI Studio and CKO maintain high availability and reliability. This includes handling external dependency failures, implementing retry logic, and providing fallback functionality when components are unavailable.\n\nKey components:\n1. Error handling for WebSocket connections\n2. Retry logic for external dependencies (AGENT-001, B2, Redis)\n3. Graceful degradation to basic RAG when CKO persona/agents unavailable\n4. User notifications for processing delays\n5. Error logging and monitoring\n\nImplementation steps:\n1. Implement WebSocket connection error handling\n2. Create retry queue for failed external operations\n3. Implement fallback to basic RAG when CKO unavailable\n4. Add user notification system for processing delays\n5. Set up error logging and monitoring\n\nExample WebSocket error handling:\n```javascript\nconst setupWebSocketWithErrorHandling = (sessionId) => {\n  let reconnectAttempts = 0;\n  const maxReconnectAttempts = 5;\n  let reconnectTimeout;\n  \n  const connect = () => {\n    const ws = new WebSocket(`${WS_BASE_URL}/cko/session/${sessionId}`);\n    \n    ws.onopen = () => {\n      console.log('WebSocket connection established');\n      setConnectionStatus('connected');\n      reconnectAttempts = 0; // Reset reconnect attempts on successful connection\n    };\n    \n    ws.onmessage = (event) => {\n      try {\n        const data = JSON.parse(event.data);\n        // Handle message\n      } catch (error) {\n        console.error('Error parsing WebSocket message:', error);\n        // Log error but don't close connection\n      }\n    };\n    \n    ws.onerror = (error) => {\n      console.error('WebSocket error:', error);\n      // Log error but let onclose handle reconnection\n    };\n    \n    ws.onclose = (event) => {\n      console.log(`WebSocket connection closed: ${event.code} ${event.reason}`);\n      setConnectionStatus('disconnected');\n      \n      // Attempt reconnection with exponential backoff\n      if (reconnectAttempts < maxReconnectAttempts) {\n        const delay = Math.min(1000 * Math.pow(2, reconnectAttempts), 30000);\n        console.log(`Reconnecting in ${delay}ms (attempt ${reconnectAttempts + 1}/${maxReconnectAttempts})`);\n        \n        reconnectTimeout = setTimeout(() => {\n          reconnectAttempts++;\n          connect();\n        }, delay);\n      } else {\n        setConnectionStatus('failed');\n        showErrorNotification('Connection to AI Studio lost. Please refresh the page.');\n      }\n    };\n    \n    return ws;\n  };\n  \n  const ws = connect();\n  \n  // Return cleanup function\n  return () => {\n    clearTimeout(reconnectTimeout);\n    if (ws) {\n      ws.close();\n    }\n  };\n};\n```\n\nRetry queue for external dependencies:\n```javascript\nclass RetryQueue {\n  constructor() {\n    this.queue = [];\n    this.processing = false;\n    this.maxRetries = 3;\n  }\n  \n  async add(operation, params, userId) {\n    const queueItem = {\n      id: uuidv4(),\n      operation,\n      params,\n      userId,\n      attempts: 0,\n      status: 'pending',\n      createdAt: new Date(),\n      lastAttempt: null\n    };\n    \n    // Save to database for persistence across restarts\n    await db.query(\n      'INSERT INTO operation_queue (id, operation, params, user_id, attempts, status) VALUES ($1, $2, $3, $4, $5, $6)',\n      [queueItem.id, queueItem.operation, JSON.stringify(queueItem.params), queueItem.userId, queueItem.attempts, queueItem.status]\n    );\n    \n    this.queue.push(queueItem);\n    \n    // Notify user of queued operation\n    await notifyUser(userId, {\n      type: 'operation_queued',\n      operation: operation,\n      message: 'Your request is being processed. You will be notified when complete.'\n    });\n    \n    if (!this.processing) {\n      this.processQueue();\n    }\n    \n    return queueItem.id;\n  }\n  \n  async processQueue() {\n    if (this.processing || this.queue.length === 0) {\n      return;\n    }\n    \n    this.processing = true;\n    \n    while (this.queue.length > 0) {\n      const item = this.queue[0];\n      \n      try {\n        // Update attempt count and status\n        item.attempts++;\n        item.lastAttempt = new Date();\n        item.status = 'processing';\n        \n        await db.query(\n          'UPDATE operation_queue SET attempts = $1, last_attempt = $2, status = $3 WHERE id = $4',\n          [item.attempts, item.lastAttempt, item.status, item.id]\n        );\n        \n        // Execute operation\n        let result;\n        switch (item.operation) {\n          case 'agent001':\n            result = await executeAgent001(item.params);\n            break;\n          case 'b2Upload':\n            result = await uploadToB2(item.params);\n            break;\n          case 'redisOperation':\n            result = await executeRedisOperation(item.params);\n            break;\n          default:\n            throw new Error(`Unknown operation: ${item.operation}`);\n        }\n        \n        // Operation succeeded\n        item.status = 'completed';\n        await db.query(\n          'UPDATE operation_queue SET status = $1, result = $2, completed_at = NOW() WHERE id = $3',\n          [item.status, JSON.stringify(result), item.id]\n        );\n        \n        // Notify user of completion\n        await notifyUser(item.userId, {\n          type: 'operation_completed',\n          operation: item.operation,\n          message: 'Your request has been processed successfully.'\n        });\n        \n        // Remove from queue\n        this.queue.shift();\n      } catch (error) {\n        console.error(`Error processing queue item ${item.id}:`, error);\n        \n        if (item.attempts >= this.maxRetries) {\n          // Max retries reached, mark as failed\n          item.status = 'failed';\n          await db.query(\n            'UPDATE operation_queue SET status = $1, error = $2, completed_at = NOW() WHERE id = $3',\n            [item.status, error.message, item.id]\n          );\n          \n          // Notify user of failure\n          await notifyUser(item.userId, {\n            type: 'operation_failed',\n            operation: item.operation,\n            message: 'Your request could not be processed after multiple attempts.'\n          });\n          \n          // Remove from queue\n          this.queue.shift();\n        } else {\n          // Retry later with exponential backoff\n          const delay = Math.min(1000 * Math.pow(2, item.attempts), 30000);\n          item.status = 'pending';\n          await db.query(\n            'UPDATE operation_queue SET status = $1 WHERE id = $2',\n            [item.status, item.id]\n          );\n          \n          // Move to end of queue for later retry\n          this.queue.push(this.queue.shift());\n          \n          // Pause processing for backoff period\n          await new Promise(resolve => setTimeout(resolve, delay));\n        }\n      }\n    }\n    \n    this.processing = false;\n  }\n  \n  // Load pending operations from database on startup\n  async loadPendingOperations() {\n    const result = await db.query(\n      \"SELECT * FROM operation_queue WHERE status IN ('pending', 'processing') ORDER BY created_at ASC\"\n    );\n    \n    this.queue = result.rows.map(row => ({\n      id: row.id,\n      operation: row.operation,\n      params: row.params,\n      userId: row.user_id,\n      attempts: row.attempts,\n      status: 'pending', // Reset processing status to pending\n      createdAt: row.created_at,\n      lastAttempt: row.last_attempt\n    }));\n    \n    if (this.queue.length > 0 && !this.processing) {\n      this.processQueue();\n    }\n  }\n}\n\n// Initialize and export singleton\nconst retryQueue = new RetryQueue();\nexport default retryQueue;\n```\n\nGraceful degradation to basic RAG:\n```javascript\nconst handleCKOQuery = async (req, res) => {\n  const { sessionId, message } = req.body;\n  const userId = req.user.id;\n  \n  try {\n    // Check if CKO service is available\n    const ckoStatus = await checkCKOServiceStatus();\n    \n    if (ckoStatus.available) {\n      // Use full CKO persona for response\n      const ckoResponse = await getCKOResponse(sessionId, message, userId);\n      return res.json(ckoResponse);\n    } else {\n      // Log degradation event\n      console.warn('CKO service unavailable, falling back to basic RAG');\n      await logServiceDegradation('cko', ckoStatus.reason);\n      \n      // Notify user of degraded service\n      const basicRAGResponse = await getBasicRAGResponse(message, userId);\n      \n      // Add degradation notice to response\n      basicRAGResponse.degraded = true;\n      basicRAGResponse.degradationMessage = 'AI Studio is currently operating in basic mode. Some advanced features may be limited.';\n      \n      return res.json(basicRAGResponse);\n    }\n  } catch (error) {\n    console.error('Error handling CKO query:', error);\n    return res.status(500).json({\n      error: 'Failed to process your request',\n      degraded: true,\n      degradationMessage: 'AI Studio is experiencing technical difficulties. Please try again later.'\n    });\n  }\n};\n```",
        "testStrategy": "1. Unit test WebSocket error handling with simulated connection failures\n2. Test retry queue with various failure scenarios\n3. Verify graceful degradation to basic RAG when CKO is unavailable\n4. Test user notification system for processing delays\n5. Verify error logging and monitoring captures relevant information\n6. Test recovery from various failure scenarios\n7. Verify system maintains 99.5% monthly availability with graceful degradation (NFR-007)\n8. Test that failed external operations are queued and retried automatically (max 3 attempts)\n9. Verify users are notified of processing delays\n10. Test system behavior when Redis/cache is unavailable",
        "priority": "high",
        "dependencies": [
          "82",
          "83",
          "84",
          "89"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-07T20:04:36.976Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-07T20:12:12.267Z",
      "taskCount": 32,
      "completedCount": 32,
      "tags": [
        "v7_3_features"
      ]
    }
  },
  "empire_desktop_v75": {
    "tasks": [
      {
        "id": 1,
        "title": "Project Setup and Tauri 2.0 Initialization",
        "description": "Initialize Tauri 2.0 project with React 18, TypeScript, TailwindCSS, and shadcn/ui for macOS native desktop app.",
        "details": "Use Tauri CLI v2.0.3: `npm create tauri-app@latest -- --template react-ts`. Install React 18.3.1, TailwindCSS 3.4.10, shadcn/ui v0.9.0. Configure `tauri.conf.json` for WKWebView, Rust backend with tokio 1.40.0 for async ops, and sqlx 0.8.1 for SQLite. Set up Rust commands for secure keychain access using keyring 2.5.0 crate. Binary target: macOS arm64/x86_64.",
        "testStrategy": "Run `tauri dev` and verify app launches <2s, WKWebView renders React UI, Rust commands invoke via `invoke('check_keychain')`. Test on macOS Sonoma/Ventura.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Local SQLite Database Setup",
        "description": "Implement local SQLite database with exact schema from PRD for projects, conversations, messages, files, and settings.",
        "details": "Use sqlx 0.8.1 with SQLite feature and rusqlite 0.32.1. Create encrypted DB using SQLCipher via tauri-plugin-sql 2.0.0. Execute PRD schema SQL on init. Add migrations with sqlx-cli 0.8.1. Rust function: `init_db(path: PathBuf) -> Result<Pool<Sqlite>>`. Store in `~/.empire/empire.db`. Enable WAL mode for concurrency.",
        "testStrategy": "Unit tests for schema creation, insert/query projects table. Verify encryption with invalid key fails. Integration test: CRUD project record.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Clerk Authentication Integration",
        "description": "Integrate Clerk auth with secure JWT storage in macOS keychain and auto-refresh.",
        "details": "Use @clerk/clerk-react 5.1.2. Rust backend: keyring 2.5.0 for Keychain access (`keyring::Entry::new('empire', 'jwt')`). Implement OAuth flow redirecting to system browser. Auto-refresh using Clerk's token cache. Expose Tauri commands: `login()`, `get_token()`, `logout()`. Biometric unlock via security-framework 2.10.0 crate.",
        "testStrategy": "Mock Clerk API, test token storage/retrieval, refresh flow. Verify keychain isolation per user. E2E: full login cycle.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Empire Backend API Client",
        "description": "Create TypeScript API client for all specified Empire v7.3 endpoints with WebSocket streaming.",
        "details": "Use axios 1.7.7 for HTTP, @tauri-apps/api 2.0.3 for WS. Implement EmpireAPI interface exactly as PRD. Streaming: `ReadableStream` from WS `/ws/chat`. Auth: Bearer token interceptor. Endpoints: `/api/query/auto`, `/api/query/adaptive`, `/api/documents/upload`, etc. TypeScript types from PRD models. Retry logic with exponential backoff using p-retry 5.0.0.",
        "testStrategy": "Mock server with MSW 2.4.11, test all endpoints, streaming chunks, error handling, auth interceptor.",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Main Chat Interface with Streaming",
        "description": "Build core chat UI with multi-line input, attachments, streaming responses, source citations.",
        "details": "React 18 + shadcn/ui Chat components. Use zustand 5.0.0-rc.2 for state. Streaming: use `useEffect` with API client's AsyncGenerator. Markdown rendering: react-markdown 9.0.1 + remark-gfm. Drag-drop files: react-dropzone 14.2.3. Citations: expandable [1][2] popover. Input: TextareaAutosize from shadcn.",
        "testStrategy": "Cypress 13.15.0 E2E: send message, verify streaming animation, expand citations, file drag-drop. Unit: message rendering.",
        "priority": "high",
        "dependencies": [
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Projects CRUD Operations",
        "description": "Implement project management: create, list, update, delete with local+remote sync.",
        "details": "React components: ProjectList, ProjectForm using shadcn DataTable. Local ops via sqlx Rust commands. Sync: POST to Empire API, update `remote_id` and `synced_at`. Templates: store as project with `is_template=true`. Department selector: 12 options from PRD. Zustand store: `projectsStore`.",
        "testStrategy": "Unit: CRUD local DB. Integration: create project → API sync → list verifies remote_id. UI: form validation, list search.",
        "priority": "high",
        "dependencies": [
          2,
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Chat History and Global Search",
        "description": "Build sidebar navigation, conversation list, global/project search with filters.",
        "details": "SQLite FTS5 for search: `CREATE VIRTUAL TABLE messages_fts USING fts5(content, tokenize=porter)`. Rust command: `search_messages(query: &str, filters: Json)`. UI: shadcn CommandMenu for Cmd+K. Results: highlight matches with context preview. Filters: date, project, attachments via SQL WHERE.",
        "testStrategy": "Performance: <500ms search 10k messages. Accuracy: insert test data, verify FTS matches. UI: search → jump to message.",
        "priority": "high",
        "dependencies": [
          2,
          5,
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Real-time Data Sync and Offline Mode",
        "description": "Implement bi-directional sync between local SQLite and Supabase with offline history viewing.",
        "details": "Use Supabase JS 2.46.6 client in Rust via tauri-plugin. Conflict resolution: last-write-wins by `updated_at`. Background sync: tokio task polling every 30s. Offline: queue unsynced changes in `pending_sync` table. Sync indicator: badge on sidebar. Queue queries for online.",
        "testStrategy": "Mock network: offline → queue → online → verify sync. Conflict test: edit same record on two devices.",
        "priority": "medium",
        "dependencies": [
          2,
          3,
          4,
          6,
          7
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Keyboard Shortcuts and Native macOS Features",
        "description": "Implement all specified keyboard shortcuts, menu bar, system tray, notifications.",
        "details": "Tauri: tauri-plugin-global-shortcut 2.0.0 for Cmd+N etc. Menu: tauri-plugin-menu 2.0.0. Tray: system_tray 0.7.0 crate. Notifications: notify-rust 4.9.0. Window: tauri-plugin-window-state 2.0.0 for restore position. Dark mode: use-os-theme.",
        "testStrategy": "Manual: test all shortcuts in app. Automated: use tauri-plugin-macos-specific for key event simulation.",
        "priority": "medium",
        "dependencies": [
          1,
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Settings, Quick Actions, and Packaging",
        "description": "Build settings UI, quick action buttons, project instructions/files, DMG packaging.",
        "details": "Settings: shadcn Settings panel, sync to DB. Quick actions: buttons calling API `/api/summarizer`, etc. Project files: upload to `/api/documents/upload`, store metadata. Instructions: rich textarea → project.instructions. Packaging: `tauri build` with codesign, DMG via create-dmg 2.0.0. Auto-updater: tauri-plugin-updater 2.0.0.",
        "testStrategy": "E2E: settings persist after restart, quick actions trigger API, file upload succeeds. Packaging: build → install DMG → launch verifies.",
        "priority": "medium",
        "dependencies": [
          2,
          4,
          5,
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "MCP Client Foundation",
        "description": "Implement MCP client layer for Supabase/Neo4j server management and tool integration.",
        "details": "Rust: tokio for spawning processes per PRD config `~/.empire/mcp_settings.json`. JSON-RPC 2.0 over stdin/stdout using serde_json 1.0.120. Commands: `start_mcp_server(name: String)`, `list_tools()`. UI: settings page to add/remove servers. Cache resources locally.",
        "testStrategy": "Integration: spawn mock MCP server, verify JSON-RPC tool list, invoke tool. Error: invalid config fails gracefully.",
        "priority": "medium",
        "dependencies": [
          1,
          3
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2026-01-02T21:40:07.235Z",
      "updated": "2026-01-02T21:40:07.235Z",
      "description": "Tasks for empire_desktop_v75 context"
    }
  }
}